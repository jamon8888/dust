export const description =
  'An overview of the Dust Platform along with its associated design principles.'

# Platform overview

An overview of the Dust Platform along with its associated design principles. You will learn how a
Dust app is structured and how it is executed. {{ className: 'lead' }}

Dust is designed to provide a flexible framework to define and deploy [large language model
apps](/introduction#large-language-model-apps) without having to write any execution code. It is
specifically intended to ease:

- Working on multiple examples at the same time while designing a large language model app.
- Introspecting model outputs produced by intermediary steps of large language model apps.
- Iterating on the design of large language model apps by providing a granular and automated
  versioning system.

## Motivation

In this section, based on years of experience designing large language model apps, we argue that
code is not the most appropriate abstraction layer when designing large language model apps.

**Entanglement and Speed.** When designing such apps, which generally consists in chains of calls to
large language models, it is highly recommended to work on multiple examples at the same time (maybe
a half-dozen) to avoid _overfitting_ your design to one particular example. Given the latency
associated with querying large language models, when working on an app with, say, 3 chained called
to a model, using 6 examples at the same time, testing your app already requires 18 calls to a large
language model. The first thing most developer will do is parallelizing the execution of the app,
effectively entangling the logic of the app with language-specific execution code. In our
experience, this has created a lot of friction while exploring the design space of an app, as each
change of paradigm generally requires a refactor of the execution code produced so far.

**Introspection.** Additionally, large language models outputs are extremely verbose, they include
not only the text generated but also the propabilities of each associated tokens. When iterating on
the design of a large language model app, especially if it has chained calls, most developer will
stop logging the output of the models (to avoid flooding their console, especially when executing in
parallel), preventing later introspection of the behavior of each element of the app.

**Versioning.** Finally, designing a large language model app, is an extremely iterative process. It
requires iterating on the prompt associated with each chained call to a large language model, as
well as the overall orchestration logic. This iterative nature makes it very easy to forget, or fail
to capture, the state of an app at a given point of time, preventing its recovery if the design
exploration leads to a dead-end.

Dust intends to solve each of these pain points by introducing a block structure along with an
automated caching and versioning system.

- **Entanglement and Speed**: Dust's execution engine automatically takes care of executing apps
  blocks in a fully parallelized manner, optionally caching model interactions to increase speed of
  iteration. As a result, Dust apps encode their logic and nothing more, making them easier to
  understand and maintain.

- **Introspection**: Dust automatically stores every block execution output and provides an UI for
  easily introspecting them on-demand. We believe leveraging an UI to be crucial while designing large
  language model apps to allow, when needed and possibly retro-actively, the introspection of each
  block output.

- **Versioning**: Dust automatically stores each version of your app as well as each execution of it
  allowing you to design with confidence, knowing that it is always possible recover a previous
  version of your large language model app, which we believe is important given the highly iterative
  nature of this process.

## Blocks

Dust apps are composed of blocks which are executed sequentially. Blocks don't have inputs, but they
can refer to the output of any previously executed block.

A block has a **type** and a **BLOCK_NAME** (uppercase, no space). Each block, when executed outputs
a JSON object that can later be accessed by subsequent blocks.

<Image src="/block_overview.png" alt="Anatomy of a Dust block">
  _The anatomy of a Dust block showing where blocks type, name, and
  configuration can be edited. Also presents the common tooling available to all
  blocks. In this example `INPUT.title` or `AGGREGATE.blob` refer to previous
  blocks outputs, respectively the `title` and `blob` fields of the `INPUT` and
  `AGGREGATE` blocks output objects._
</Image>

## Inputs

The `input` block is the block that receives the arguments required to run a Dust app.

By default, a Dust app has a unique execution stream, but the `input` block allows you to run a
Dust app on multiple inputs in parallel while designing it. During the _design phase_, an input
block refers to a dataset, and when executed, will fork the execution stream on each element of its
dataset and return that element as output. After an `input` block, each block will have as many
outputs as there are elements in the dataset associated with the `input` block, representing the
outputs for each parallel execution stream.

There can be only one `input` block per app. Before the `input` block there is only one stream of
execution. After the `input` block, there is as many parallel streams of execution as there are
elements in the dataset associated with the `input` block.

<Note>
  The `input` block is used to parametrize an app behavior. While designing the
  app, it is associated to a dataset of input examples. When the app is run by
  API, it will return the inputs passed by API.
</Note>

When run by API, an app receives an array of inputs (generally just one, but multiple is possible)
and will be executed on these inputs instead of the dataset it is associated with during the design
phase.

<Image
  src="input_illustration.png"
  alt="Illustration of the role of the input block"
>
  _The `code` block `FOO` is executed only once and its output will be
  accessible from each stream of execution spawned by the `input` block. The
  outputs of the `input` block are elements of the dataset it is associated
  with, one element per stream of execution. Subsequent blocks will have access
  to outputs from their respective streams of execution.
</Image>

## Datasets

Dust apps can also define datasets which are arrays of JSON objects. Datasets main roles are:

- Store example inputs on which the app is run during its design. These datasets are pulled from
  `input` blocks.
- Store few-shot examples used when prompting models. These datasets are made available to `llm`
  blocks through the use of `data` blocks (see [core blocks](#)).

All datasets are automatically versioned and each app version points to their specific dataset
version.

## Execution

The Dust execution engine will run an app in parallel on each element attached to the `input` block.
Each input's execution trace is completely independent and they cannot be cross-referenced. Previous
runs of an app are stored along with the app version and all the associated block outputs. They can
be retrieved from the `Runs` panel.

Other [core blocks](#) allow the further parallelization of the execution such as the `map` and
`reduce` blocks. Dust's execution engine will also take care of automatically parallelizing
execution eagearly when they are used.
